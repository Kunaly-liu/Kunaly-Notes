##  Java面试题总结

## Java 基础

###  面向对象和面向过程的区别?

**面向过程 ：**面向过程是一种以事件为中心的编程思想，编程的时候把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步一步的具体步骤中再按顺序调用函数。

**面向对象 ：**面向对象是按人们认识客观世界的系统思维方式，采用基于对象（实体）的概念建立模型，模拟客观世界分析、设计、实现软件的编程思想，通过面向对象的理念使计算机软件系统能与现实世界中的系统一一对应。

面向对象易维护、易复用、易扩展。 因为面向对象有封装、继承、多态性的特性，所以可以设计出低耦合的系统，使系统更加灵活、更加易于维护。但是，面向对象性能比面向过程低。

 

### 类与对象的区别？

**类的概念：**
类是具有相同属性和服务的一组对象的集合。它为属于该类的所有对象提供了统一的抽象描述，其内部包括属性和服务两个主要部分。在面向对象的编程语言中，类是一个独立的程序单位，它应该有一个类名并包括属性说明和服务说明两个主要部分。

**对象的概念：**
对象是系统中用来描述客观事物的一个实体，它是构成系统的一个基本单位。一个对象由一组属性和对这组属性进行操作的一组服务组成。从更抽象的角 度来说，对象是问题域或实现域中某些事物的一个抽象，它反映该事物在系统中需要保存的信息和发挥的作用；它是一组属性和有权对这些属性进行操作的一组服务的封装体。客观世界是由对象和对象之间的联系组成的。

**类与对象的关系：**
类与对象的关系就如模具和铸件的关系，`类的实例化结果就是对象，而对一类对象的抽象就是类`。类描述了一组有相同特性（属性）和相同行为（方法）的对象。

###  Java 面向对象编程三大特性: 封装 继承 多态

**封装**

封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。

**继承**

继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。

关于继承如下 3 点请记住：

1. 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。
2. 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。
3. 子类可以用自己的方式实现父类的方法。（以后介绍）。

**多态**

**多态是同一个行为具有多个不同表现形式或形态的能力。**

**多态就是同一个接口，使用不同的实例而执行不同操作。**

所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。在 Java 中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。



### 访问修饰符 public,private,protected,default 的区别？ 

| 修饰符    | 当前类 | 同 包 | 同包子类 | 不同包子 类 | 其他包 |
| --------- | ------ | ----- | -------- | ----------- | ------ |
| public    | 能     | 能    | 能       | 能          | 能     |
| protected | 能     | 能    | 能       | 能          | 不能   |
| default   | 能     | 能    | 能       | 不能        | 不能   |
| private   | 能     | 不能  | 不能     | 不能        | 不能   |

类的成员不写访问修饰时默认为 default。默认对于同一个包中的其他类相当于公 开（public），对于不是同一个包中的其他类相当于私有（private）。受保护 （protected）对子类相当于公开，对不是同一包中的没有父子关系的类相当于私有。Java 中，外部类的修饰符只能是 public 或默认，类的成员（包括内部类）的 修饰符可以是以上四种。



### Static关键字有什么作用？

Static可以修饰内部类、方法、变量、代码块

- Static修饰的类是静态内部类
- Static修饰的方法是静态方法，表示该方法属于当前类的，而不属于某个对象的，静态方法也不能被重写，可以直接使用类名来调用。在static方法中不能使用this或者super关键字。
- Static修饰变量是静态变量或者叫类变量，静态变量被所有实例所共享，不会依赖于对象。静态变量在内存中只有一份拷贝，在JVM加载类的时候，只为静态分配一次内存。
- Static修饰的代码块叫静态代码块，通常用来做程序优化的。静态代码块中的代码在整个类加载的时候只会执行一次。静态代码块可以有多个，如果有多个，按照先后顺序依次执行。



### final 在java中的作用，有哪些用法?

final也是很多面试喜欢问的地方,但我觉得这个问题很无聊,通常能回答下以下5点就不错了: 
1. 被final修饰的类不可以被继承。
2. 被final修饰的方法不可以被重写。
3. **被final修饰的变量不可以被改变，如果修饰引用，那么表示引用不可变，引用指向的内容可变。** 
4. 被final修饰的方法，JVM会尝试将其内联，以提高运行效率。
5. 被final修饰的常量，在编译阶段会存入常量池中。



### Java的重写与重载是什么？有什么区别？

重载与重写是Java 多态性的不同表现。
重写是父类与子类之间多态性的表现，而重载是一个类中多态性的表现。

**重载：**

1、方法名相同，必须具有不同的参数列表。

2、可以有不同的返回类型，只要参数列表不同即可。

3、可有不同的访问修饰符。

4、可以抛出不同的异常。

**重写：**

1、参数列表必须与被重写的方法相同。

2、返回的类型必须与被重写的方法的返回类型相同。

（注意：jdk7、jdk8 子类方法返回的类型是父类方法返回类型的子类算成一致）

3、访问修饰符的限制一定要大于被重写的方法的访问修饰符。

4、重写方法一定不能抛出新的检查异常或比被重写的方法申明更加宽泛的检查型异常。

| 区别点     | 重载方法 | 重写方法                                                     |
| ---------- | -------- | ------------------------------------------------------------ |
| 发⽣范围   | 同一个类 | 子类                                                         |
| 参数列表   | 必须修改 | ⼀定不能修改                                                 |
| 返回类型   | 可修改   | ⼦类⽅法返回值类型应⽐⽗类⽅法返回值类型更⼩或相等           |
| 异常       | 可修改   | ⼦类⽅法声明抛出的异常类应⽐⽗类⽅法声明抛出的异常类更⼩或相等； |
| 访问修饰符 | 可修改   | ⼀定不能做更严格的限制（可以降低限制）                       |
| 发生阶段   | 编译期   | 运行期                                                       |

方法的重写要遵循“**两同两小一大**”：

“两同”即方法名相同、形参列表相同；

“两小”指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等；

“一大”指的是子类方法的访问权限应比父类方法的访问权限更大或相等。



### 构造方法有哪些特性？ 

1. 名字与类名相同。
2. 没有返回值，但不能用 void 声明构造函数。
3. 生成类的对象时自动执行，无需调用。



### 无参构造方法的作用？

Java 程序在执行子类的构造方法之前，如果没有用 super() 来调用父类特定的构造方法，则会调用父类中“没有参数的构造方法”。因此，如果父类中只定义了有参数的构造方法，而在子类的构造方法中又没有用 super() 来调用父类中特定的构造方法，则编译时将发生错误，因为 Java 程序在父类中找不到没有参数的构造方法可供执行。解决办法是在父类里加上一个不做事且没有参数的构造方法。



### 父子类的加载顺序

- (1) 父类静态代码块(包括静态初始化块，静态属性，但不包括静态方法)
- (2) 子类静态代码块(包括静态初始化块，静态属性，但不包括静态方法 )
- (3) 父类非静态代码块( 包括非静态初始化块，非静态属性 )
- (4) 父类构造函数
- (5) 子类非静态代码块 ( 包括非静态初始化块，非静态属性 )
- (6) 子类构造函数

```java
class A {
    public A() {//构造函数
        System.out.println("class A");
    }
    { //代码块
        System.out.println("I'm A class"); 
    }
    static { //静态代码块
        System.out.println("class A static"); 
    }
}
public class B extends A {
    public B() {//构造函数
        System.out.println("class B");
    }
    { //代码块
        System.out.println("I'm B class"); 
    }
    static { System.out.println("class B static"); 
    }   //静态代码块
    public static void main(String[] args) {
         new B();
    }
}
```

结果：

```java
 class A static 
 class B static 
 I'm A class 
 class A
 I'm B class 
 class B
```



### String 是基本数据类型吗？

不是。Java 中的基本数据类型只有 8 个：byte、short、int、long、float、double、 char、boolean；除了基本类型（primitive type），剩下的都是引用类型（reference type），Java 5 以后引入的枚举类型也算是一种比较特殊的引用类型。



### 基本类型和包装类型的区别

Java 的每个基本类型都对应了一个包装类型，比如说 int 的包装类型为 Integer，double 的包装类型为 Double。

基本类型和包装类型的区别主要有以下 4 点：

**1.包装类型可以为 null，而基本类型不可以**

> 它使得包装类型可以应用于 POJO 中，而基本类型则不行 **POJO**：简单无规则的 Java 对象，只有属性字段以及 setter 和 getter 方法。为什么 POJO 的属性必须要用包装类型? 《阿里巴巴 Java 开发手册》上有详细的说明 数据库的查询结果可能是 null，如果使用基本类型的话，因为要自动拆箱（将包装类型转为基本类型，比如说把 Integer 对象转换成 int 值），就会抛出 NullPointerException 的异常。

**2.包装类型可用于泛型，而基本类型不可以**

**3.基本类型比包装类型更高效**

基本类型在栈中直接存储的具体数值，而包装类型则存储的是堆中的引用

<img src="Java面试总结.assets/image-20210926022102181.png" alt="image-20210926022102181" style="zoom:50%;" />

**4.自动装箱和自动拆箱**

有了基本类型和包装类型，肯定有些时候要在它们之间进行转换。 把基本类型转换成包装类型的过程叫做装箱。 反之，把包装类型转换成基本类型的过程叫做拆箱, 在 Java SE5 之前，开发人员要手动进行装拆箱



### int 和 Integer

```java
public static void main(String[] args) {    
    Integer i1 = 100;
    Integer i2 = 100;
    // i1 == i2?
    Integer i3 = 128;
    Integer i4 = 128;
  // i3 == i4?
}
```

答案：

i1 == i2为true 

i3 == i4为false

在Interger类中，存在一个静态内部类IntegerCache， 该类中存在一个Integer cache[]， 并且存在一个static块，会在加载类的时候执行，会将-128至127这些数字提前生成Integer对象，并缓存在cache数组中，当我们在定义Integer数字时，会调用Integer的valueOf方法，valueOf方法会判断所定义的数字是否在-128至127之间，如果存在则直接从cache数组中获取Integer对象，如果超过，则生成一个新的 Integer 对象。



### 简述内部类、静态内部类、匿名内部类的区别

**成员内部类：**      

成员内部类可访问外部类所有的方法和成员变量。      

不能有静态方法和静态成员变量。  ( static 成员变量，必须同时使用 final 和 static 修饰。)

在外部类的静态方法和外部类以外的其他类中，必须通过外部类的实例创建内部类的实例。

在外部类中不能直接访问内部类的成员，而必须通过内部类的实例去访问。

**局部内部类：**

`在方法中定义的内部类称为局部内部类`。与局部变量类似，局部内部类不能有访问说明符，因为它不是外围类的一部分，但是它可以访问当前代码块内的常量，和此外围类所有的成员。

需要注意的是：

　　(1)、局部内部类只能在定义该内部类的方法内实例化，不可以在此方法外对其实例化。

　　(2)、局部内部类对象不能使用该内部类所在方法的非final局部变量。

**静态内部类：**      

只能访问外部类的静态成员变量与静态方法。      

静态内部类的非静态成员可访问外部类的静态变量，而不可访问外部类的非静态变量。  

在创建静态内部类的实例时，不需要创建外部类的实例。

**匿名内部类：**      

**类的定义和对象的实例化同时进行。** 

1、匿名内部类不能定义任何静态成员、方法。

2、匿名内部类中的方法不能是抽象的；

3、匿名内部类必须实现接口或抽象父类的所有抽象方法。

4、匿名内部类不能定义构造器；

5、匿名内部类访问的外部类成员变量或成员方法必须用static修饰；

6、内部类可以访问外部类私有变量和方法。



### 接口和抽象类的区别是什么？

1. 接口的方法默认是 public ，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。
2. 接口中除了 static  final  变量，不能有其他变量，而抽象类中则不一定。
3. 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过 extends  关键字扩展多个接口。
4. 接口方法默认修饰符是 public ，抽象方法可以有 public 、 protected  和 default  这些修饰符（抽象方法就是为了被重写所以不能使用 private  关键字修饰！）。
5. 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。

> 总结一下 jdk7~jdk9 Java 中接口概念的变化：
> 1. 在 jdk 7 或更早版本中，接口里面只能有常量变量和抽象方法。这些接口方法必须由选择实现接口的类实现。
> 2. jdk 8 的时候接口可以有默认方法和静态方法功能。
> 3. jdk 9 在接口中引入了私有方法和私有静态方法。
>



###  成员变量与局部变量的区别有哪些？

1. **从语法形式上看**：**成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；**成员变量可以被 public , private , static  等修饰符所修饰，而局部变量不能被访问控制修饰符及 static  所修饰；但是，成员变量和局部变量都能被 final  所修饰。
2. **从变量在内存中的存储方式来看：**如果成员变量是使用 static 修饰的，那么这个成员变量是属于类的，如果没有使用 static 修饰，这个成员变量是属于实例的。对象存于堆内存，如果局部变量类型为基本数据类型，那么存储在栈内存，如果为引用数据类型，那存放的是指向堆内存对象的引用或者是指向常量池中的地址。
3. **从变量在内存中的生存时间上看**：**成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。**
4. **成员变量如果没有被赋初值：**则会自动以类型的默认值而赋值（一种情况例外:被 final  修饰的成员变量也必须显式地赋值），而局部变量则不会自动赋值。



### == 与 equals 的区别？

== : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象(基本数据类型==比较的是值，引用数据类型==比较的是内存地址)。

equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：

- 情况 1：类没有覆盖 equals() 方法。则通过 equals() 比较该类的两个对象时，等价于通过“==”比较这两个对象。
- 情况 2：类覆盖了 equals() 方法。一般，我们都覆盖 equals() 方法来比较两个对象的内容是否相等；若它们的内容相等，则返回 true (即，认为这两个对象相等)。

```java
public class test1 {
    public static void main(String[] args) {
        String a = new String("ab"); // a 为一个引用
        String b = new String("ab"); // b为另一个引用,对象的内容一样
        String aa = "ab"; // 放在常量池中
        String bb = "ab"; // 从常量池中查找
        if (aa == bb) // true
            System.out.println("aa==bb");
        if (a == b) // false，非同一对象
            System.out.println("a==b");
        if (a.equals(b)) // true
            System.out.println("aEQb");
        if (42 == 42.0) { // true
            System.out.println("true");
        }
    }
}
```

**说明：**
String 中的 equals 方法是被重写过的，因为 object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。

当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。

###  hashCode 与 equals ？

`hashCode() ` 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。` hashCode()` 定义在 JDK 的 Object  类中，这就意味着 Java 中的任何类都包含有 `hashCode()`  函数。另外需要注意的是： Object  的 `hashcode() `方法是本地方法，也就是用 c 语⾔或 c++ 实现的，该方法通常用来将对象的内存地址转换为整数之后返回。

**为什么要有 hashCode？**

我们以“ HashSet  如何检查重复”为例子来说明为什么要有 hashCode？

当你把对象加入 HashSet  时， HashSet  会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode， HashSet  会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals()  方法来检查 hashcode 相等的对象是否真的相同。如果两者相同， HashSet  就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。

两个对象有相同的 hashcode 值，它们也不一定是相等。

**请你解释Object若不重写hashCode()的话，hashCode()如何计算出来的？**

Object 的 hashcode 方法是本地方法，也就是用 c 或 c++ 实现的，该方法直接返回对象的内存地址。
如果没有重写hashCode()，则任何对象的hashCode()值都不相等（而Hashmap想让部分值的hashCode值一样，所以就要重写）。

**为什么在Java中重写equals()方法同时要重写hashcode()方法？**

由上个问题知道没有重写hashCode()，则任何对象的hashCode()值都不相等。

HashMap中的比较key是这样的，先求出key的hashcode()，比较其值是否相等，若相等再比较equals(),若相等则认为他们是相等的。若equals()不相等则认为他们不相等。

如果只重写equals没有重写hashCode()，就会导致相同的key值也被hashcode认为是不同的key值（因为没有重写hashCode()，则任何对象的hashCode() 值都不相等），就会在HashMap中存储相同的key值（map中key值不能相同），这就不符合条件了。

**equals和hashcode的关系:**

1、如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；

2、如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false)



### Error与Exception的区别

在 Java 中，所有的异常都有一个共同的祖先 Throwable（可抛出）。

**Throwable**： 有两个重要的子类：Exception（异常）和 Error（错误），二者都是 Java 异常处理的重要子类，各自都包含大量子类。异常和错误的区别是：异常能被程序本身可以处理，错误是无法处理。

**Error（错误）:** 是程序无法处理的错误，表示运行应用程序中较严重问题。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题。例如，Java虚拟机运行错误（Virtual MachineError），当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。这些错误表示故障发生于虚拟机自身、或者发生在虚拟机试图执行应用时，如Java虚拟机运行错误（Virtual MachineError）、类定义错误（NoClassDefFoundError）等。这些错误是不可查的，因为它们在应用程序的控制和处理能力之 外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在 Java中，错误通过Error的子类描述。 

 **Exception（异常）:**  是程序本身可以处理的异常。Exception 类有一个重要的子类 RuntimeException。RuntimeException 类及其子类表示“JVM 常用操作”引发的错误。例如，若试图使用空值对象引用、除数为零或数组越界，则分别引发运行时异常（NullPointerException、ArithmeticException）和 ArrayIndexOutOfBoundException。

  **Exception（异常）分两大类：运行时异常和非运行时异常(编译异常)。**程序中应当尽可能去处理这些异常。

1.  **运行时异常：**都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。
2.  **非运行时异常 （编译异常）：**是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。

![image-20210925012542230](Java面试总结.assets/image-20210925012542230.png)



### 获取用键盘输入常用的两种方法？

**方法 1：通过 Scanner**

```java
Scanner input = new Scanner(System.in);
String s  = input.nextLine();
input.close();
```

**方法 2：通过 BufferedReader**

```java
BufferedReader input = new BufferedReader(new InputStreamReader(System.in));
String s = input.readLine();
```



### Java中的IO流分为几种？

 **Java 中 IO 流分为几种?** 

- 按照流的流向分，可以分为输入流和输出流；
- 按照操作单元划分，可以划分为字节流和字符流；
- 按照流的角色划分为节点流和处理流。

> InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。
>
> OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。

**按操作方式分类结构图：**

![](Java面试总结.assets/image-20210720015235287.png)

**按操作对象分类结构图：**

![image-20210720015413996](Java面试总结.assets/image-20210720015413996.png)



###  既然有了字节流、为什么还要有字符流?

问题本质想问：不管是文件读写还是网络发送接收，信息的最小存储单元都是字节，那为什么 I/O 流操作要分为字节流操作和字符流操作呢？

回答：字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。



### IO 操作

> IO分两阶段（一旦拿到数据后就变成了数据操作，不再是IO）：   
>
> 1. 数据准备阶段   
> 2.  内核空间复制数据到用户进程缓冲区（用户空间）阶段 

在操作系统中，程序运行的空间分为内核空间和用户空间，应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。 

 **阻塞IO和非阻塞IO的区别在于第一步发起IO请求是否会被阻塞：**    

如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。 

一般来讲：阻塞IO模型、非阻塞IO模型、IO复用模型(select/poll/epoll)、信号驱动IO模型都属于同步IO，因为阶段2是阻塞的(尽管时间很短)。 

**同步IO和异步IO的区别就在于第二个步骤是否阻塞：**  

 如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO

> 同步和异步IO的概念： 	
>
> - 同步是用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行 	
> - 异步是用户线程发起I/O请求后仍需要继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数 
>
> 阻塞和非阻塞IO的概念： 	
>
> - 阻塞是指I/O操作需要彻底完成后才能返回用户空间 	
> - 非阻塞是指I/O操作被调用后立即返回一个状态值，无需等I/O操作彻底完成



### 什么是同步、异步、阻塞、非阻塞？

先来个例子理解一下概念，以银行取款为例： 

**同步 ：** 自己亲自出马持银行卡到银行取钱（**使用同步IO时，Java自己处理IO读写**）；

**异步 ：** 委托一小弟拿银行卡到银行取钱，然后给你（**使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)**）；

**阻塞 ：** ATM排队取款，你只能等待（**使用阻塞IO时，Java调用会一直阻塞到读写完成才返回**）；

**非阻塞 ：** 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（**使用非阻塞IO时，如果不能读写 Java 调用会马上返回，当 IO 事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成**）



**同步阻塞IO：**在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！

**同步非阻塞IO：**在此种方式下，用户进程发起一个 IO 操作以后边可返回做其它事情，但是用户进程需要时不时的询问 IO 操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的 CPU 资源浪费。JAVA的NIO就属于同步非阻塞IO。

**异步非阻塞IO：**在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。Java AIO属于这种异步非阻塞模型。 

**IO多路复用**

**select：**轮询，遍历所有连接，调用对应设备驱动的poll函数，检测读流、写流、异常流。容量是固定的，连接数有限制。

**poll**：轮询，和select差不多，但是它对fd集合做了优化，使用链表存储，解决了连接数上限的问题。

**epoll**：**epoll最大的优化就是让就绪的fd执行回调函数，不需要再去fd集合轮询哪些fd就绪了**。epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，**epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。**

调用`epoll_create`创建句柄，并采用红黑树而不是数组来存储描述符和事件，用双向链表rdllist存放准备就绪的事件；

调用`epoll_ctl`添加监听事件时，若红黑树中没有相应的节点，增加节点，并新增回调函数。每当有事件中断来临时，调用回调函数向双向链表rdllist中插入数据；

调用`epoll_wait`返回或判断rdllist中的数据，便可以得到事件完成的描述符。

epoll两种工作模式：水平触发，边缘触发。红黑树和双向链表都存在内核cache中，避免额外开销。

- **LT模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，**应用程序可以不立即处理该事件**。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
- **ET模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，**应用程序必须立即处理该事件**。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。



###  BIO、NIO、AIO 有什么区别?

**Java 中 3 种常⻅ IO 模型:**

- **BIO 属于同步阻塞 IO 模型 。**
   同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到在内核把数据拷贝到用户空间。

  ![image-20210730234317671](Java面试总结.assets/image-20210730234317671.png)

- ![image-20210730232827421](Java面试总结.assets/image-20210730232827421.png)

- **NIO (Non-blocking/New I/O): 同步非阻塞的 I/O。**
  同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。 相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。

   但是，这种 IO 模型同样存在问题：**应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是⼗分消耗 CPU 资源的。**

  ![image-20210730234507692](Java面试总结.assets/image-20210730234507692.png)

  **I/O 多路复用模型**

   IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间->用户空间）还是阻塞的。

  ![image-20210730234753130](Java面试总结.assets/image-20210730234753130.png)

  Java 中的 NIO 于 Java 1.4 中引入，对应 java.nio  包，提供了 Channel  , Selector， Buffer  等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。

  Java 中的 NIO 可以看作是 I/O 多路复用模型。也有很多⼈认为，Java 中的 NIO 属于同步非阻塞 IO 模型。

  > **Java NIO 主要有三大核心部分： Channel(通道)， Buffer(缓冲区)， Selector（选择器）。**
  >
  > 传统 IO 基于字节流和字符流进行操作， 而 NIO 基于 Channel 和 Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。 Selector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。  NIO 和传统 IO 之间第一个最大的区别是， IO 是面向流的， NIO 是面向缓冲区的。
  
  ![image-20210730234813828](Java面试总结.assets/image-20210730234813828.png)

- **AIO (Asynchronous I/O): 异步非阻塞的 IO。**在 Java 7 中引入了 NIO 的改进版 NIO 2。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

![image-20210730234900405](Java面试总结.assets/image-20210730234900405.png)

[Linux内核之 I/O多路复用 ](https://www.cnblogs.com/orange-CC/p/13571016.html)



### java中是值传递引用传递？ 

理论上说，java都是引用传递，对于基本数据类型，传递是值的副本，而不是值本身。对于对象类型，传递是对象的引用，当在一个方法操作操作参数的时候，其实操作的是引用所指向的对象。

### 形参与实参区别

**实参(argument)：**

 全称为"实际参数"是在调用时传递给函数的参数，实参可以是常量、变量、表达式、函数等， 无论实参是何种类型的量，在进行函数调用时，它们都必须具有确定的值， 以便把这些值传送给形参。 因此应预先用赋值，输入等办法使实参获得确定值。    

**形参(parameter)：**

全称为"形式参数" 由于它不是实际存在变量，所以又称虚拟变量。是在定义函数名和函数体的时候使用的参数,目的是用来接收调用该函数时传入的参数.在调用函数时，实参将赋值给形参。因而，必须注意实参的个数，类型应与形参一一对应，并且实参必须要有确定的值。

> 实参出现在主调函数中，进入被调函数后，实参变量也不能使用。
>
> 形参出现在函数定义中，在整个函数体内都可以使用， 离开该函数则不能使用。
>
> **形参和实参的功能是作数据传送。发生函数调用时， 主调函数把实参的值传送给被调函数的形参从而实现主调函数向被调函数的数据传送。**

1. **形参变量只有在被调用时才分配内存单元，在调用结束时， 即刻释放所分配的内存单元。**因此，参只有在函数内部有效。 函数调用结束返回主调函数后则不能再使用该形参变量。 
2. **实参可以是常量、变量、表达式、函数等， 无论实参是何种类型的量，在进行函数调用时，它们都必须具有确定的值，** 以便把这些值传送给形参。 因此应预先用赋值，输入等办法使实参获得确定值。 
3. **实参和形参在数量上，类型上，顺序上应严格一致， 否则会发生“类型不匹配”的错误。** 
4. **函数调用中发生的数据传送是单向的。** 即只能把实参的值传送给形参，而不能把形参的值反向地传送给实参。 因此在函数调用过程中，形参的值发生改变，而实参中的值不会变化。
5. 当形参和实参不是指针类型时，在该函数运行时，形参和实参是不同的变量，他们在内存中位于不同的位置，形参将实参的内容复制一份，在该函数运行结束的时候形参被释放，而实参内容不会改变。而如果函数的参数是指针类型变量,在调用该函数的过程中，传给函数的是实参的地址，在函数体内部使用的也是实参的地址，即使用的就是实参本身。所以在函数体内部可以改变实参的值。



### 深拷贝 vs 浅拷贝？

1. 浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。
2. 深拷贝：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。

![image-20210720133827089](Java面试总结.assets/image-20210720133827089.png)



### 如何实现对象的克隆？

有两种方式：

1). 实现 Cloneable 接口并重写 Object 类中的 clone()方法；

2). 实现 Serializable 接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆。



### 什么是泛型？为什么要使用泛型？

泛型，即“参数化类型”。

一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。

泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。



### 什么是反射

Java反射就是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；并且能改变它的属性。

**反射能做什么？**

我们知道反射机制允许程序在运行时取得任何一个已知名称的class的内部信息，包括包括其modifiers(修饰符)，fields(属性)，methods(方法)等，并可于运行时改变fields内容或调用methods。那么我们便可以更灵活的编写代码，代码可以在运行时装配，无需在组件之间进行源代码链接，降低代码的耦合度；还有动态代理的实现等等；但是需要注意的是反射使用不当会造成很高的资源消耗！

### 反射的实现，获取Class类的方式

1. 使用 Class 类的 forName 静态方法

   ```java
   Class aClass1 = Class.forName("java.lang.String");
   ```

2. 任何数据类型（包括基本的数据类型）都有一个“静态”的class属性

   ```java
   Class aClass2 = String.class;
   ```

3. 使用对象的getClass()方法

   ```java
   Class aClass3 = "hello".getClass();
   ```

4. 通过类加载器ClassLoader的loadClass方法

   ```java
   ClassLoader cl = this.getClass().getClassLoader();
   Class aClass4 = cl.loadClass("类的全类名");
   ```

   

### 反射中，Class.forName和ClassLoader区别

（1）Class.forName除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。

（2）而classloader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容，只有在newInstance才会去执行static块。

> Class.forName(name,initialize,loader)带参数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象。

ClassLoader就是遵循双亲委派模型最终调用启动类加载器的类加载器，实现的功能是“通过一个类的全限定名来获取描述此类的二进制字节流”，获取到二进制流后放到JVM中。Class.forName()方法实际上也是调用的CLassLoader来实现的。



### Java 反射 API 

**反射 API 用来生成 JVM 中的类、接口或则对象的信息。**

1. Class 类：反射的核心类，可以获取类的属性，方法等信息。
2. Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。
3. Method 类： Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法。
4. Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法。

```java
//获取 Person 类的 Class 对象
 Class clazz=Class.forName("reflection.Person");
//获取 Person 类的所有方法信息
 Method[] method=clazz.getDeclaredMethods();
 for(Method m:method){
    System.out.println(m.toString());
 }
 //获取 Person 类的所有成员属性信息
 Field[] field=clazz.getDeclaredFields();
 for(Field f:field){
    System.out.println(f.toString());
 }
 //获取 Person 类的所有构造方法信息
 Constructor[] constructor=clazz.getDeclaredConstructors();
 for(Constructor c:constructor){
    System.out.println(c.toString());
 
```

### 如何利用反射动态创建对象实例

**Class 对象的 newInstance()**

1. 使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求
该 Class 对象对应的类有默认的空构造器。

**调用 Constructor 对象的 newInstance()**

2. 先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance()
    方法来创建 Class 对象对应类的实例,通过这种方法可以选定构造方法创建实例。

  ```java
  //获取 Person 类的 Class 对象
   Class clazz=Class.forName("reflection.Person"); 
   //使用.newInstane 方法创建对象
   Person p=(Person) clazz.newInstance();
  //获取构造方法并创建对象
   Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);
   //创建对象并设置属性 
   Person p1=(Person) c.newInstance("李四","男",20);
  ```

  

### 什么是java序列化，如何实现序列化？

**序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。**

可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决在对对象流进行读写操作时所引发的问题。

#### 序列化的实现

将需要被序列化的类实现`Serializable`接口，该接口没有需要实现的方法，`implements Serializable`只是为了标注该对象是可被序列化的，然后使用一个输出流(如：`FileOutputStream`)来构造一个`ObjectOutputStream`(对象流)对象，接着，使用`ObjectOutputStream`对象的`writeObject(Object obj)`方法就可以将参数为`obj`的对象写出(即保存其状态)，要恢复的话则用输入流。

**序列化对象以字节数组保持--静态成员不保存** 

使用 Java 对象序列化， 在保存对象时，会把其状态保存为一组字节，在未来， 再将这些字节组装成对象。必须注意地是， 对象序列化保存的是对象的”状态”，即它的成员变量。由此可知，对象序列化不会关注类中的静态变量。

要想将父类对象也序列化，就需要让父类也实现 Serializable 接口。

#### Transient 关键字

Transient 关键字阻止该变量被序列化到文件中：

1. 在变量声明前加上 Transient 关键字，可以阻止该变量被序列化到文件中，在被反序列化后， transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。
2. 服务器端给客户端发送序列化对象数据，对象中有一些数据是敏感的，比如密码字符串等，希望对该密码字段在序列化时，进行加密，而客户端如果拥有解密的密钥，只有在客户端进行反序列化时，才可以对密码进行读取，这样可以一定程度保证序列化对象的数据安全。



### 什么是注解？

Annotation（注解）是 Java 提供的一种对元程序中元素关联信息和元数据（metadata）的途径和方法。 Annatation(注解)是一个接口，程序可以通过反射来获取指定程序中元素的 Annotation对象，然后通过该 Annotation 对象来获取注解中的元数据信息。

**4 种标准元注解是哪四种？**

元注解的作用是负责注解其他注解。

1. **@Target 修饰的对象范围：**可被用于 packages、types（类、接口、枚举、Annotation 类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch 参数）。

2. **@Retention 定义 被保留的时间长短：**表示需要在什么级别保存注解信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效），取值（RetentionPoicy）有：SOURCE:在源文件中有效（即源文件保留）、CLASS:在 class 文件中有效（即 class 保留）、RUNTIME:在运行时有效（即运行时保留）。

3. **@Documented 描述-javadoc：**@Documented 用于描述其它类型的 annotation 应该被作为被标注的程序成员的公共 API，因此可以被例如 javadoc 此类的工具文档化。

4. **@Inherited 阐述了某个被标注的类型是被继承的：**如果一个使用了@Inherited 修饰的 annotation 类型被用于一个 class，则这个 annotation 将被用于该class 的子类。

   

### JDK 1.8 的新特性

- **Lambda 表达式** − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。
- **方法引用** − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。
- **默认方法** − 默认方法就是一个在接口里面有了一个实现的方法。
- **新工具** − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。
- **Stream API** −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。
- **Date Time API** − 加强对日期与时间的处理。
- **Optional 类** − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。
- **Nashorn, JavaScript 引擎** − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。



## Java 集合

**Java 集合框架图**

<img src="Java面试总结.assets/20180803195348216" alt="这里写图片描述" style="zoom:150%;" />



### String 为什么是不可变的?

简单的来说：String 类中使用 final 关键字修饰字符数组来保存字符串， private final char value[] ，所以 String 对象是不可变的。

### String、StringBuffer 和 StringBuilder 的区别?

而 StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串 char[] value  但是没有用 final 关键字修饰，所以这两种对象都是可变的。

String 中的对象是不可变的，也就可以理解为常量，线程安全。

StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。

StringBuilder 并没有对方法进行加同步锁，所以是线程不安全的。

**性能**

每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的⻛险。

对于三者使用的总结：

1. 操作少量的数据: 适用 String
2. 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder
3. 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer



###  说说List、Set、Map三者的区别？

- List (对付顺序的好帮手)：存储的元素是有序的、可重复的。
- Set (注重独一无二的性质)： 存储的元素是无序的、不可重复的。
- Map (用 Key 来搜索的专家)：使用键值对（kye-value）存储，类似于数学上的函数 y=f(x)，“x”代表 key，"y"代表 value，Key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。



### Arraylist 与 LinkedList 区别?

1. **底层数据结构： Arraylist  底层使用的是 Object  数组； LinkedList  底层使用的是 双向链表 数据结构**（JDK1.6 之前为循环链表，JDK1.7 取消了循环，改为双向链表，原因：1、头尾表示更清晰；2、头尾插入元素维护指针更少，效率更高；3、省去了一个header节点的空间）

2. **插入和删除是否受元素位置的影响：**

   ① ArrayList  采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行 add(E e) 方法的时候， ArrayList  会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（ add(int index, E element) ）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。

   ② LinkedList  采用链表存储，所以对于 add(E e) 方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（ (add(int index, E element) ） 时间复杂度近似为 o(n)) 因为需要先移动到指定位置再插入。

4. **是否支持快速随机访问：** LinkedList  不支持高效的随机元素访问，而 ArrayList  支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于 get(int index) 方法)。
5. **内存空间占用：** ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

###  ArrayList 与 Vector 区别呢?

- **ArrayList**  是 List  的主要实现类，底层使用 Object[ ] 存储，适用于频繁的查找工作，线程不安全 ;
- **Vector**  是 List  的古老实现类，底层使用 Object[ ] 存储，线程安全的。



### HashMap 说一说？

1. HashMap 的底层是个 Node 数组（Node<K,V>[] table），在数组的具体索引位置，如果存在多个节点，则可能是以链表或红黑树的形式存在。
2. 增加、删除、查找键值对时，定位到哈希桶数组的位置是很关键的一步，源码中是通过下面3个操作来完成这一步：
   1. 拿到 key 的 hashCode 值；
   2. 将 hashCode 的高位参与运算，重新计算 hash 值；
   3. 将计算出来的 hash 值与 “table.length - 1” 进行 & 运算。
3. HashMap 的默认初始容量（capacity）是 16，capacity 必须为 2 的幂次方；默认负载因子（load factor）是 0.75；实际能存放的节点个数（threshold，即触发扩容的阈值）= capacity * load factor。
4. HashMap 在触发扩容后，阈值会变为原来的 2 倍，并且会对所有节点进行重 hash 分布，重 hash 分布后节点的新分布位置只可能有两个：“原索引位置” 或 “原索引+oldCap位置”。例如 capacity 为16，索引位置 5 的节点扩容后，只可能分布在新表 “索引位置5” 和 “索引位置21（5+16）”。
5. 导致 HashMap 扩容后，同一个索引位置的节点重 hash 最多分布在两个位置的根本原因是：1）table的长度始终为 2 的 n 次方；2）索引位置的计算方法为 “(table.length - 1) & hash”。HashMap 扩容是一个比较耗时的操作，定义 HashMap 时尽量给个接近的初始容量值。
6. HashMap 有 threshold 属性和 loadFactor 属性，但是没有 capacity 属性。初始化时，如果传了初始化容量值，该值是存在 threshold 变量，并且 Node 数组是在第一次 put 时才会进行初始化，初始化时会将此时的 threshold 值作为新表的 capacity 值，然后用 capacity 和 loadFactor 计算新表的真正 threshold 值。
7. **当同一个索引位置的节点在增加后大于8，并且此时数组的长度大于等于 64，则会触发链表节点（Node）转红黑树节点（TreeNode），**转成红黑树节点后，其实链表的结构还存在，通过 next 属性维持。链表节点转红黑树节点的具体方法为源码中的 treeifyBin 方法。而如果数组长度小于64，则不会触发链表转红黑树，而是会进行扩容。
8. 当同一个索引位置的节点在移除后达到 6 个时，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点。红黑树节点转链表节点的具体方法为源码中的 untreeify 方法。
9. HashMap 在 JDK 1.8 之后不再有死循环的问题，JDK 1.8 之前存在死循环的根本原因是在扩容后同一索引位置的节点顺序会反掉。
10. HashMap 是非线程安全的，在并发场景下使用 ConcurrentHashMap 来代替。

**为什么要转红黑树？**

红黑树是一个特殊的平衡二叉树，查找的时间复杂度是 O(logn) ；而链表查找元素的时间复杂度为 O(n)，远远大于红黑树的 O(logn)，尤其是在节点越来越多的情况下，O(logn) 体现出的优势会更加明显；简而言之就是为了提升查询的效率。

**为什么不一开始就用红黑树？**

单个 TreeNode 需要占用的空间大约是普通 Node 的两倍，所以只有当包含足够多的 Nodes 时才会转成 TreeNodes，而是否足够多就是由 TREEIFY_THRESHOLD 的值（默认值8）决定的。而当桶中节点数由于移除或者 resize 变少后，又会变回普通的链表的形式，以便节省空间，这个阈值是 UNTREEIFY_THRESHOLD（默认值6）。



### HashTable和HashMap的区别？

1. Hashtable是线程安全的，HashMap不是线程安全的；

2. HashMap效率较高，Hashtable效率较低；

   如果对同步性或与遗留代码的兼容性没有任何要求，建议使用HashMap。 查看Hashtable的源代码就可以发现，除构造函数外，Hashtable的所有 public 方法声明中都有 synchronized关键字，而HashMap的源码中则没有。

3. 对 Null key 和 Null value 的支持： HashMap  可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException 。

4. 父类不同：Hashtable的父类是Dictionary，HashMap的父类是AbstractMap；

5. 初始容量大小和每次扩充容量大小的不同 ：

    ① 创建时如果不指定容量初始值， Hashtable  默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。 HashMap  默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。

   ② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap  会将其扩充为 2 的幂次方大小（ HashMap  中的 tableSizeFor() 方法保证，下面给出了源代码）。也就是说 HashMap  总
   是使用 2 的幂作为哈希表的大小。

6. 底层数据结构： JDK1.8 以后的 HashMap  在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。

![image-20210803002256766](Java面试总结.assets/image-20210803002256766.png)

![image-20210803002323578](Java面试总结.assets/image-20210803002323578.png)

### 为什么HashMap的容量总是为2的整次幂?

HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素
存放的位置（这里的 n 指的是数组的长度）这里的`hash%length==hash&(length-1)`的前提是 length 是2的 n 次方。 并且 采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方。



### ConcurrentHashMap 和 Hashtable 的区别？

ConcurrentHashMap  和 Hashtable  的区别主要体现在实现线程安全的方式上不同。

- **底层数据结构：** 

  JDK1.7 的 ConcurrentHashMap  底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟 HashMap1.8  的结构一样，**数组+链表/红黑树**。 

  Hashtable  和 JDK1.8 之前的 HashMap  的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；

- **实现线程安全的方式（重要）：** 

  ① 在 JDK1.7 的时候， ConcurrentHashMap （分段锁） 对整个桶数组进行了分割分段( Segment )，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了 Segment  的概念，而是直接用 **Node  数组+链表+红黑树**的数据结构来实现，并发控制使用 `synchronized  和 CAS `来操作。

  ② Hashtable （同一把锁, **全表锁**） :使用 `synchronized ` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

  ![image-20210720144747127](Java面试总结.assets/image-20210720144747127.png)

![image-20210720144807261](Java面试总结.assets/image-20210720144807261.png)

**JDK1.8 的 ConcurrentHashMap：(锁头节点)**

JDK1.8 的 ConcurrentHashMap  不在是 Segment 数组 + HashEntry 数组 + 链表，而是 **Node 数组 + 链表 / 红黑树**。不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode 。当冲突链表达到一定长度时，链表会转换成红黑树。

![image-20210803002448856](Java面试总结.assets/image-20210803002448856.png)



### ConcurrentHashMap线程安全的具体实现方式？

**JDK1.7：**  

 ConcurrentHashMap  是由 Segment  数组结构和 HashEntry  数组结构组成。

```java
static class Segment<K,V> extends ReentrantLock implements Serializable {
}
```

Segment 实现了 ReentrantLock ,所以 Segment  是一种可重入锁，扮演锁的角色。 HashEntry  用于存储键值对数据。首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。

一个 ConcurrentHashMap  里包含一个 Segment  数组。 Segment  的结构和 HashMap  类似，是一种数组和链表结构，一个 Segment  包含一个 HashEntry  数组，每个 HashEntry  是一个链表结构的元素，每个 Segment  守护着一个 HashEntry  数组里的元素，当对 HashEntry  数组的数据进行修改时，必须首先获得对应的 Segment  的锁。

**JDK1.8：**

 ConcurrentHashMap  取消了 Segment  分段锁，采用 CAS 和 synchronized  来保证并发安全。数据结构跟HashMap1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值 `8 `时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))），synchronized  只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。



### HashMap的扩容机制原理

**1.7版本**

1. 先生成新数组
2. 遍历老数组中的每个位置上的链表上的每个元素
3. 取每个元素的key，并基于新数组长度，计算出每个元素在新数组中的下标
4. 将元素添加到新数组中去
5. 所有元素转移完了之后，将新数组赋值给HashMap对象的table属性

**1.8版本**

1. 先生成新数组

2. 遍历老数组中的每个位置上的链表或红黑树

3. 如果是链表，则直接将链表中的每个元素重新计算下标，并添加到新数组中去

4. 如果是红黑树，则先遍历红黑树，先计算出红黑树中每个元素对应在新数组中的下标位置

   a. 统计每个下标位置的元素个数
   b. 如果该位置下的元素个数超过了8，则生成一个新的红黑树，并将根节点的添加到新数组的对应位置
   c. 如果该位置下的元素个数没有超过8，那么则生成一个链表，并将链表的头节点添加到新数组的对应位置

5. 所有元素转移完了之后，将新数组赋值给HashMap对象的table属性



### HashMap 和 HashSet区别？

 HashSet  底层就是基于 HashMap  实现的。

| HashMap                            | HashSet                                                      |
| ---------------------------------- | ------------------------------------------------------------ |
| 实现了 Map  接口                   | 实现 Set  接口                                               |
| 存储键值对                         | 仅存储对象                                                   |
| 调用put() 向 map 中添加加元素      | 调用add() 方法向 Set  中添加元素                             |
| HashMap  使用键（Key）计算hashcode | HashSet  使用成员对象来计算 hashcode  值，对于两个对象来说hashcode 可能相同，所以 equals() 方法用来判断对象的相等性 |



### HashSet如何检查重复？

当你把对象加入 HashSet 时， HashSet  会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode  值作比较，如果没有相符的 hashcode ， HashSet  会假设对象没有重复出现。但是如果发现有相同 hashcode  值的对象，这时会调用 equals() 方法来检查 hashcode  相等的对象是否真的相同。如果两者相同， HashSet  就不会让加入操作成功。

hashCode() 与 equals()  的相关规定：
1. 如果两个对象相等，则 hashcode  一定也是相同的
2. 两个对象相等,对两个 equals()  方法返回 true
3. 两个对象有相同的 hashcode  值，它们也不一定是相等的
4. 综上， equals()  方法被覆盖过，则 hashCode()  方法也必须被覆盖
5. hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode() ，



###  HashSet、LinkedHashSet 和 TreeSet 三者的异同

- **HashSet**  是 Set  接口的主要实现类 ， HashSet  的底层使用的是 HashMap 的键值，线程不安全的，可以存储 null 值；
- **LinkedHashSet**  是 HashSet  的子类，能够按照添加的顺序遍历；同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。
- **TreeSet**  是SortedSet接口的唯一实现类，TreeSet可以确保集合元素处于排序状态。排序的方式有自然排序和定制排序。

> **如果你需要一个访问快速的Set，你应该使用HashSet；**
>
> **当你需要一个排序的Set，你应该使用TreeSet；**
>
> **当你需要记录下插入时的顺序时，你应该使用LinkedHashSet。**



### CopyOnWriteArrayList 的底层原理是怎样的

1. 首先CopyOnWriteArrayList内部也是用过数组来实现的，在向CopyOnWriteArrayList添加元素时，会复制一个新的数组，写操作在新数组上进行，读操作在原数组上进行
   
2. 并且，写操作会加锁，防止出现并发写入丢失数据的问题

3. 写操作结束之后会把原数组指向新数组

4. CopyOnWriteArrayList允许在写操作时来读取数据，大大提高了读的性能，因此适合读多写少的应用场景，但是CopyOnWriteArrayList会比较占内存，同时可能读到的数据不是实时最新的数据，所以不适合实时性要求很高的场景

  

### Java的Arrays.sort()方法用的什么排序

Arrays.sort并不是单一的排序，而是插入排序，快速排序，归并排序三种排序的组合；

1. **元素少于INSERTION_SORT_THRESHOLD（47）用插入排序**；
2. **大于INSERTION_SORT_THRESHOLD（47）少于阀值 QUICKSORT_THRESHOLD（286），用快速排序的方法；**
3. **大于阀值QUICKSORT_THRESHOLD（286），归并排序**；

如下图：

![image-20210723133007120](Java面试总结.assets/image-20210723133007120.png)





## Java 多线程

### 简述线程、程序、进程的基本概念？

**程序**是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。

**进程**是程序的一次执行过程，是系统运行程序(资源分配)的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，同时，每个进程还占有某些系统资源如 CPU 时间，内存空间，文件，输入输出设备的使用权等等。

**线程**与进程相似，但线程是一个比进程更小的调度和执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。



### 进程间通信方式

**管道(pipe)**

管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

**有名管道 (namedpipe)**

有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

**信号量(semaphore)**

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

**消息队列(messagequeue)**

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

**信号 (sinal)**

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**共享内存(shared memory)**

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

**套接字(socket)**

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。



### 线程间通信方式

**1. wait/notify等待通知方式**

基于synchronized和wait()和notify()

**2. 管道流**

管道输入/输出流的形式

**3. Volatile 内存共享**

共享内存：线程之间共享程序的公共状态，线程之间通过读-写内存中的公共状态来隐式通信。

**4. 阻塞队列**

Java5提供了一个BlockingQueue接口，虽然BlockingQueue也是Queue的子接口，但它的主要用途不是作为容器，而是作为线程同步的工具。

BlockingQueue具有一个特征：当生产者线程试图向BlockingQueue中放入元素时，如果该队列已满则线程被阻塞。而消费者线程 在取元素时，如果该队列已空则该线程被阻塞。

程序的两个线程通过交替向BlockingQueue中放入元素、取出元素，即可很好地控制线程的通信。

**5. 使用JUC工具类 **

CountDownLatch 并发工具

CyclicBarrier 并发工具

**6. 基于Lock和Condition的await()和signal()**

**7. 基于LockSupport的park()和unpark()**



### 线程的创建方式?

1. 继承Thread类

2. 实现Runnable接口

3. 使用Callable和Future
4. 使用线程池

### 实现 Runnable 接口和 Callable 接口的区别？

 Callable  接口可以返回结果或抛出检查异常，Runnable  接口不会。

如果任务不需要返回结果或抛出异常推荐使用 Runnable  接口，这样代码看起来会更加简洁。



### 线程有哪些基本状态?

Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。

![image-20210720013453394](Java面试总结.assets/image-20210720013453394.png)

线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：

![image-20210720013535889](Java面试总结.assets/image-20210720013535889.png)

由上图可以看出：

线程创建之后它将处于 NEW（新建） 状态，调用 start()  方法后开始运行，线程这时候处于 READY（RUNABLE 可运行） 状态。可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 RUNNING（运行） 状态。

当线程执行 wait() 方法之后，线程进入 WAITING（等待）状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过sleep(long millis)方法或 wait(long millis) 方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。



1、新建状态（New）：当线程对象对创建后，即进入了新建状态，如：Thread t= new MyThread()；

2、就绪状态（Runnable）：当调用线程对象的 start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待 CPU 调度执行，并不是说执行了 t.start()此线程立即就会执行；

3、运行状态（Running）：当 CPU 开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就 绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；

4、阻塞状态（Blocked）：处于运行状态中的线程由于某种原因，暂时放弃对 CPU的使用权，停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被 CPU 调用以进入到运行状态。

根据阻塞产生的原因不同，阻塞状态又可以分为三种：

1. 等待阻塞：运行状态中的线程执行 wait()方法，使本线程进入到等待阻塞状态；
2. 同步阻塞：线程在获取 synchronized 同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态；
3. 其他阻塞：通过调用线程的 sleep()或 join()或发出了 I/O 请求时，线程会进入到阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。

5、死亡状态（Dead）：线程执行完了或者因异常退出了 run()方法，该线程结束生命周期。



当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。线程在执行 完Runnable 的 run() 方法之后将会进入到 TERMINATED（终止） 状态。

> 操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。



### 什么是线程死锁?如何避免死锁?

线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

<img src="Java面试总结.assets/image-20210720151745746.png" alt="image-20210720151745746" />

**死锁代码：**

```java
package Algorithm;

public class DeadLock {
    private static Object resource1 = new Object(); //资源1
    private static Object resource2 = new Object(); //资源2

    public static void main(String[] args) {
        new Thread(()->{
            synchronized (resource1){
                System.out.println(Thread.currentThread().getName() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + "waiting resource2");
                synchronized (resource2){
                    System.out.println(Thread.currentThread().getName() + "get resource2");
                }
            }
        },"线程 1 ").start();

        new Thread(()->{
            synchronized(resource2){
                System.out.println(Thread.currentThread().getName() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + "waiting resource1");
                synchronized (resource1){
                    System.out.println(Thread.currentThread().getName() + "get resource1");
                }
            }
        },"线程 2 ").start();
    }
}
```

运行结果：

![image-20210720160019899](Java面试总结.assets/image-20210720160019899.png)

线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过Thread.sleep(1000); 让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。

### 产生死锁必须具备以下四个条件

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

###  如何避免线程死锁?

1. 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。

2. 破坏请求与保持条件 ：一次性申请所有的资源。
3. 破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
4. 破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。



### 什么场景会导致线程的上下文切换？

上下文切换就是一个工作的线程被另外一个线程暂停，另外一个线程占用了处理器开始执行任务的过程。

**导致线程上下文切换的有两种类型：**

**自发性上下文切换**是指线程由 Java 程序调用导致切出，在多线程编程中，执行**调用sleep()、wait()、yield()、join()、park()、方法或 synchronized 关键字和 lock **，常常就会引发自发性上下文切换。

**非自发性上下文切换**指线程由于调度器的原因被迫切出。常见的有：线程被分配的时间片用完、JVM垃圾回收（STW、线程暂停）、线程执行优先级。

#### 那么虚拟机垃圾回收为什么会导致上下文切换 ？

在 Java 虚拟机中，对象的内存都是由虚拟机中的堆分配的，在程序运行过程中，新的对象将不断被创建，如果旧的对象使用后不进行回收，堆内存将很快被耗尽。Java 虚拟机提供了一种回收机制，对创建后不再使用的对象进行回收，从而保证堆内存的可持续性分配。而这种垃圾回收机制的使用有可能会导致` stop-the-world `事件的发生，这其实就是一种线程暂停行为。



###  sleep() 方法和 wait() 方法区别和共同点?

- **两者最主要的区别在于： sleep()  方法没有释放锁，而 wait()  方法释放了锁 。**
- sleep()方法属于Thread类中的。而wait()方法属于Object类中的。
- wait()  通常被用于线程间交互/通信， sleep() 通常被用于暂停执行。
- wait()  方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll()  方法。 sleep(long timeout) 方法执行完成后，线程会自动苏醒。使用 wait(long timeout)  超时后线程会自动苏醒。
- 两者都可以暂停线程的执行。



### 生产者消费者代码

```java

```



### start() 方法和 run() 方法?

**调用 start()  方法可启动线程并使线程进入就绪状态，直接执行 run()  方法的话不会以多线程的方式执行。**

new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start()  会执行线程的相应准备工作，然后自动执行 run()  方法的内容，这是真正的多线程工作。 但是，直接执行 run()  方法，会把 run()  方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。



### 说一说对于 synchronized 关键字的了解？

synchronized  关键字解决的是多个线程之间访问资源的同步性， synchronized 关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

synchronized 关键字最主要的三种使用方式：

1. 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁。
2. 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁。
3. 修饰代码块 ：指定加锁对象，对给定对象/类加锁。 synchronized(this/object)  表示进入同步代码库前要获得给定对象的锁。 synchronized(类.class)  表示进入同步代码前要获得 当前 class 的锁。

**synchronized底层原理：**

Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。  monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因。

1. MonitorEnter指令：插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁；
2. MonitorExit指令：插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit；

在 Java 早期版本中，`synchronized` 属于 **重量级锁**，效率低下。

因为监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对 `synchronized` 较大优化，所以现在的 `synchronized` 锁效率也优化得很不错了。JDK1.6 对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

### synchronized可重入锁的实现原理

synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。

当一个线程请求方法时，会去检查锁状态。

1. 如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。
2. 如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。

在释放锁时，

1. 如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。
2. 如果非可重入锁的，线程退出方法，直接就会释放该锁。

### volatile关键字的作用？

一个共享变量（类的成员变量、类的静态成员变量）被 volatile 修饰之后，那么就具备了两层语义：

- 保证了不同线程对这个变量进行操作时的**可见性**，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
- **保证有序性**：禁止进行指令重排序。

**volatile原理：**

 volatile 可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层 volatile 是采用“内存屏障”来实现的。加入volatile关键字时，会多出一个 lock 前缀指令，lock 前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

（1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；

（2）它会强制将对缓存的修改操作立即写入主存；

（3）如果是写操作，它会导致其他CPU中对应的缓存行无效。



### synchronized 关键字和 volatile 关键字的区别？

`synchronized`  关键字和` volatile`  关键字是两个互补的存在，而不是对立的存在！

- volatile  关键字是线程同步的轻量级实现，所以 volatile 性能肯定比 synchronized 关键字要好。但是 volatile  关键字只能用于变量而 synchronized  关键字可以修饰方法以及代码块。
- volatile  关键字能保证数据的可见性，但不能保证数据的原子性。 synchronized  关键字两者都能保证。
- volatile 关键字主要用于解决变量在多个线程之间的可⻅性，而 synchronized  关键字解决的是多个线程之间访问资源的同步性。



### sychronized 和 ReentrantLock 的区别

相似点：

这两种同步方式有很多相似之处，它们都是加锁方式同步，而且都是阻塞式的同步，也就是说当如果一个线程获得了对象锁，进入了同步块，其他访问该同步块的线程都必须阻塞在同步块外面等待，而进行线程阻塞和唤醒的代价是比较高的。

不同点：

1. sychronized是一个关键字，ReentrantLock是一个类；
2. sychronized会自动的加锁与释放锁，ReentrantLock需要程序员手动加锁与释放锁；
3. sychronized的底层是JVM层面的锁，ReentrantLock是API层面的锁；
4. sychronized是非公平锁，ReentrantLock可以选择公平锁或非公平锁；
5. sychronized锁的是对象，锁信息保存在对象头中，ReentrantLock通过代码中int类型的state标识来标识锁的状态；
6. sychronized底层有一个锁升级的过程；

由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：
1. 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于
Synchronized 来说可以避免出现死锁的情况。
2. 公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数 true 设为公平锁，但公平锁表现的性能不是很好。
3. 锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象 。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。



### 原子性，可见性，有序性

并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念：

- 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

- 可见性：是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

- 有序性：即程序执行的顺序按照代码的先后顺序执行。

  

### ThreadLocal 了解么？

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？

 ThreadLocal 类主要解决的就是让每个线程绑定自己的值，可以将 ThreadLocal 类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。如果你创建了一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。他们可以使用 get（）  和 set（）方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。



**对ThreadLocal的理解、底层原理**
ThreadLocal是 JDK java.lang 包下的一个类，ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量，并且不会和其他线程的局部变量冲突，实现了线程间的数据隔离。ThreadLocal的应用场景主要有：
（1）保存线程上下文信息，在需要的地方可以获取
（2）线程间数据隔离
（3）数据库连接；
*底层原理*：每个线程的内部都维护了一个 ThreadLocalMap，它是一个键值对数据格式，key 是一个弱引用，也就是 ThreadLocal 本身，而 value 是强引用，存的是线程变量的值。也就是说 ThreadLocal 本身并不存储线程的变量值，它只是一个工具，用来维护线程内部的 Map，帮助存和取变量。 

**使用threadLocal会出现什么问题**
ThreadLocal 在 ThreadLocalMap 中是以一个弱引用身份被 Entry 中的 Key 引用的，因此如果 ThreadLocal 没有外部强引用来引用它，那么 ThreadLocal 会在下次 JVM 垃圾收集时被回收。这个时候 Entry 中的 key 已经被回收，但是 value 又是一强引用不会被垃圾收集器回收，这样 ThreadLocal 的线程如果一直持续运行，value 就一直得不到回收，这样就会发生内存泄露。 

**ThreadLocal的key是哪种引用类型？为啥这么设计？**
ThreadLocalMap 中的 key 是弱引用，而 value 是强引用才会导致内存泄露的问题  

1. 若key 使用强引用：这样会导致一个问题，引用的 ThreadLocal 的对象被回收了，但是 ThreadLocalMap 还持有 ThreadLocal 的强引用毫无意义，如果没有手动删除，ThreadLocal 不会被回收，则会导致内存泄漏。 
2. 若key 使用弱引用：这样的话，引用的 ThreadLocal 的对象被回收了，由于 ThreadLocalMap 持有 ThreadLocal 的弱引用，即使没有手动删除，ThreadLocal 也会被回收。value 在下一次 ThreadLocalMap 调用 set、get、remove 的时候会被清除（清理key为null的记录），使用完了ThreadLocal最好在手动的remove一下。 
3. 比较以上两种情况：由于 ThreadLocalMap 的生命周期跟 Thread 一样长，如果都没有手动删除对应 key，都会导致内存泄漏，但是使用弱引用可以多一层保障，弱引用 ThreadLocal 不会内存泄漏，对应的 value 在下一次 ThreadLocalMap 调用 set、get、remove 的时候被清除，算是最优的解决方案。 

**什么是内存泄漏**
内存泄漏是指用户向系统申请分配内存进行使用，可是使用完了以后却没有释放，结果那块内存用户不能访问（也许你把它的地址给弄丢了），而系统也不能再把它分配给需要的程序。 

**Java有哪些引用类型？分别有哪些使用场景**

1. 强引用，任何时候都不会被；垃圾回收器回收，如果内存不足，宁愿抛出OutOfMemoryError
   使用场景：我们平常大部分使用的场景都是使用了强引用，比如new创建对象，反射获得一个对象等。 
2. 软引用，只有在内存将满的时候才会被垃圾回收器回收，如果还有可用内存，垃圾回收器不会回收。
   软引用可以和一个引用队列进行关联，如果这个软引用的对象被垃圾回收，就会将这个软引用加入到关联的队列中去。 可用于高速缓存。 
3. 弱引用（WeakReference），生命周期更短，只要垃圾回收器运行，就肯定会被回收，不管还有没有可用内存。
   使用场景： 弱引用用于生命周期更短的，对内存更敏感的场景中，比如占用内存很大的Map，java api中就提供了WeakHashMap使用，就会是的大Map被及时清理掉。 
4. 虚引用（PhantomReference），虚引用等于没有引用，任何时候都有可能被垃圾回收。虚引用必须和引用队列联合使用，引用队列的作用和软弱引用一样。
   使用场景： 我觉得他的使用场景应该在判断一个对象是否被垃圾回收了，什么时候引用队列有新的引用入队了，就说明他被回收了。

**ThreadLocal  内部维护的是一个类似 Map  的 ThreadLocalMap  数据结构， key  为当前对象的 ThreadLocal  对象，值为 Object 对象。**

比如我们在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 ThreadLocal 对象的Thread 内部都是使用ThreadLocalMap  存放数据的， ThreadLocalMap 的 key 就是 ThreadLocal 对象，value 就是 ThreadLocal  对象调用 set 方法设置的值。

![image-20210720195137553](Java面试总结.assets/image-20210720195137553.png)

### ThreadLocal的内存泄露是什么原因？

ThreadLocal的内存泄露分析：

先看ThreadLocalMap的源码：

```java
static class ThreadLocalMap {
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
    ...
   }
```

ThreadLocal的实现原理，每一个Thread维护一个ThreadLocalMap，key为使用**弱引用**的ThreadLocal实例，value为线程变量的副本。这些对象之间的引用关系如下：

![image-20210728145807734](Java面试总结.assets/image-20210728145807734.png)

实心箭头表示强引用，空心箭头表示弱引用

从上图中可以看出，hreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal不存在外部**强引用**时，Key(ThreadLocal)势必会被GC回收，这样就会导致ThreadLocalMap中key为null， 而value还存在着强引用，只有thead线程退出以后,value的强引用链条才会断掉。

但如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：

> Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value

永远无法回收，造成内存泄漏。

**ThreadLocal正确的使用方法**

- 每次使用完ThreadLocal都调用它的remove()方法清除数据
- 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。

**ThreadLocal 代码示例：**

相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。

```java
import java.text.SimpleDateFormat;
import java.util.Random;

public class ThreadLocalExample implements Runnable{

     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本
    private static final ThreadLocal<SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyyMMdd HHmm"));

    public static void main(String[] args) throws InterruptedException {
        ThreadLocalExample obj = new ThreadLocalExample();
        for(int i=0 ; i<10; i++){
            Thread t = new Thread(obj, ""+i);
            Thread.sleep(new Random().nextInt(1000));
            t.start();
        }
    }

    @Override
    public void run() {
        System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern());
        try {
            Thread.sleep(new Random().nextInt(1000));
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        //formatter pattern is changed here by thread, but it won't reflect to other threads
        formatter.set(new SimpleDateFormat());

        System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern());
    }

}
```

Output:

```java
Thread Name= 0 default Formatter = yyyyMMdd HHmm
Thread Name= 0 formatter = yy-M-d ah:mm
Thread Name= 1 default Formatter = yyyyMMdd HHmm
Thread Name= 2 default Formatter = yyyyMMdd HHmm
Thread Name= 1 formatter = yy-M-d ah:mm
Thread Name= 3 default Formatter = yyyyMMdd HHmm
Thread Name= 2 formatter = yy-M-d ah:mm
Thread Name= 4 default Formatter = yyyyMMdd HHmm
Thread Name= 3 formatter = yy-M-d ah:mm
Thread Name= 4 formatter = yy-M-d ah:mm
Thread Name= 5 default Formatter = yyyyMMdd HHmm
Thread Name= 5 formatter = yy-M-d ah:mm
Thread Name= 6 default Formatter = yyyyMMdd HHmm
Thread Name= 6 formatter = yy-M-d ah:mm
Thread Name= 7 default Formatter = yyyyMMdd HHmm
Thread Name= 7 formatter = yy-M-d ah:mm
Thread Name= 8 default Formatter = yyyyMMdd HHmm
Thread Name= 9 default Formatter = yyyyMMdd HHmm
Thread Name= 8 formatter = yy-M-d ah:mm
Thread Name= 9 formatter = yy-M-d ah:mm
```

从输出中可以看出，Thread-0 已经改变了 formatter 的值，但仍然是 thread-2 默认格式化程序与初始化值相同，其他线程也一样。



###  为什么要用线程池？

**使用线程池的好处：**

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 如何创建线程池?

**一、通过Executors工具类提供的方法。**

**1、newCachedThreadPool**

创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程。

```java
private static void createCachedThreadPool() {
        ExecutorService executorService = Executors.newCachedThreadPool();
        for (int i = 0; i < 10; i++) {
            final int index = i;
            executorService.execute(() -> {
                // 获取线程名称,默认格式:pool-1-thread-1
                System.out.println(DateUtil.now() + " " + Thread.currentThread().getName() + " " + index);
                // 等待2秒
                sleep(2000);
            });
        }
    }
```

结果：

<img src="Java面试总结.assets/711223-20200821180616758-653509028.png" alt="img" align=left />

因为初始线程池没有线程，而线程不足会不断新建线程，所以线程名都是不一样的。

**2、newFixedThreadPool**

创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待。

```java
private static void createFixedThreadPool() {
        ExecutorService executorService = Executors.newFixedThreadPool(3);
        for (int i = 0; i < 10; i++) {
            final int index = i;
            executorService.execute(() -> {
                // 获取线程名称,默认格式:pool-1-thread-1
                System.out.println(DateUtil.now() + " " + Thread.currentThread().getName() + " " + index);
                // 等待2秒
                sleep(2000);
            });
        }
    }
```

结果：

<img src="Java面试总结.assets/711223-20200821180628577-1278267487.png" alt="img"  align=left />

因为线程池大小是固定的，这里设置的是3个线程，所以线程名只有3个。因为线程不足会进入队列等待线程空闲，所以日志间隔2秒输出。

**3、newScheduledThreadPool**

创建一个周期性的线程池，支持定时及周期性执行任务。

```java
private static void createScheduledThreadPool() {
        ScheduledExecutorService executorService = Executors.newScheduledThreadPool(3);
        System.out.println(DateUtil.now() + " 提交任务");
        for (int i = 0; i < 10; i++) {
            final int index = i;
            executorService.schedule(() -> {
                // 获取线程名称,默认格式:pool-1-thread-1
                System.out.println(DateUtil.now() + " " + Thread.currentThread().getName() + " " + index);
                // 等待2秒
                sleep(2000);
            }, 3, TimeUnit.SECONDS);
        }
    }
```

结果：

<img src="Java面试总结.assets/711223-20200821180640775-1180993122.png" alt="img" align="left"/>

因为设置了延迟3秒，所以提交后3秒才开始执行任务。因为这里设置核心线程数为3个，而线程不足会进入队列等待线程空闲，所以日志间隔2秒输出。

> **注意：这里用的是ScheduledExecutorService类的schedule()方法，不是ExecutorService类的execute()方法。**

**4、newSingleThreadExecutor**

创建一个单线程的线程池，可保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

```java
private static void createSingleThreadPool() {
        ExecutorService executorService = Executors.newSingleThreadExecutor();
        for (int i = 0; i < 10; i++) {
            final int index = i;
            executorService.execute(() -> {
                // 获取线程名称,默认格式:pool-1-thread-1
                System.out.println(DateUtil.now() + " " + Thread.currentThread().getName() + " " + index);
                // 等待2秒
                sleep(2000);
            });
        }
    }
```

结果：

<img src="Java面试总结.assets/711223-20200821180649609-293227377.png" alt="img"  align="left"/>

　因为只有一个线程，所以线程名均相同，且是每隔2秒按顺序输出的。

**二、通过ThreadPoolExecutor类自定义。**

ThreadPoolExecutor类提供了4种构造方法，可根据需要来自定义一个线程池。

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        // 省略...
    }
```

共7个参数如下：

（1）corePoolSize：核心线程数，线程池中始终存活的线程数。 

（2）maximumPoolSize: 最大线程数，线程池中允许的最大线程数。（当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。）

（3）keepAliveTime: 存活时间，线程没有任务执行时最多保持多久时间会终止。

（4）unit: 单位，参数keepAliveTime的时间单位，7种可选。

（5）workQueue: 一个阻塞队列，用来存储等待执行的任务，均为线程安全，7种可选。( 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。)

（6）threadFactory: 线程工厂，主要用来创建线程，默及正常优先级、非守护线程。

（7）handler：拒绝策略，拒绝处理任务时的策略，4种可选，默认为AbortPolicy。

> 阿里代码规范《阿里巴巴Java开发手册》中明确不建议使用Executors类提供的这4种方法：
>
> 【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。
>
> Executors返回的线程池对象的弊端如下:
>
> FixedThreadPool和SingleThreadPool：允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。
>
> CachedThreadPool和ScheduledThreadPool：允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。

**ThreadPoolExecutor  阻塞队列**

1. ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。
2. LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。
3. PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。
4. DelayQueue：使用优先级队列实现的无界阻塞队列。
5. SynchronousQueue：不存储元素的阻塞队列。
6. LinkedTransferQueue：由链表结构组成的无界阻塞队列。
7. LinkedBlockingDeque：由链表结构组成的双向阻塞队列

**ThreadPoolExecutor  拒绝策略**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时， ThreadPoolTaskExecutor  定义一些策略:

- ThreadPoolExecutor.AbortPolicy ：抛出 RejectedExecutionException 来拒绝新任务的处理。

- ThreadPoolExecutor.CallerRunsPolicy ：调用执行调用者自己的线程运行任务。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。
- ThreadPoolExecutor.DiscardPolicy ： 不处理新任务，直接丢弃掉。
- ThreadPoolExecutor.DiscardOldestPolicy ： 此策略将丢弃最早的未处理的任务请求。



### 线程池执行原理？

为了搞懂线程池的原理，我们需要首先分析一下 execute 方法，executor.execute(worker) 用来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：

```java
// 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)
   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
 
    private static int workerCountOf(int c) {
        return c & CAPACITY;
    }
 
    private final BlockingQueue<Runnable> workQueue;
 
    public void execute(Runnable command) {
        // 如果任务为null，则抛出异常。
        if (command == null)
            throw new NullPointerException();
        // ctl 中保存的线程池当前的一些状态信息
        int c = ctl.get();
 
        //  下面会涉及到 3 步 操作
        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize
        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)
添加到该线程中；然后，启动该线程从而执行任务。
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会⾛到这里
        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以
加入任务，该任务才会被加入进去
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除
任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。
            if (!isRunning(recheck) && remove(command))
                reject(command);
                // 如果当前线程池为空就新创建一个线程并执行。
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线
程中；然后，启动该线程从而执行任务。
        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内
容。
        else if (!addWorker(command, false))
            reject(command);
    }
```

简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下：

1. 如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务；
2. 如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；
3. 如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；
4. 如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。
   

![image-20210721001623897](Java面试总结.assets/image-20210721001623897.png)



### 执行execute()和 submit()的区别是什么呢？

1. **execute() 方法用于提交不需要返回值的任务，**所以无法判断任务是否被线程池执行成功与否；
2. **submit() 方法用于提交需要返回值的任务。**线程池会返回一个 Future  类型的对象，通过这个 Future  对象可以判断任务是否执行成功，并且可以通过 Future  的 get() 方法来获取返回值， get() 方法会阻塞当前线程直到任务完成，而使用 get(long timeout，TimeUnit unit) 方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。



### 介绍一下 Atomic 原子类

Atomic  翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。所以，所谓原子类说简单点就是具有原子/原子操作特征的类。

并发包 java.util.concurrent  的原子类都存放在 java.util.concurrent.atomic 下,如下图所示。

![image-20210721002323119](Java面试总结.assets/image-20210721002323119.png)

**JUC 包中的原子类是分为4类：**

**基本类型**

使用原子的方式更新基本类型

- AtomicInteger ：整形原子类
- AtomicLong ：长整型原子类
- AtomicBoolean ：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素

- AtomicIntegerArray ：整形数组原子类
- AtomicLongArray ：长整形数组原子类
- AtomicReferenceArray ：引用类型数组原子类

**引用类型**

- AtomicReference ：引用类型原子类
- AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。
- AtomicMarkableReference  ：原子更新带有标记位的引用类型

**对象的属性修改类型**

- AtomicIntegerFieldUpdater ：原子更新整形字段的更新器
- AtomicLongFieldUpdater ：原子更新长整形字段的更新器
- AtomicReferenceFieldUpdater ：原子更新引用类型字段的更新器

### AtomicInteger 的使用

**AtomicInteger 类常用方法**

```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并自增
public final int getAndDecrement() //获取当前的值，并自减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```

**AtomicInteger 类的使用示例**

使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。

```java
class AtomicIntegerTest {
    private AtomicInteger count = new AtomicInteger();
    //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。
    public void increment() {
        count.incrementAndGet();
    }

    public int getCount() {
        return count.get();
    }
}
```

**AtomicInteger 线程安全原理简单分析**

AtomicInteger 类的部分源码：

```java
// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）
private static final Unsafe unsafe = Unsafe.getUnsafe();
private static final long valueOffset;

static {
    try {
        valueOffset = unsafe.objectFieldOffset
            (AtomicInteger.class.getDeclaredField("value"));
    } catch (Exception ex) { throw new Error(ex); }
}

private volatile int value;
```

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

CAS 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个 volatile 变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。



### 什么是 CAS ?

CAS 是 compare and swap 的缩写，即我们所说的比较交换。

cas 是一种基于锁的操作，而且是乐观锁。在 java 中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 来获取数据，性能较悲观锁有很大的提高。

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和 A 的值是一样的，那么就将内存里面的值更新成 B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a 线程获取地址里面的值被b线程修改了，那么 a 线程需要自旋，到下次循环才有可能机会执行。java.util.concurrent.atomic 包下的类大多是使用 CAS 操作来实现的( AtomicInteger,AtomicBoolean,AtomicLong)。

**CAS 的问题**

**1、CAS 容易造成 ABA 问题**

一个线程 a 将数值改成了 b，接着又改成了 a，此时 CAS 认为是没有变化，其实是已经变化过了，而这个问题的解决方案可以使用版本号标识，每操作一次version 加 1。在 java5 中，已经提供了 AtomicStampedReference 来解决问题。

**2、不能保证代码块的原子性**

CAS 机制所保证的知识一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证 3 个变量共同进行原子性的更新，就不得不使用 synchronized 了。

**3、CAS 造成 CPU 利用率增加**

之前说过了 CAS 里面是一个循环判断的过程，如果线程一直没有获取到状态，cpu 资源会一直被占用。



### AQS 了解么？

AQS 的全称为（ AbstractQueuedSynchronizer ），这个类在 java.util.concurrent.locks 包下面。

![AQS类](Java面试总结.assets/AQS类.png)

AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用⼴泛的大量的同步器，比如我们提到的 ReentrantLock ， Semaphore ，其他的诸如 ReentrantReadWriteLock ， SynchronousQueue ， FutureTask  等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。

**AQS 原理:**

AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

> CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。

AQS(AbstractQueuedSynchronizer)原理图：

![image-20210721003353977](Java面试总结.assets/image-20210721003353977.png)

AQS 使用一个volatile修饰的 int 成员变量来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。

```java
private volatile int state;//共享变量，使用volatile修饰保证线程可⻅性
```

状态信息通过 protected 类型的 getState，setState，compareAndSetState 进行操作

```java
//返回同步状态的当前值
protected final int getState() {
        return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
        state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

**AQS 定义两种资源共享方式：**

`Exclusive（独占）：`只有一个线程能执行，如 ReentrantLock 。又可分为公平锁和非公平锁：

- 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
- 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的

`Share（共享）：`多个线程可同时执行，如CountDownLatch 、 Semaphore  、 CyclicBarrier 、 ReadWriteLock 。



### 如何自定义同步器

不同的自定义同步器争用共享资源的方式也不同。**自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可**，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在底层实现好了。自定义同步器实现时主要实现以下几种方法：

- isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
- tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
- tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
- tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
- tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

默认情况下，每个方法都抛出 UnsupportedOperationException 。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS 类中的其他方法都是 final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。

以 ReentrantLock 为例，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。此后，其他线程再 tryAcquire()时就会失败，直到 A 线程 unlock()到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证 state 是能回到零态的。

再以 CountDownLatch  以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后 countDown()  一次，state 会 CAS(Compare and Swap)减 1。等到所有子线程都执行完后(即 state=0)，会 unpark()主调用线程，然后主调用线程就会从 await()  函数返回，继续后余动作。



### AQS 组件总结

**Semaphore (信号量)-允许多个线程同时访问：** synchronized  和 ReentrantLock  都是一次只允许一个线程访问某个资源， Semaphore (信号量)可以指定多个线程同时访问某个资源。

**CountDownLatch （倒计时器）：** CountDownLatch  是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以**让某一个线程等待直到倒计时结束，再开始执行**。

CountDownLatch 的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch 对象的 await()方法，其他的任务执行完自己的任务后调用同一个 CountDownLatch 对象上的countDown()方法，这个调用 await()方法的任务将一直阻塞等待，直到这个 CountDownLatch 对象的计数值减到 0 为止。

**CyclicBarrier (循环栅栏)：** CyclicBarrier  和 CountDownLatch  非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch  更加复杂和强大。主要应用场景和 CountDownLatch  类似。 CyclicBarrier  的字面意思是可循环使用（ Cyclic ）的屏障（ Barrier ）。它要做的事情是，**让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。** CyclicBarrier  默认的构造方法是 CyclicBarrier(int parties) ，其参数表示屏障拦截的线程数量，每个线程调用 await()  方法告诉 CyclicBarrier  我已经到达了屏障，然后当前线程被阻塞。



### ReentrantLock的非公平锁和公平锁的两处不同

1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。

公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。

相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。



### Java 锁升级过程

#### 锁种类

**偏向锁：**

偏向锁是JDK6中引入的一项锁优化，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。通过在锁对象的对象头中记录一下当前获取到该锁的线程ID，这样该线程下次如果又来获取该锁就可以直接获取到了；

**轻量级锁：**

如果明显存在其它线程申请锁，那么偏向锁将很快升级为轻量级锁。之所以叫轻量级锁，是为了和重量级锁区分开来，轻量级锁底层是通过自旋来实现的，并不会阻塞线程；

**自旋锁：**

自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。

**重量级锁：**

指的是原始的Synchronized的实现，重量级锁的特点：除拥有锁的线程外阻塞其他所有竞争线程，只有持有锁的线程释放锁之后才会唤醒这些线程。

#### 锁升级具体过程

**锁的4种状态：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态（级别从低到高）**

![preview](Java面试总结.assets/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg)

1. 线程A在进入同步代码块前，先检查MarkWord中的线程ID是否与当前线程ID一致，如果一致（还是线程A获取锁对象），则无需使用CAS来加锁、解锁。
2. 如果不一致，再检查是否为偏向锁，如果不是，则自旋等待锁释放。
3. 如果是，再检查该线程是否存在（偏向锁不会主动释放锁），如果不在，则设置线程ID为线程A的ID，此时依然是偏向锁。
4. 如果还在，则暂停该线程，同时将锁标志位设置为00即轻量级锁（将MarkWord复制到该线程的栈帧中并将MarkWord设置为栈帧中锁记录Lock record）。线程A自旋等待锁释放。
5. 如果自旋次数到了该线程还没有释放锁，或者该线程还在执行，线程A还在自旋等待，这时又有一个线程B过来竞争这个锁对象，那么这个时候轻量级锁就会膨胀为重量级锁。重量级锁把除了拥有锁的线程都阻塞，防止CPU空转。
6. 如果该线程释放锁，则会唤醒所有阻塞线程，重新竞争锁。



### 多线程操作long和double类型的问题？

JAVA内存模型要求，变量的读取和写入必须是原子操作，但对于非volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解成两个32位的操作。当读取一个非volatile类型的long时，如果读操作和写操作在不同的线程中执行，那么很可能读取到某个值的高32位和另一个值的低32位。就是说，在多线程环境下，使用共享且可变的long和double变量是不安全的，必须用关键字volatile声明或者用锁保护起来。





## JVM

### 什么是JMM模型？

`JMM并不真实存在，只是一种规范，通过这种规范来让定义程序中各个变量的访问方式。`JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。

JMM是围绕原子性，有序性、可见性展开

![image-20210727150746409](Java面试总结.assets/image-20210727150746409.png)

**JMM-同步八种操作介绍**

1. lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态
2. unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
3. read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
4. load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
5. use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
6. assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量
7. store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
8. write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中

　　如果要把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。

![image-20210727150902527](Java面试总结.assets/image-20210727150902527.png)



### 介绍下 Java 内存区域(运行时数据区)

JVM 内存区域主要分为：

线程私有区域【程序计数器、虚拟机栈、本地方法区】、线程共享区域【JAVA 堆、方法区】。

![image-20210721012013437](Java面试总结.assets/image-20210721012013437.png)

线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁。

线程共享区域随虚拟机的启动/关闭而创建/销毁。

![image-20210721012352780](Java面试总结.assets/image-20210721012352780.png)

#### 程序计数器(线程私有)

一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，为了线程切换后能恢复到正确的执行位置，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有”的内存。

 正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如果还是 Native 方法，则为空。 

这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。

#### 虚拟机栈(线程私有)

是描述 java 方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。

栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接 (Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。![image-20210721014749322](Java面试总结.assets/image-20210721014749322.png)

局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。

![image-20210721012843580](Java面试总结.assets/image-20210721012843580.png)

Java 虚拟机栈会出现两种错误： StackOverFlowError  和 OutOfMemoryError 。

- StackOverFlowError ： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。
- OutOfMemoryError ： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出 OutOfMemoryError 错误。

####  本地方法栈(线程私有)

和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

####  堆（Heap-线程共享）

Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一⽬的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。

在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分：
1. 新生代内存(Young Generation)
2. 老生代(Old Generation)
3. 永生代(Permanent Generation)

![image-20210721013513088](Java面试总结.assets/image-20210721013513088.png)

JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。

![image-20210721013623009](Java面试总结.assets/image-20210721013623009.png)

大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会加  1(Eden 区->Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold  来设置。

####  方法区

方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

> 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。



**运行时常量池**

运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表（用于存放编译期生成的各种字面量和符号引用），class文件中常量池保存的是字符串常量，类和接口名字，字段名，和其他一些在class中引用的常量。每个class都有一份。

运行时常量池保存的是从class文件常量池构建的静态常量引用和符号引用。每个class都有一份。

字符串常量池保存的是“字符”的实例，供运行时常量池引用。

> 1. JDK1.7之前运行时常量池包含字符串常量池存放在方法区, 此时hotspot虚拟机对方法区的实现为永久代
> 2. JDK1.7 字符串常量池被从方法区拿到了堆中, 这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区, 也就是hotspot中的永久代 。
> 3. JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)。



**直接内存**

直接内存并不是 JVM 运行时数据区的一部分, 但也会被频繁的使用。在 JDK 1.4 引入的 NIO 提供了基于 Channel 与 Buffer 的 IO 方式, 它可以使用 Native 函数库直接分配堆外内存, 然后使用DirectByteBuffer 对象作为这块内存的引用进行操作, 这样就避免了在 Java堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。



### OOM与SOF的区别

两个都是由于内存不足导致的。

OOM 是OUT OF MEMORY的简称，是因为栈的大小不足，想要继续扩展的时候，但是由于JAVA虚拟机的可用内存不足导致的。

SOF是 Stack Over Flow的简称。是因为方法执行的时候，创建新的栈帧，但是虚拟机栈的内存不足以放下新的栈帧导致的。



### 说一下堆内存中对象的分配的基本策略

![image-20210721015948415](Java面试总结.assets/image-20210721015948415.png)

 **对象优先在 eden 区分配**

大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC.

**大对象直接进入老年代**

为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。

**长期存活的对象将进入老年代**

既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。

如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold  来设置。



![image-20210721022718562](Java面试总结.assets/image-20210721022718562.png)

### 如何判断对象是否死亡?(两种方法)

 **引用计数法**

给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。

**可能出现的问题：循环引用**

**可达性分析算法**

这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所⾛过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

![image-20210721020624850](Java面试总结.assets/image-20210721020624850.png)

### GC ROOT对象都有哪些？

- 当前正在被调用的方法里局部变量引用的对象，即虚拟机栈的**局部变量**表中引用的对象；
- 方法区中**静态变量**引用的对象；
- 方法区中**常量**引用的对象；
- 本地方法栈中**Native方法引用的对象**；

### 介绍一下强引用,软引用,弱引用,虚引用？

**强引用(StrongReference)**

以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空 间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也**不会靠随意回收具有强引用的对象**来解决内存不足问题。

 **软引用(SoftReference)** 

如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，**如果内存空间不足了，就会回收这些对象的内存。**只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。

**弱引用(WeakReference)** 

如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，**不管当前内存空间足够与否，都会回收它的内存。**不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。

**虚引用（PhantomReference）**
"虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，**在任何时候都可能被垃圾回收**。

虚引用需要 PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。

> 虚引用与软引用和弱引用的一个区别在于：` 虚引用必须和引用队列（ReferenceQueue）联合使用。`当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。`程序可以通过判断引用队列中是 否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收`。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。



### JVM什么时候触发YGC和FGC

  YGC ：对新生代堆进行gc。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。

  FGC ：全堆范围的gc。默认堆空间使用到达80%(可调整)的时候会触发fgc。以我们生产环境为例，一般比较少会触发fgc，有时10天或一周左右会有一次。

**什么时候执行YGC和FGC**

1. **YGC的时机：** edn空间不足

2. **FGC的时机：**

   1. old空间不足；

   2. perm空间不足；

   3. 显示调用System.gc() ，包括RMI等的定时触发;

   4. YGC时的悲观策略；

   5. dump live的内存信息时(jmap –dump:live)。



###  垃圾收集有哪些算法？

#### 标记-清除算法

该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：
1. 效率问题
2. 空间问题（标记清除后会产生大量不连续的碎片）

![image-20210721021840532](Java面试总结.assets/image-20210721021840532.png)

####  复制算法

为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。

![image-20210721021929713](Java面试总结.assets/image-20210721021929713.png)

#### 标记-整理算法

根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

![image-20210721022550976](Java面试总结.assets/image-20210721022550976.png)



####  分代收集算法

当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

> 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。



### 常见的垃圾回收器有那些?

![img](Java面试总结.assets/1218593-20200617151347151-1115053251.webp)



#### Serial 收集器

新生代采用复制算法，老年代采用标记-整理算法。

它是一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）。

下图展示了Serial 收集器（老年代采用Serial Old收集器）的运行过程:

![img](Java面试总结.assets/1218593-20200617151346143-185948479.webp)



#### ParNew 收集器

**ParNew收集器就是Serial收集器的多线程版本**，它也是一个新生代收集器。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。

ParNew收集器的工作过程如下图（老年代采用Serial Old收集器):

![img](Java面试总结.assets/1218593-20200617151346313-1618842335.webp)



#### Parallel Scavenge 收集器

Parallel Scavenge 收集器也是使用**复制**算法的多线程收集器。

Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。

使用 java -XX:+PrintCommandLineFlags -version 命令查看：

```java
-XX:InitialHeapSize=262921408 -XX:MaxHeapSize=4206742528 -
XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -
XX:+UseCompressedOops -XX:+UseParallelGC
java version "1.8.0_211"
Java(TM) SE Runtime Environment (build 1.8.0_211-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)
```

JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old

Parallel Old收集器的工作流程与Parallel Scavenge相同，这里给出Parallel Scavenge/Parallel Old收集器配合使用的流程图：

<img src="Java面试总结.assets/image-20210721024446626.png" alt="image-20210721024446626" style="zoom: 67%;" />



#### Serial Old收集器

Serial Old 是 Serial收集器的老年代版本，它同样是一个**单线程**收集器，使用“**标记-整理**”（Mark-Compact）算法。

####  Parallel Old 收集器

Parallel Scavenge 收集器的老年代版本。使用**多线程和“标记-整理”算法**。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。

#### CMS 收集器

CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为⽬标的收集器。它非常符合在注重用户体验的应用上使用。

从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- **初始标记（CMS initial mark）：**仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。
- **并发标记（CMS concurrent mark）：**进行GC Roots Tracing的过程，在整个过程中耗时最长。
- **重新标记（CMS remark）：**为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要 “Stop The World”。
- **并发清除（CMS concurrent sweep）**

![img](Java面试总结.assets/1218593-20200617151346793-1876462710.webp)

从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。

但是它有下面三个明显的缺点：

- 对 CPU 资源敏感；
- 无法处理浮动垃圾；（CMS并发清理阶段用户线程运行产生的新的垃圾）
- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。



#### G1 收集器

G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征。

被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：

- 并行与并发：`G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间`。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
- 分代收集：`虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念`。
- 空间整合：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。`G1把Java堆分为多个Region，就是“化整为零”。`
- **可预测的停顿：**这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，`能让使用者明确指定在一个长度为 M 毫秒的时间片段内`。

G1收集器的运作大致可划分为以下几个步骤：

- **初始标记（Initial Marking）** 仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程，但耗时很短。
- **并发标记（Concurrent Marking）** 从GC Root 开始对堆中对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。
- **最终标记（Final Marking）** 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。
- **筛选回收（Live Data Counting and Evacuation）** 首先对各个Region中的回收价值和成本进行排序，根据用户所期望的GC 停顿是时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

![img](Java面试总结.assets/1218593-20200617151346949-1522911316.webp)



####  ZGC 收集器

GC是java主要优势之一。 然而, 当GC停顿太长, 就会开始影响应用的响应时间。 消除或者减少GC停顿时长, java将对更广泛的应用场景是一个更有吸引力的平台。 此外, 现代系统中可用内存不断增长,用户和程序员希望JVM能够以高效的方式充分利用这些内存, 并且无需长时间的GC暂停时间。

ZGC, A Scalable Low-Latency Garbage Collector(Experimental)ZGC, 这应该是JDK11最为瞩目的特性, 没有之一。 但是后面带了Experimental,说明这还不建议用到生产环境。 

ZGC 是一个并发, 基于region, 压缩型的垃圾收集器, 只有root扫描阶段会STW(stop the world), 因此GC停顿时间不会随着堆的增长和存活对象的增长而变长。

ZGC 与  ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。在 ZGC 中出现 Stop The World 的情况会更少！

**优势：**

- GC暂停时间不会超过10ms；
- 既能处理几百兆的小堆, 也能处理几个T的大堆(OMG)；
- 和G1相比, 应用吞吐能力不会下降超过15%；
- 为未来的GC功能和利用colord指针以及Load barriers优化奠定基础；
- 初始只支持64位系统

ZGC的设计目标是：支持TB级内存容量， 暂停时间低（<10ms） ， 对整个程序吞吐量的影响小于15%。 将来还可以扩展实现机制， 以支持不少令人兴奋的功能， 例如多层堆（即热对象置于DRAM和冷对象置于NVMe闪存） ，或压缩堆。



### 查看 Java8 的默认 GC

**1. cmd命令行查看Java8的GC：**

```java
java -XX:+PrintCommandLineFlags -version
```

结果如下：

```bash
-XX:InitialHeapSize=132397312 // JVM默认初始化堆大小
-XX:MaxHeapSize=2118356992 //JVM堆的默认最大值
-XX:+PrintCommandLineFlags 
-XX:+UseCompressedClassPointers 
-XX:+UseCompressedOops 
-XX:-UseLargePagesIndividualAllocation 
-XX:+UseParallelGC //Java8使用的GC类型
java version "1.8.0_20" //使用的java版本
Java(TM) SE Runtime Environment (build 1.8.0_20-b26)
Java HotSpot(TM) 64-Bit Server VM (build 25.20-b23, mixed mode)
```

结果分析：由结果可以看出Java8的GC情况是：-XX:+UseParallelGC，即Parallel Scavenge（新生代） + Parallel Old（老生代），实际上几个主流Java版本的GC情况如下：

- jdk1.7 默认垃圾收集器Parallel Scavenge（新生代【标记-复制算法】）+Parallel Old（老年代【标记整理算法】）
- jdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）
- jdk1.9 默认垃圾收集器G1【从局部(两个Region之间)来看是基于"标记—复制"算法实现，从整体来看是基于"标记-整理"算法实现】



### JVM 类加载机制

JVM 类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。

![image-20210721141535764](Java面试总结.assets/image-20210721141535764.png)

**加载：**

加载是类加载过程中的一个阶段， 这个阶段会在**内存中生成一个代表这个类的 java.lang.Class 对象， 作为方法区这个类的各种数据的入口。**注意这里不一定非得要从一个 Class 文件获取，这里既可以从 ZIP 包中读取（比如从 jar 包和 war 包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将 JSP 文件转换成对应的 Class 类）。

**验证：**

这一阶段的主要目的是**为了确保 Class 文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。**

**准备：**

准备阶段是正式**为类变量分配内存并设置类变量的初始值**阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为：实际上变量 v 在准备阶段过后的初始值为 0 而不是 8080， 将 v 赋值为 8080 的 put static 指令是程序被编译后， 存放于类构造器方法之中。
但是注意如果声明为：

```java 
public static final int v = 8080;
```

在编译阶段会为 v 生成 ConstantValue 属性，在准备阶段虚拟机会根据 ConstantValue 属性将 v赋值为 8080。

**解析：**

**解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。**



**符号引用：**

符号引用就是 class 文件中的：

CONSTANT_Class_info

CONSTANT_Field_info

CONSTANT_Method_info  等类型的常量。

符号引用与虚拟机实现的布局无关， 引用的目标并不一定要已经加载到内存中。 各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在 Java 虚拟机规范的 Class 文件格式中。

**直接引用：**  

直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。

**初始化：** 

初始化是类加载过程的最后一步，到了此阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，类变量已经被赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序指定的主观计划去初始化类变量和其他资源，或者可以从另一个角度来表达：初始化阶段是执行类构造器`<clinit>()`方法的过程。

**类构造器：** 

初始化阶段是执行类构造器方法的过程。 方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证子方法执行之前，父类的方法已经执行完毕， 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成`<clinit>()`方法。

**注意以下几种情况不会执行类初始化：**  

1. 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。
2. 定义对象数组，不会触发该类的初始化。
3. 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。
4. 通过类名获取 Class 对象，不会触发类的初始化。
5. 通过 Class.forName 加载指定类时，如果指定参数 initialize 为 false 时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。
6. 通过 ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。



### 类加载器

虚拟机设计团队把加载动作放到 JVM 外部实现，以便让应用程序决定如何获取所需的类， JVM 提供了 3 种类加载器：  

**启动类加载器(Bootstrap ClassLoader)**  

负责加载 JAVA_HOME\lib 目录中的， 或通过-Xbootclasspath 参数指定路径中的， 且被虚拟机认可（按文件名识别， 如 rt.jar） 的类。

**扩展类加载器(Extension ClassLoader)**

负责加载 JAVA_HOME\lib\ext 目录中的，或通过 java.ext.dirs 系统变量指定路径中的类库。

**应用程序类加载器(Application ClassLoader)**

负责加载用户路径（classpath）上的类库。JVM 通过双亲委派模型进行类的加载， 当然我们也可以通过继承 java.lang.ClassLoader实现自定义的类加载器。

<img src="Java面试总结.assets/image-20210721143446092.png" alt="image-20210721143446092" style="zoom: 50%;" />

### 双亲委派

当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class）， 子类加载器才会尝试自己去加载。

采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样的一个 Object 对象。

![image-20210721143802529](Java面试总结.assets/image-20210721143802529.png)



### 你知道哪些破坏双亲委派的情况？

#### Spring 中的类加载机制 - ClassLoader

OverridingClassLoader 是 Spring 自定义的类加载器，默认会先自己加载(excludedPackages 或 excludedClasses 例外)，只有加载不到才会委托给双亲加载，这就破坏了 JDK 的双亲委派模式。

#### JDBC为什么要破坏双亲委派模型

在JDBC 4.0之后实际上我们不需要再调用Class.forName来加载驱动程序了，我们只需要把驱动的jar包放到工程的类加载路径里，那么驱动就会被自动加载。

这个自动加载采用的技术叫做SPI，数据库驱动厂商也都做了更新。可以看一下jar包里面的META-INF/services目录，里面有一个java.sql.Driver的文件，文件里面包含了驱动的全路径名。

使用上，我们只需要通过下面一句就可以创建数据库的连接：

```java
Connection con = DriverManager.getConnection(url , username , password ) ;   
```

JDBC的Driver接口定义在JDK中，其实现由各个数据库的服务商来提供，比如MySQL驱动包。DriverManager 类中要加载各个实现了Driver接口的类，然后进行管理，但是 DriverManager 位于 $JAVA_HOME中jre/lib/rt.jar 包，由BootStrap类加载器加载，而其 Driver 接口的实现类是位于服务商提供的 Jar 包，**根据类加载机制，当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。**也就是说BootStrap类加载器还要去加载 jar 包中的 Driver 接口的实现类。我们知道，BootStrap 类加载器默认只负责加载 $JAVA_HOME 中 jre/lib/rt.jar 里所有的 class ，所以需要由子类加载器去加载 Driver 实现，这就破坏了双亲委派模型。

#### Tomcat 如何破坏双亲委派模型?

**每个Tomcat的webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器。**

事实上，tomcat之所以造了一堆自己的classloader，大致是出于下面三类目的：

- 对于各个 `webapp`中的 `class`和 `lib`，需要相互隔离，不能出现一个应用中加载的类库会影响另一个应用的情况，而对于许多应用，需要有共享的lib以便不浪费资源。
- 与 `jvm`一样的安全性问题。使用单独的 `classloader`去装载 `tomcat`自身的类库，以免其他恶意或无意的破坏；
- 热部署。 `tomcat`修改文件不用重启就自动重新装载类库。



### Java对象创建过程

1. **类加载检查**

   虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

2. **分配内存**

   在类加载检查通过后，接下来虚拟机将为新生对象分配内存。

   一种办法“指针碰撞”、一种办法“空闲列表”，最常用的办法“本地线程分配缓冲(TLAB)”

3. **初始化零值**

   内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）

4. **设置对象头**

   初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

5. **执行 init 方法**

   在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始， <init>  方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init>  方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

   

- **指针碰撞**
  - 适用场合：堆内存规整（即没有内存碎片）的情况下
  - 原理：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界值指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可
  - GC收集器：Serial、ParNew
- **空闲列表**
  - 适用场合：堆内存不规整的情况下
  - 原理：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例（这一块儿可以类比memcached的slab模型），最后更新列表记录。
  - GC收集器：CMS
- 注意
  - 选择以上两种方式中的哪一种，取决于Java堆内存是否规整
  - Java堆内存是否规整，取决于GC收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的。



**内存分配并发问题**

 堆内存是各个线程的共享区域，所以在操作堆内存的时候，需要处理并发问题。处理的方式有两种：

- CAS+失败重试
  -  CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。具体的做法与AtomicInteger的getAndSet(int newValue)方法的实现方式类似。
- TLAB（Thread Local Allocation Buffer）

- - 原理：为每一个线程预先在Eden区分配一块儿内存，JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配

- - -XX:+/-UseTLAB：是否使用TLAB
  - -XX:TLABWasteTargetPercent设置TLAB可占用的Eden区的比率，默认为1%
  - JVM会根据以下三个条件来给每个线程分配合适大小的TLAB
    - -XX:TLABWasteTargetPercent
    - 线程数量
    - 线程是否频繁分配对象

- - -XX:PrintTLAB：查看TLAB的使用情况



### Java的对象结构

**Java对象由三个部分组成：对象头、实例数据、对齐填充。**

- 对象头：由两部分组成，第一部分存储对象自身的运行时数据：哈希码、GC分代年龄、锁标识状态、线程持有的锁、偏向线程ID（一般占32/64 bit）。第二部分是指针类型，指向对象的类元数据类型（即对象代表哪个类）。如果是数组对象，则对象头中还有一部分用来记录数组长度。
- 实例数据：用来存储对象真正的有效信息（包括父类继承下来的和自己定义的）
- 对齐填充：JVM要求对象起始地址必须是8字节的整数倍（8字节对齐  )

### 对象头

对象头包括三部分：

![image-20210804110734461](Java面试总结.assets/image-20210804110734461.png)

- **markword**
  第一部分`markword`，用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为“MarkWord”。

  **markword：**

  ![image-20210724002756631](Java面试总结.assets/image-20210724002756631.png)

- **klass**
  **对象头的另外一部分是klass类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例**
  
- **数组长度（只有数组对象有）**，如果对象是一个数组，那在对象头中还必须有一块数据用于记录数组长度。



### 对象如何晋升到老年代？

对象优先在新生代的 eden 区分配内存，但是也并不绝对，下面几种情况对象会晋升到老年代。

- 大对象直接进入老年代。比如很长的字符串，或者很大的数组等。
- **长期存活的对象进入老年代。**在堆中分配内存的对象，其内存布局的对象头中（Header）包含了 GC 分代年龄标记信息。如果对象在 eden 区出生，那么它的 GC 分代年龄会初始值为 1，每熬过一次 Minor GC 而不被回收，这个值就会增加 1 岁。**当它的年龄到达一定的数值时（jdk1.7 默认是 15 岁），就会晋升到老年代中。**
- **动态对象年龄判定。**当 Survivor 空间中相同年龄所有对象的大小总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，而不需要达到默认的分代年龄。



### 什么时候会触发Young ？FullGC？

**触发MinorGC(Young GC)**

  虚拟机在进行minorGC之前会判断老年代最大的可用连续空间是否大于新生代的所有对象总空间

  1、如果大于的话，直接执行minorGC

  2、如果小于，判断是否开启HandlerPromotionFailure，没有开启直接FullGC

  3、如果开启了HanlerPromotionFailure, JVM会判断老年代的最大连续内存空间是否大于历次晋升的大小，如果小于直接执行FullGC

  4、如果大于的话，执行minorGC

**触发FullGC**

- **老年代空间不足**

​     如果创建一个大对象，Eden区域当中放不下这个大对象，会直接保存在老年代当中，如果老年代空间也不足，就会触发Full GC。为了避免这种情况，最好就是不要创建太大的对象。

- **持久代空间不足**

​    如果有持久代空间的话，系统当中需要加载的类，调用的方法很多，同时持久代当中没有足够的空间，就出触发一次Full GC。

- **YGC出现promotion failure**

​    promotion failure发生在Young GC, 如果Survivor区当中存活对象的年龄达到了设定值，会就将Survivor区当中的对象拷贝到老年代，如果老年代的空间不足，就会发生promotion failure， 接下去就会发生Full GC.

- **统计YGC发生时晋升到老年代的平均总大小大于老年代的空闲空间**

​    在发生YGC是会判断，是否安全，这里的安全指的是，当前老年代空间可以容纳YGC晋升的对象的平均大小，如果不安全，就不会执行YGC,转而执行Full GC。

- **显示调用System.gc**

除了以上几种状况外，对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。



### 排查内存故障的方法

**对于还在正常运行的系统：**

1. top命令：Linux命令。可以查看实时的内存使用情况。  
2. 可以使用jmap来查看JVM中各个区域的使用情况
3. 可以通过jstack来查看线程的运行情况，比如哪些线程阻塞、是否出现了死锁
4. 可以通过jstat命令来查看垃圾回收的情况，特别是fullgc，如果发现fullgc比较频繁，那么就得进行调优了
5. 通过各个命令的结果，或者jvisualvm等工具来进行分析
6. 首先，初步猜测频繁发送fullgc的原因，如果频繁发生fullgc但是又一直没有出现内存溢出，那么表示fullgc实际上是回收了很多对象了，所以这些对象最好能在younggc过程中就直接回收掉，避免这些对象进入到老年代，对于这种情况，就要考虑这些存活时间不长的对象是不是比较大，导致年轻代放不下，直接进入到了老年代，尝试加大年轻代的大小，如果改完之后，fullgc减少，则证明修改有效
7. 同时，还可以找到占用CPU最多的线程，定位到具体的方法，优化这个方法的执行，看是否能避免某些对象的创建，从而节省内存

**对于已经发生了OOM的系统：**

1. 一般生产系统中都会设置当系统发生了OOM时，生成当时的dump文件（-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base）
2. 我们可以利用jsisualvm等工具来分析dump文件
3. 根据dump文件找到异常的实例对象，和异常的线程（占用CPU高），定位到具体的代码
4. 然后再进行详细的分析和调试

总之，调优不是一蹴而就的，需要分析、推理、实践、总结、再分析，最终定位到具体的问题



### jdk命令行工具 

-  jps（jvm process status）：查看所有java进程启动类、传入参数和java虚拟机参数等信息。 
  -  jps：显示虚拟机执行主类名称以及这些进程的本地虚拟机唯一 ID（Local Virtual Machine Identifier,LVMID）。 
  -  jps -q ：只输出进程的本地虚拟机唯一 ID。 
  -  jps -l:输出主类的全名，如果进程执行的是 Jar 包，输出 Jar 路径。 
  -  jps -v：输出虚拟机进程启动时 JVM 参数。 
  -  jps -m：输出传递给 Java 进程 main() 函数的参数。 
-  jstat （JVM Statistics Monitoring Tool）: 用于监视虚拟机各种运行状态信息的命令行工具。它可以显示虚拟机进程中的类信息、内存、垃圾收集、JIT 编译等运行数据，在没有 GUI，只提供了纯文本控制台环境的服务器上，它将是运行期间定位虚拟机性能问题的首选工具。 
  -  jstat 命令使用格式：
     jstat - [-t] [-h] [ []]
     比如 jstat -gc -h3 31736 1000 10表示分析进程 id 为 31736 的 gc 情况，每隔 1000ms 打印一次记录，打印 10 次停止，每 3 行后打印指标头部。 
  -  jstat -class vmid ：显示 ClassLoader 的相关信息； 
  -  jstat -compiler vmid ：显示 JIT 编译的相关信息； 
  -  jstat -gc vmid ：显示与 GC 相关的堆信息； 
  -  jstat -gccapacity vmid ：显示各个代的容量及使用情况； 
  -  jstat -gcnew vmid ：显示新生代信息； 
  -  jstat -gcnewcapcacity vmid ：显示新生代大小与使用情况； 
  -  jstat -gcold vmid ：显示老年代和永久代的行为统计，从jdk1.8开始,该选项仅表示老年代，因为永久代被移除了； 
  -  jstat -gcoldcapacity vmid ：显示老年代的大小； 
  -  jstat -gcpermcapacity vmid ：显示永久代大小，从jdk1.8开始,该选项不存在了，因为永久代被移除了； 
  -  jstat -gcutil vmid ：显示垃圾收集信息； 
  -  另外，加上 -t参数可以在输出信息上加一个 Timestamp 列，显示程序的运行时间。 
-  jinfo (Configuration Info for Java) :输出当前 jvm 进程的全部参数和系统属性 (第一部分是系统的属性，第二部分是 JVM 的参数)。 
  -  jinfo -flag name vmid :输出对应名称的参数的具体值。 
  -  使用 jinfo 可以在不重启虚拟机的情况下，可以动态的修改 jvm 的参数。jinfo -flag [+|-]name vmid 开启或者关闭对应名称的参数。 
-  jmap (Memory Map for Java) :生成堆转储快照; 
-  jhat (JVM Heap Dump Browser ) : 用于分析 heapdump 文件，它会建立一个 HTTP/HTML 服务器，让用户可以在浏览器上查看分析结果; 
-  jstack (Stack Trace for Java):生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。 
  -  生成线程快照的目的主要是定位线程长时间出现停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者在等待些什么资源。 

 **可视化分析工具** 

-  jconsole 检测死锁 显示内存信息，细化到Eden区，survivor区的详细情况。 可强制执行gc。 
-  Visual VM，能够监控线程，内存情况，查看方法的CPU时间和内存中的对象，已被GC的对象，反向查看分配的堆栈(如100个String对象分别由哪几个对象分配出来的).







## MySQL

### Drop、Delete、TRUNCATE的区别

**drop**

- **drop直接删掉表；**
- **drop语句将表所占用的空间全释放掉。**
- **drop语句将删除表的结构被依赖的约束（constrain)，触发器（trigger)索引（index)**；依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。

**delete**

- delete删除表中数据，可以加where字句
- delete操作不会减少表或索引所占用的空间。
- 范围：可以是table和view。
- **只删除数据，而不删除表的结构（定义）**
- delete语句为DML（Data Manipulation Language),这个操作会被放到 rollback segment中,事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。
- delete语句每次删除一行，并在事务日志中为所删除的每行记录一项。

**truncate**

- **truncate删除表中数据，再插入时自增长id又从1开始, 只删除数据，而不删除表的结构（定义）**
- truncate、drop是DDL（Data Define Language)，操作立即生效，原数据不放到 rollback segment中，不能回滚
- Truncate table 表名  速度快,而且效率高，因为: truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。
- 对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE

**效率方面：drop > truncate > delete**



### MyISAM和InnoDB区别

1. **是否支持行级锁 :** MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
2. **是否支持事务和崩溃后的安全恢复**： MyISAM 强调的是性能，每次查询具有原子性，其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。
3. **是否支持外键：** MyISAM不支持，而InnoDB支持。
4. **是否支持MVCC ：**仅 InnoDB 支持。应对高并发事务， MVCC比单纯的加锁更高效；MVCC只在 READ COMMITTED  和 REPEATABLE READ  两个隔离级别下工作；MVCC可以使用 乐观(optimistic)锁 和 悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。



### 索引

MySQL官方对索引的定义为：

**索引（index）是帮助MySQL高效获取数据的数据结构（有序）**。在数据之外，数据库系统还维护者满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。



![image-20210723003707782](Java面试总结.assets/image-20210723003707782.png)

左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找快速获取到相应数据。一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。**索引是数据库中用来提高性能的最常用的工具。**

**MyISAM: B+Tree叶节点的data域存放的是数据记录的地址**。**索引文件和数据文件是分离的，**在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为**“非聚簇索引”。**

**InnoDB: 其数据文件本身就是索引文件。**其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为**“聚簇索引（或聚集索引）**”。而其余的索引都作为**辅助索引**，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再⾛一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

![image-20210927161446528](Java面试总结.assets/image-20210927161446528.png)



### 索引的好处与坏处？

**优势：**

1） 类似于书籍的目录索引，**提高数据检索的效率**，降低数据库的IO成本。

2） 通过索引列对数据进行排序，降低数据排序的成本，降低CPU的消耗。

**劣势：**

1） 实际上索引也是一张表，该表中保存了主键与索引字段，并指向实体类的记录，所以索引列也是要**占用空间**的。

2） **虽然索引大大提高了查询效率，同时却也降低更新表的速度**，如对表进行INSERT、UPDATE、DELETE。因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。



### 索引的结构

**MySQL索引使用的数据结构主要有B+Tree索引 和 哈希索引 。**对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

> **为什么MySQL 没有使用哈希表作为索引的数据结构呢？**
>
> 1. Hash 冲突问题。
>
> 2. Hash 索引不支持顺序和范围查询。

索引是在MySQL的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型的。MySQL目前提供了以下4种索引：

- BTREE 索引 ： 最常见的索引类型，大部分索引都支持 B 树索引。
- HASH 索引：只有Memory引擎支持 ， 使用场景简单 。
- R-tree 索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。
- Full-text （全文索引） ：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从Mysql5.6版本开始支持全文索引。

<center><b>MyISAM、InnoDB、Memory三种存储引擎对各种索引类型的支持</b></center>

| 索引        | InnoDB引擎      | MyISAM引擎 | Memory引擎 |
| ----------- | --------------- | ---------- | ---------- |
| BTREE索引   | **支持**        | 支持       | 支持       |
| HASH 索引   | 不支持          | 不支持     | 支持       |
| R-tree 索引 | 不支持          | 支持       | 不支持     |
| Full-text   | 5.6版本之后支持 | 支持       | 不支持     |



### B 树和 B+ 树

B 树也称 B-树,全称为 **多路平衡查找树** ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 `Balanced` （平衡）的意思。目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。

#### B 树的结构

BTree又叫多路平衡搜索树，一颗m叉的BTree特性如下：

- 树中每个节点最多包含m个孩子。
- 除根节点与叶子节点外，每个节点至少有[ceil(m/2)]个孩子。
- 若根节点不是叶子节点，则至少有两个孩子。
- 所有的叶子节点都在同一层。
- 每个非叶子节点由n个key与n+1个指针组成，其中[ceil(m/2)-1] <= n <= m-1 

以5叉BTree为例，key的数量：公式推导[ceil(m/2)-1] <= n <= m-1。所以 2 <= n <=4 。当n>4时，中间节点分裂到父节点，两边节点分裂。

插入 C N G A H E K Q M F W L T Z D P R X Y S 数据为例。

演变过程如下：

1). 插入前4个字母 C N G A 

![1555944126588](Java面试总结.assets/1555944126588.png) 

2). 插入H，n>4，中间元素G字母向上分裂到新的节点

![1555944549825](Java面试总结.assets/1555944549825.png) 

3). 插入E，K，Q不需要分裂

![1555944596893](Java面试总结.assets/1555944596893.png) 

4). 插入M，中间元素M字母向上分裂到父节点G

![1555944652560](Java面试总结.assets/1555944652560.png) 

5). 插入F，W，L，T不需要分裂

![1555944686928](Java面试总结.assets/1555944686928.png) 

6). 插入Z，中间元素T向上分裂到父节点中 

![1555944713486](Java面试总结.assets/1555944713486.png) 

7). 插入D，中间元素D向上分裂到父节点中。然后插入P，R，X，Y不需要分裂

![1555944749984](Java面试总结.assets/1555944749984.png) 

8). 最后插入S，NPQR节点n>5，中间节点Q向上分裂，但分裂后父节点DGMT的n>5，中间节点M向上分裂

![1555944848294](Java面试总结.assets/1555944848294.png) 

到此，该BTREE树就已经构建完成了， BTREE树 和 二叉树 相比， 查询数据的效率更高， 因为对于相同的数据量来说，BTREE的层级结构比二叉树小，因此搜索速度快。



#### B+ 树的结构

B+Tree为BTree的变种，B+Tree与BTree的区别为：

1. n叉B+Tree最多含有n个key，而BTree最多含有n-1个key。
2. B+Tree的叶子节点保存所有的key信息，依key大小顺序排列。

3. 所有的非叶子节点都可以看作是key的索引部分。

![image-20210723020311032](Java面试总结.assets/image-20210723020311032.png)

#### B 树和B+树两者有何异同呢？

- B 树的所有节点既存放键(key) 也存放数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
- B 树的叶子节点都是独立的，B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
- B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。
- `B+树中，层数少，只在叶子节点存数据的特点就能极大的保证磁盘IO次数少，效率高`

#### MySQL中的B+Tree

MySql索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能。

**innodb B+Tree的叶子节点是一个页，每个叶子节点之间是一个双向链表的结构。**

MySQL中的 B+Tree 索引结构示意图: 

![img](Java面试总结.assets/1313648-20210722094837743-1354658103.png)



### 为什么MySQL数据库要用B+树存储索引？而不用红黑树、Hash、B树？

**红黑树：**如果在内存中，红黑树的查找效率比B树更高，但是涉及到磁盘操作，B树就更优了。因为红黑树是二叉树，数据量大时树的层数很高，从树的根结点向下寻找的过程，每读1个节点，都相当于一次IO操作，因此红黑树的I/O操作会比B树多的多。

**hash 索引：**如果只查询单个值的话，hash 索引的效率非常高。但是 hash 索引有几个问题：1）不支持范围查询；2）不支持索引值的排序操作；3）不支持联合索引的最左匹配规则。

**B树索引：**B树索相比于B+树，在进行范围查询时，需要做局部的中序遍历，可能要跨层访问，跨层访问代表着要进行额外的磁盘I/O操作；另外，B树的非叶子节点存放了数据记录的地址，会导致存放的节点更少，树的层数变高。



### 索引分类

根据索引的存储方式来划分，索引可以分为**聚簇索引**和**非聚簇索引**。聚簇索引的特点是叶子节点包含了完整的记录行，而非聚簇索引的叶子节点只有索引字段和主键的键值。

**聚簇索引也叫聚集索引，**它实际上并不是一种单独的索引类型，而是一种数据存储方式，聚簇索引的叶子节点保存了一行记录的所有列信息。也就是说，聚簇索引的叶子节点中，包含了一个完整的记录行。聚集索引是根据数据行的键值在表中排序存储数据行。每个表只能有一个聚集索引。

**非聚簇索引也叫辅助索引、普通索引，**它的叶子节点只包含一个主键值，通过非聚簇索引查找记录要先找到主键，然后通过主键再到聚簇索引中找到对应的记录行，这个过程被称为**回表**。

> 聚簇索引按照如下规则创建：
>
> - 当定义了主键后，InnoDB会利用主键来生成其聚簇索引；
> - 如果没有主键，InnoDB会选择一个非空的唯一索引来创建聚簇索引；
> - 如果这也没有，InnoDB会隐式的创建一个自增的列来作为聚簇索引。

根据聚簇索引和非聚簇索引还能继续下分还能分为普通索引、覆盖索引、唯一索引以及联合索引等。

> 1） 单值索引 ：即一个索引只包含单个列，一个表可以有多个单列索引
>
> 2） 唯一索引 ：索引列的值必须唯一，但允许有空值
>
> 3） 复合索引 ：即一个索引包含多个列



**非聚集索引一定回表查询吗?**

**非聚集索引不一定回表查询。**

> 试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。
>
> 那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。

```text
 SELECT name FROM table WHERE name='guang19';
```



### 什么是回表查询？

InnoDB 中，对于主键索引，只需要走一遍主键索引的查询就能在叶子节点拿到数据。

而对于普通索引，叶子节点存储的是 key + 主键值，因此需要再走一次主键索引，通过主键索引找到行记录，这就是所谓的回表查询，先定位主键值，再定位行记录。



### 覆盖索引？

**如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”**。我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作。

**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。**

> 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。
>
> 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。



### MySQL 如何为表字段添加索引？

1.添加 PRIMARY KEY（主键索引）

```sql
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )
```

2.添加 UNIQUE(唯一索引)

```sqlite
ALTER TABLE `table_name` ADD UNIQUE ( `column` )
```

3.添加 INDEX(普通索引)

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
```

4.添加 FULLTEXT(全文索引)

```sql
ALTER TABLE `table_name` ADD FULLTEXT ( `column`)
```

5.添加多列索引

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```



### 索引的设计原则？

**1. 选择合适的字段创建索引：**

- **不为 NULL 的字段** ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。
- **被频繁查询的字段** ：我们创建索引的字段应该是查询操作非常频繁的字段。
- **被作为条件查询的字段** ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。
- **频繁需要排序的字段** ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
- **被经常频繁用于连接的字段** ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。
- **使用唯一索引，区分度越高，使用索引的效率越高。**

**2. 被频繁更新的字段应该慎重建立索引。**

虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。

**3. 尽可能的考虑建立联合索引而不是单列索引。**

因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。

**4. 注意避免冗余索引** 。

冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

**5. 考虑在字符串类型的字段上使用前缀索引代替普通索引。**

前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。

**6.  利用最左前缀**，N个列组合而成的组合索引，那么相当于是创建了N个索引，如果查询时where子句中使用了组成该索引的前几个字段，那么这条查询SQL可以利用组合索引来提升查询效率。

```java
创建复合索引:
	CREATE INDEX idx_name_email_status ON tb_seller(NAME,email,STATUS);
就相当于
	对name 创建索引 ;
	对name , email 创建了索引 ;
	对name , email, status 创建了索引 ;
```



### 如何避免索引失效？

1. **全值匹配 ，**对索引中所有列都指定具体值。
2. **单列索引和复合索引。**尽量使用复合索引，而少使用单列索引 。
3. **尽量使用覆盖索引，避免select ***
4. **最左前缀法则，**如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列。
5. **范围查询右边的列，不能使用索引 。**
6. **不要在索引列上进行运算操作， 索引将失效。**
7. **字符串不加单引号，造成索引失效。**在查询时，没有对字符串加单引号，MySQL的查询优化器，会自动的进行类型转换，造成索引失效。
8. **用 or 分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。**建议使用 union 替换 or 。
9. **以%开头的Like模糊查询，索引失效。**如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。
10. **如果MySQL评估使用索引比全表更慢，则不使用索引。**
11. **is  NULL ， is NOT NULL  <font color='red'>有时</font>索引失效。**
12. **in 走索引， not in 索引失效。**



### 使用索引的一些建议？

- 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引
- 避免 where 子句中对字段施加函数，这会造成无法命中索引。
- 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。
- 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes 视图来查询哪些索引从未被使用
- 在使用 limit offset 查询缓慢时，可以借助索引来提高性能
- 索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价自然也就水涨船高。对于插入、更新、删除等DML操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低DML操作的效率，增加相应操作的时间消耗。另外索引过多的话，MySQL也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但无疑提高了选择的代价。
- 使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的I/O效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升MySQL访问索引的I/O效率。



### MySQL事务？

**什么是事务?** 

事务是逻辑上的一组操作，要么都执行，要么都不执行。

**事物的四大特性(ACID)**

1. **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性（Consistency）：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
3. **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。



### MySQL并发事务带来的问题?

**脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

**丢失修改（Lost to modify）**: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。

**不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

**幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

### MySQL事务的隔离级别?

**READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

**READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。

**REPEATABLE-READ(可重复读)：**  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

**SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

| 隔离级别                     | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | ---- | ---------- | ---- |
| 读未提交（read-uncommitted） | 是   | 是         | 是   |
| 不可重复读（read-committed） | 否   | 是         | 是   |
| 可重复读（repeatable-read）  | 否   | 否         | 是   |
| 串行化（serializable）       | 否   | 否         | 否   |

**MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。**

我们可以通过 SELECT @@tx_isolation; 命令来查看。



### Innodb是如何实现事务的

Innodb通过Buffer Pool，LogBuffer，Redo Log，Undo Log来实现事务，以一个update语句为例：
1. Innodb在收到一个update语句后，会先根据条件找到数据所在的⻚，并将该⻚缓存在Buffer Pool
    中
2. 执行update语句，修改Buffer Pool中的数据，也就是内存中的数据
3. 针对update语句生成一个RedoLog对象，并存入LogBuffer中
4. 针对update语句生成undolog⽇志，用于事务回滚
5. 如果事务提交，那么则把RedoLog对象进行持久化，后续还有其他机制将Buffer Pool中所修改的
    数据⻚持久化到磁盘中
6. 如果事务回滚，则利用undolog⽇志进行回滚



### InnoDB可重复读隔离级别的底层实现原理

 *Repeatable Read*（可重复读）：一个事务在执行过程中可以看到其他事务已经提交的新插入的记录（读已经提交的，其实是读早于本事务开始且已经提交的），但是不能看到其他事务对已有记录的更新（即晚于本事务开始的），并且，该事务不要求与其他事务是“可串行化”的。

 使用MVCC（多版本并发控制）。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。
在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。

  如果数据库并发控制引擎是单纯的封锁协议机制，则应该在读取数据的时候，判断数据项是不是其他事务更新过的。可是*InnoDB*没有这么做，而是通过如下方式，在*RR*隔离级别下为事务设置了一个“一致性读视图（即快照）”，之后读取数据，就是根据这个快照来获取，这样，就不能看到他晚于本事务的事务对已有记录的更新（更新生成新版本，必然不在旧的快照所限定的范围内）。



### MySQL的锁？

**MyISAM 和 InnoDB 存储引擎使用的锁：**

- MyISAM 采用表级锁(table-level locking)。
- InnoDB 支持行级锁(row-level locking)和表级锁，默认为行级锁。

**从对数据操作的类型分：**

1） 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响。

2） 写锁（排它锁）：当前操作没有完成之前，它会阻断其他写锁和读锁。

**锁的分类：**

**按锁粒度分类**

- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。
- **页级锁：**页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。因此，采取了折衷的页级锁，一次锁定相邻的一组记录。BDB 支持页级锁。

**锁级别分类**

- **共享锁（Share Lock）：**共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。

  共享锁：SELECT … LOCK IN SHARE MODE

- **排他锁（Exclusive Lock）：**排他锁又称写锁、独占锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。

  排他锁：SELECT … FOR UPDATE

- **意向锁（Intention Lock）：**意向锁是表级锁，是InnoDB存储引擎自己维护的，用户无法手动添加意向锁。

  其设计目的主要是为了加表锁时提升互斥判断的效率，加速检测表锁与行锁的冲突。

  InnoDB 意向锁分为：

  意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁；
  
  意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。
  
  ![img](Java面试总结.assets/v2-90562dae9e1e0570434f55935591f0dc_720w.jpg)



**InnoDB 存储引擎的锁的算法有三种：**

- Record lock：记录锁，单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap临键锁，锁定一个范围，包含记录本身

**MySQL锁优化建议：**

- 尽可能让所有数据检索都能通过索引来完成，避免无索引行锁升级为表锁。
- 合理设计索引，尽量缩小锁的范围
- 尽可能减少索引条件，及索引范围，避免间隙锁
- 尽量控制事务大小，减少锁定资源量和时间长度
- 尽可使用低级别事务隔离（但是需要业务层面满足需求）



### MySQL 基本架构概览?

如下图，整个MySQL Server由以下组成：

- Connection Pool : 连接池组件
- Management Services & Utilities : 管理服务和工具组件
- SQL Interface : SQL接口组件
- Parser : 查询分析器组件
- Optimizer : 优化器组件
- Caches & Buffers : 缓冲池组件
- Pluggable Storage Engines : 存储引擎
- File System : 文件系统

![image-20210723023021434](Java面试总结.assets/image-20210723023021434.png)

**1） 连接层**

最上层是一些客户端和链接服务，包含本地socket通信和大多数基于客户端/服务端工具实现的类似于 TCP/IP的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

**2） 服务层**

第二层架构主要完成大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化，部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如 过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定表的查询的顺序，是否利用索引等， 最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存，如果缓存空间足够大，这样在解决大量读操作的环境中能够很好的提升系统的性能。

**3） 引擎层**

存储引擎层， 存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API和存储引擎进行通信。不同的存储引擎具有不同的功能，这样我们可以根据自己的需要，来选取合适的存储引擎。

**4）存储层**

数据存储层， 主要是将数据存储在文件系统之上，并完成与存储引擎的交互。



###  一条SQL 语句在 MySQL 内部是如何执行的？

下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。

![image-20210806153835857](Java面试总结.assets/image-20210806153835857.png)

1. **客户端发送一条查询给服务器；**
2. **服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。否则进入下一阶段；**
3. **服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；**
4. **MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询；**
5. **将结果返回给客户端。**

- **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
- **查询缓存:** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
- **分析器:** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
- **优化器：** 按照 MySQL 认为最优的方案去执行。
- **执行器:** 执行语句，然后从存储引擎返回数据。

> - 查询语句的执行流程如下：
>
>   权限校验（如果命中缓存）---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
>
> - 更新语句执行流程如下：
>
>   分析器----》权限校验----》执行器---》引擎---redo log(prepare 状态---》binlog---》redo log(commit状态)



### SQL 语句的执行顺序

以下的每一步操作都会生成一个虚拟表，作为下一个处理的输入，在这个过程中，这些虚拟表对于用户都是透明的，只用最后一步执行完的虚拟表返回给用户，在处理过程中，没有的步骤会直接跳过。

以下为逻辑上的执行顺序：

<img src="Java面试总结.assets/image-20210806154028849.png" alt="image-20210806154028849" style="zoom: 50%;" align=left />

(1) from：对左表left-table和右表right-table执行笛卡尔积(a*b)，形成虚拟表VT1;

(2) on: 对虚拟表VT1进行on条件进行筛选，只有符合条件的记录才会插入到虚拟表VT2中;

(3) join: 指定out join会将未匹配行添加到VT2产生VT3,若有多张表，则会重复(1)~(3);

(4) where: 对VT3进行条件过滤，形成VT4, where条件是从左向右执行的;

(5) group by: 对VT4进行分组操作得到VT5;

(6) cube | rollup: 对VT5进行cube | rollup操作得到VT6;

(7) having: 对VT6进行过滤得到VT7;

(8) select: 执行选择操作得到VT8，本人看来VT7和VT8应该是一样的;

(9) distinct: 对VT8进行去重，得到VT9;

(10) order by: 对VT9进行排序，得到VT10;

(11) limit: 对记录进行截取，得到VT11返回给用户。

> on 条件应用于连表过滤，where 应用于on 过滤后的结果（有on的话），having 应用于分组过滤



### 视图？

**视图（View）是一种虚拟存在的表。**视图并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。通俗的讲，**视图就是一条SELECT语句执行后返回的结果集**。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上。

视图相对于普通的表的优势主要包括以下几项。

- **简单：**使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。
- **安全：**使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。
- **数据独立：**一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。



### 存储过程和函数 ？

**存储过程和函数是  事先经过编译并存储在数据库中的一段 SQL 语句的集合，**调用存储过程和函数可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。	

​	**存储过程和函数的区别在于函数必须有返回值，而存储过程没有。**

​	函数 ： 是一个有返回值的过程 ；

​	过程 ： 是一个没有返回值的函数 ；

### MySQL存储过程与事务transaction

Mysql 中，单个 Store Procedure(SP) 不是原子操作，而 oracle 则是原子的。如下的存储过程，即使语句2 失败，语句 1 仍然会被 commit 到数据库中：

```sql
create table testproc(id int(4) primary key, name varchar(100));
CREATE PROCEDURE test_proc_ins(
IN i_id INT,
IN i_name VARCHAR(100)
)
BEGIN
     INSERT INTO testproc VALUES (i_id, i_name);  -- 语句1
     INSERT INTO testproc VALUES (i_id, i_name);  -- 语句2（因为id为PK，此语句将出错）。
END;
```

 要使整个存储过程成为一个原子操作的办法是：在存储过程主体开始部分，指定开始一个事务。语句 2 失败，语句 1 不会被 commit 到数据库中，存储过程将会在调用时抛出一个异常。

```sql
CREATE PROCEDURE test_proc_ins(
IN i_id INT,
IN i_name VARCHAR(100)
)
BEGIN
start transaction; --整个存储过程指定为一个事务
      INSERT INTO testproc VALUES (i_id, i_name);
      INSERT INTO testproc VALUES (i_id+1, i_name); -- 这里把id+1，避免主键冲突
commit; -- 语句1。必须主动提交
END;
```

MySQL的存储过程在处理事务时如何回滚，首先使用SQLException捕获SQL错误，然后处理； 按照这个推论，我们必须在 MySQL 存储过程中捕获 SQL 错误，最后判断是回滚( ROLLBACK )还是提交(COMMIT)。

```sql
DROP PROCEDURE IF EXISTS  test_sp1 
CREATE PROCEDURE test_sp1( )  
    BEGIN  
    DECLARE t_error INTEGER DEFAULT 0;  
    DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET t_error=1;  
  
        START TRANSACTION;  
            INSERT INTO test VALUES(NULL, 'test sql 001');     
            INSERT INTO test VALUES('1', 'test sql 002');     
  
        IF t_error = 1 THEN  
            ROLLBACK;  
        ELSE  
            COMMIT;  
        END IF;  
   select t_error;   //返回标识位的结果集；
END
```



### 触发器 ？

**触发器是与表有关的数据库对象，指在 insert/update/delete 之前或之后，触发并执行触发器中定义的SQL语句集合。**触发器的这种特性可以协助应用在数据库端确保数据的完整性 , 日志记录 , 数据校验等操作 。



### 什么是内联接、左外联接、右外联接？

**内联接（Inner Join）**：匹配2张表中相关联的记录。

**左外联接（Left Outer Join）**：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。

**右外联接（Right Outer Join）**：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。在判定左表和右表时，要根据表名出现在Outer Join的左右位置关系。



### 如何快速定位慢SQL

**导致SQL执行慢的原因：**

​    1. 硬件问题。如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等。

​    2. 没有索引或者索引失效。（一般在互联网公司，DBA会在半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除.一是为了做数据分析, 二是为了不破坏索引 ）

​    3. 数据过多（分库分表）

​    4. 服务器调优及各个参数设置（调整my.cnf）

**分析原因时，一定要找切入点：**

​    1. 先观察，**开启慢查询日志，**设置相应的阈值（比如超过3秒就是慢SQL），在生产环境跑上个一天过后，看看哪些SQL比较慢。

​    2. **Explain和慢SQL分析。**比如SQL语句写的烂，索引没有或失效，关联查询太多（有时候是设计缺陷或者不得以的需求）等等。

​    3. **Show Profile是比Explain更近一步的执行细节，**可以查询到执行每一个SQL都干了什么事，这些事分别花了多少秒。在MySQL5.7中， show profile 命令已经开始不推荐使用，MySQL使用**performance_schema** 中系统表的信息来替代show profile 命令。

​    4. 找DBA或者运维对MySQL进行服务器的参数调优。



### explain 执行计划有哪些字段？

**explain 字段有：**

**id：标识符**

**select_type：查询的类型**

**table：输出结果集的表**

**partitions：匹配的分区**

**type：表的连接类型**

**possible_keys：查询时，可能使用的索引**

**key：实际使用的索引**

**key_len：使用的索引字段的长度**

**ref：列与索引的比较**

**rows：估计要检查的行数**

**filtered：按表条件过滤的行百分比**

**Extra：附加信息**

​	其中type 中有哪些常见的值？

​	按类型排序，从好到坏，常见的有：const > eq_ref > ref > range > index > ALL。

- const：通过主键或唯一键查询，并且结果只有1行（也就是用等号查询）。因为仅有一行，所以优化器的其余部分可以将这一行中的列值视为常量。

- eq_ref：通常出现于两表关联查询时，使用主键或者非空唯一键关联，并且查询条件不是主键或唯一键的等号查询。

- ref：通过普通索引查询，并且使用的等号查询。

- range：索引的范围查找（>=、<、in 等）。

- index：全索引扫描。

- All：全表扫描



### MySQL 中的日志文件

- **二进制日志（binlog）：**该日志文件会以二进制的形式记录数据库的各种操作，但不记录查询语句。用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原。
- **错误日志（errorlog）：**该日志文件会记录 MySQL 服务器的启动、关闭和运行错误等信息。
- **通用查询日志（general log）：**该日志记录 MySQL 服务器的启动和关闭信息、客户端的连接信息、更新、查询数据记录的 SQL 语句等。
- **慢查询日志（slow query log）：**记录执行事件超过指定时间的操作，通过工具分析慢查询日志可以定位 MySQL 服务器性能瓶颈所在。
- **重做日志（redo log）：**确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
- **回滚日志（undo log）：**保存了事务提交之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。



### SQL优化_ 大批量插入数据

1.  **主键顺序插入**

   因为InnoDB类型的表是按照主键的顺序保存的，所以将导入的数据按照主键的顺序排列，可以有效的提高导入数据的效率。如果InnoDB表没有主键，那么系统会自动默认创建一个内部列作为主键，所以如果可以给表创建一个主键，将可以利用这点，来提高导入数据的效率。

2. **关闭唯一性校验**

   在导入数据前执行 SET UNIQUE_CHECKS = 0，关闭唯一性校验，在导入结束后执行SET UNIQUE_CHECKS = 1，恢复唯一性校验，可以提高导入的效率。

3. **手动提交事务**

   如果应用使用自动提交的方式，建议在导入前执行 SET AUTOCOMMIT = 0，关闭自动提交，导入结束后再执行 SET AUTOCOMMIT = 1，打开自动提交，也可以提高导入的效率。

### SQL优化_  分页查询

一般分页查询时，通过创建覆盖索引能够比较好地提高性能。

一个常见又非常头疼的问题就是 limit 2000000,10，此时需要MySQL排序前2000010 记录，仅仅返回2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大 。

1. **该方案适用于主键自增的表，可以把Limit 查询转换成某个位置的查询 。**

   ```sql
   explain select * from tb_item where id > 2000000 limit 10;
   ```

2. **在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。**

   ```sql
   explain select * from tb_item t,(select id from tb_item order by id limit 10) a 
   where t.id = a.id;
   ```



### MySQL优化_  应用优化

1.  **使用连接池**

   对于访问数据库来说，建立连接的代价是比较昂贵的，因为我们频繁的创建关闭连接，是比较耗费资源的，我们有必要建立 数据库连接池，以提高访问的性能。

2.  **减少对MySQL的访问**

   避免对数据列进行重复检索。

   增加cache层。

3. **负载均衡 **

   利用MySQL复制分流查询，通过MySQL的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，从而可以降低单台服务器的读写压力。

   采用分布式数据库架构，分布式数据库架构适合大数据量、负载高的情况，它有良好的拓展性和高可用性。通过在多台服务器之间分布数据，可以实现在多台服务器之间的负载均衡，提高访问效率。

### MySQL优化_  SQL 语句优化 

1、Where 子句中：where 表之间的连接必须写在其他 Where 条件之前，那些可以过滤掉最大数量记录的条件必须写在 Where 子句的末尾，HAVING 最后。

2、用 EXISTS 替代 IN、用 NOT EXISTS 替代 NOT IN。

3、 避免在索引列上使用计算

4、避免在索引列上使用 IS NULL 和 IS NOT NULL

5、对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。

6、应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描

7、应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描



### 什么是MVCC？

> MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。
>
> **核心思想，“维持一个数据的多个版本，使得读写操作没有冲突”，**



#### MVCC带来的好处

多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题：

- 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能。

- 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题。

  

#### 什么是当前读和快照读？

- **当前读**

  **读取的是记录的最新版本，**读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。

- **快照读**

  像不加锁的 select 操作就是快照读，即**不加锁的非阻塞读**；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

  ```sql
  当前读:select...lock in share mode; select...for update;
  当前读:update、insert、delete
  快照读:不加锁的非阻塞读，select
  ```

说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现。



#### MVCC的实现原理

实现原理主要是版本链，undo日志 ，Read View 来实现的。

InnoDB的MVCC，通过在每行记录后面保存两个隐藏的列来实现：一个保存了行的创建时间，一个保存行的过期时间（删除时间），当然，这里的时间并不是时间戳，而是系统版本号，每开始一个新的事务，系统版本号就会递增。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。

#### 隐式字段

每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段。

![image-20210806165809251](Java面试总结.assets/image-20210806165809251.png)

- **DB_TRX_ID**
   6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID
- **DB_ROLL_PTR**
   7byte，回滚指针，用于配合undo日志，指向这条记录的上一个版本（存储于rollback segment里）
- **DB_ROW_ID**
   6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
- 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了

#### undo日志

undo log 是一种用于撤销回退的日志，用于事务没提交之前，会先记录存放到 Undo 日志文件里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志回退事务。

undo log 主要分为两种：

- **insert undo log**
   代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃
- **update undo log**
   事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除。

#### Read View(读视图)

事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。

**Read View几个属性：**

- trx_ids: 当前系统活跃(未提交)事务版本号集合；
- low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”；
- up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”；
- creator_trx_id: 创建当前read view的事务版本号；

**Read View可见性判断条件：**

- db_trx_id < up_limit_id || db_trx_id == creator_trx_id（显示）

  - 如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。

  - 或者数据的事务ID等于creator_trx_id ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。

- db_trx_id >= low_limit_id（不显示）

  如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不显示。如果小于则进入下一个判断

- db_trx_id是否在活跃事务（trx_ids）中

  - 不存在：则说明read view产生的时候事务已经commit了，这种情况数据则可以显示。

  - 已存在：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的。

**RC、RR级别下的InnoDB快照读区别：**

**在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View，** 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；

**而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View,** 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因。

[MVCC多版本并发控制 ](https://www.jianshu.com/p/8845ddca3b23)



## Redis

### 使用 Redis 有哪些好处？

1、速度快，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O（1）

2、支持丰富数据类型，支持 string，list，set，Zset，hash 等

3、支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行

4、丰富的特性：可用于缓存，发布订阅、消息，按 key 设置过期时间，过期后将会自动删除



### Redis的五种数据类型何应用场景

Redis的数据结构有：
1. 字符串（String）：可以用来做最简单的数据缓存，可以缓存某个简单的字符串，也可以缓存某个json格式的字符串，Redis分布式锁的实现就利用了这种数据结构，还包括可以实现计数器、Session共享、分布式ID；
2. 哈希表（Hash）：可以用来存储一些key-value对，更适合用来存储对象；
3. 列表（List）：Redis的列表通过命令的组合，既可以当做栈，也可以当做队列来使用，可以用来缓存类似微信公众号、微博等消息流数据；
4. 集合（Set）：和列表类似，也可以存储多个元素，但是不能重复，集合可以行交集、并集、差集操作，从而可以实现类似，我和某⼈共同关注的人、朋友圈点赞等功能；
5. 有序集合（Sorted Set）：集合是无序的，有序集合可以设置顺序，可以用来实现排行榜功能；



**高级数据类型:**

我们实际项目中比较常用的是 string，hash 如果你是 Redis 中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。

如果你说还玩过 Redis Module，像 BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮了。

#### 1. BitMaps

在应用场景中，有一些数据只有两个属性，比如是否是学生，是否是党员等等，对于这些数据，最节约内存的方式就是用bit去记录，以是否是学生为例，1代表是学生，0代表不是学生。那么1000110就代表7个人中3个是学生，这就是BitMaps的存储需求。

- bitmaps不是一个真实的数据结构，而是String类型上的一组面向bit操作的集合
- BitMaps就是通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身
- 可以把Bitmaps想象成是一串二进制数字，每个位置只存储0和1（某种状态），下标是Bitmaps的偏移量（offset）
- 我们知道8个bit可以组成一个Byte，所以bitmaps本身会极大的节省储存空间。

**BitMaps的基本操作：**

获取指定key对应偏移量上的bit值

```java 
getbit key offset   如果没有设置的话，默认是0
```

设置指定key对应偏移量上的bit值，value只能是0或1

 ```java
setbit key offset value  偏移量很大的话，也能设置，但是前面要补0，比较耗时
 ```

对指定key按位进行交、并、非、异或操作，并将结果保存到destKey中

```java
 bitop op destKey key1 [key2...] 
```

op：and（交）、or（并）、not（非）、xor（异或）

统计指定key中1的数量

```java
bitcount key [start end]
```



#### 2. HyperLogLog

HyperLogLog是用来做基数统计的，所谓基数统计，就是指一串数字中不重复的数字个数，如{1，2，1，2，3}的基数集就是{1，2，3}，基数就是3，内部运用了LogLog算法。

**HyperLogLog 类型的基本操作**

添加数据

```java 
 pfadd key element [element ...] 
```

统计数据

```java
 pfcount key [key ...]
```

合并数据

```java
 pfmerge destkey sourcekey [sourcekey...]
```

**注意：**

- 用于进行基数统计，不是集合，不保存数据，只记录数量而不是具体数据
- 核心是基数估算算法，最终数值存在一定误差
- 误差范围：基数估计的结果是一个带有 0.81% 标准错误的近似值
- 耗空间极小，每个hyperloglog key占用了12K的内存用于标记基数
- pfadd命令不是一次性分配12K内存使用，会随着基数的增加内存逐渐增大
- Pfmerge命令合并后占用的存储空间为12K，无论合并之前数据量多少

> 业务场景：统计页面实时 UV 数、统计在线用户数、统计用户每天搜索不同词条的个数。而Bitmaps则用于判断某个用户是否访问过搜索页面。这是它们用法的不同。

#### GEO 介绍

GEO是redis中关于地理位置计算的高级数据类型，比如微信中的附近好友会展示好友离你的距离，这就是GEO的一个应用。



### Redis持久化机制

Redis是一个支持持久化的内存数据库，通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。

实现：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。

> RDB: 将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据 
> AOF: 将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程

#### RDB

**RDB：**  是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）

快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：

```java
save 900 1       #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 300 10      #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 60 10000    #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

**优点：**
1、只有一个文件 dump.rdb，存储效率较高，方便持久化。

2、容灾性好，一个文件可以保存到安全的磁盘。

3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis的高性能) 

4、相对于数据集大时，比 AOF 恢复数据的效率更高。

**缺点：**

1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)。

2、bgsave指令每次运行要执行fork操作创建子进程，要牺牲掉一些性能。



#### AOF

**AOF：** Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。

默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：`appendonly yes`，开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。

在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```java
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

**优点：**

1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次。

2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof工具解决数据一致性问题。

3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写，可以删除其中的某些命令（比如误操作的 flushall）)  

**缺点：**

1、AOF 文件比 RDB 文件大，且恢复速度慢。

2、数据集大的时候，比 rdb 启动效率低。



#### AOF重写

随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积。AOF文件重写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是将对同一个数据的若干个条命令执行结果转化成最终结果数据对应的指令进行记录。

**AOF重写作用**

- 降低磁盘占用量，提高磁盘利用率 
- 提高持久化效率，降低持久化写时间，提高IO性能 
- 降低数据恢复用时，提高数据恢复效率

**AOF重写规则**

-  进程内已超时的数据不再写入文件 

- 忽略无效指令，重写时使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令，如del key1、 hdel key2、srem key3、set key4 111、set key4 222等 
- 对同一数据的多条写命令合并为一条命令 ， 如lpush list1 a、lpush list1 b、 lpush list1 c 可以转化为：lpush list1 a b c。  为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素



#### RDB与AOF的区别 

| 持久化方式   | RDB                | AOF                |
| ------------ | ------------------ | ------------------ |
| 占用存储空间 | 小（数据级：压缩） | 大（指令级：重写） |
| 存储速度     | 慢                 | 快                 |
| 恢复速度     | 快                 | 慢                 |
| 数据安全性   | 会丢失数据         | 依据策略决定       |
| 资源消耗     | 高/重量级          | 低/轻量级          |
| 启动优先级   | 低                 | 高                 |



### 单线程的redis为什么这么快

(一)纯内存操作

(二)单线程操作，避免了频繁的上下文切换

(三)采用了非阻塞I/O多路复用机制



### Redis 的线程模型了解么？

Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 Socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。



### redis 的过期策略

1. ~~**定时删除** :  创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作。~~
2. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
3. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

### redis 内存淘汰机制

Redis 提供 6 种数据淘汰策略：

1. volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰；
2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰；
3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰；
4. allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）；
5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰；
6. no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没⼈使用吧！

4.0 版本后增加以下两种：
7. volatile-lfu（least frequently used）：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰；
8. allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key；



### Redis 事务 

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的；

Redis会将一个事务中的所有命令序列化，然后按顺序执行。

1. **MULTI： 命令用于开启一个事务**，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
2. **EXEC：执行所有事务块内的命令**。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。
3. **DISCARD：客户端可以清空事务队列，并放弃执行事务**， 并且客户端会从事务状态中退出。
4. **WATCH： 命令可以为 Redis 事务提供 check-and-set （CAS）行为**。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。

- redis 不支持回滚“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。
- 如果在一个事务中的命令出现错误，那么所有的命令都不会执行；
- 如果在一个事务中出现运行错误，那么正确的命令会被执行。

> 你可以将Redis中的事务就理解为 ：Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。



### 缓存穿透

 **什么是缓存穿透？** 

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

**缓存穿透有哪些解决办法？**

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

2. 缓存无效 key

   如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间；

3. 布隆过滤器

   将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

> Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。
>
> 但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 
>
> 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

### 缓存击穿

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

**解决方案？**

1. 设置热点数据永远不过期
2. 使用互斥锁(mutex key)

### 缓存雪崩

**什么是缓存雪崩？**

缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。

**有哪些解决办法？**

针对热点缓存失效的情况

1. 设置不同的失效时间比如随机设置缓存的失效时间。

2. 缓存永不失效。

3. 排斥锁，即第一个线程过来读取cache，发现没有，就去访问DB。后续线程再过来就需要等待第一个线程读取DB成功，cache里的value变得可用，后续线程返回新的value。

4. 缓存过期标记 + 异步刷新：

   排斥锁方案对缓存过期是零容忍的：cache一旦过期，后续所有读操作就必须返回新的value。如果我们稍微放宽点限制：在cache过期时间T到达后，允许短时间内部分读请求返回旧值，我们就能提出兼顾吞吐率的方案。实际上既然用了cache，系统就默许了容忍cache和DB的数据短时间的不一致。

   限制放宽后，下面我们提出一个优化思路。时间T到达后，cache中的key和value不会被清掉，而只是被标记为过期（逻辑上过期，物理上不过期），然后程序异步去刷新cache。而后续部分读线程在前面的线程刷新cache成功之前，暂时获取cache中旧的value返回。一旦cache刷新成功，后续所有线程就能直接获取cache中新的value。

针对 Redis 服务不可用的情况：
1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。

2. 限流，避免同时处理大量的请求。

  

### 如何保证缓存和数据库数据的一致性？

**Cache Aside Pattern（旁路缓存模式)：**

**写** ：先更新 DB、然后直接删除 cache 。

**读** :  从 cache 中读取数据，读取到就直接返回、cache中读取不到的话，就从 DB 中读取数据返回、再把数据放到 cache 中。



**延时双删，**步骤是：先删除Redis缓存数据，再更新Mysql，延迟几百毫秒再删除Redis缓存数据，这样就算在更新Mysql时，有其他线程读了Mysql，把老数据读到了Redis中，那么也会被删除掉，从而把数据保持一致。



**Read/Write Through Pattern（读写穿透）：**

**写（Write Through）：**

- 先查 cache，cache 中不存在，直接更新 DB。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。

**读(Read Through)：**

- 从 cache 中读取数据，读取到就直接返回 。

- 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

  

**Write Behind Pattern（异步缓存写入）：**

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**



### Redis集群策略

Redis提供了三种集群策略：
1. **主从模式：**这种模式比较简单，主库可以读写，并且会和从库进行数据同步，这种模式下，客户端直接连主库或某个从库，但是但主库或从库宕机后，客户端需要手动修改IP，另外，这种模式也比较难进行扩容，整个集群所能存储的数据受到某台机器的内存容量，所以不可能支持特大数据量；
2. **哨兵模式：**这种模式在主从的基础上新增了哨兵节点，但主库节点宕机后，哨兵会发现主库节点宕机，然后在从库中选择一个库作为进的主库，另外哨兵也可以做集群，从而可以保证但某一个哨兵节点宕机后，还有其他哨兵节点可以继续工作，这种模式可以比较好的保证Redis集群的高可用，但是仍然不能很好的解决Redis的容量上限问题。
3. **Cluster模式：**Cluster模式是用得比较多的模式，它支持多主多从，这种模式会按照key进行槽位的分配，可以使得不同的key分散到不同的主节点上，利用这种模式可以使得整个集群支持更大的数据容量，同时每个主节点可以拥有自己的多个从节点，如果该主节点宕机，会从它的从节点中选举一个新的主节点。

对于这三种模式，如果Redis要存的数据量不大，可以选择哨兵模式，如果Redis要存的数据量大，并且需要持续的扩容，那么选择Cluster模式。



### Redis主从复制的核心原理

Redis的主从复制是提高Redis的可靠性的有效措施，主从复制的流程如下：
1. 集群启动时，主从库间会先建立连接，为全量复制做准备。
2. 主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载，这个过程依赖于内存快照 RDB。
3. 在主库将数据同步给从库的过程中，主库不会阻塞，仍然可以正常接收请求。否则，redis的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的RDB文件中。为了保证主从库的数据一致性，主库会在内存中用专⻔的replication buffer，记录RDB文件生成收到的所有写操作。
4. 最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成RDB文件发送后，就会把此时replocation buffer中修改操作发送给从库，从库再执行这些操作。这样一来，主从库就实现同步了
5. 后续主库和从库都可以处理客户端读操作，写操作只能交给主库处理，主库接收到写操作后，还会将写操作发送给从库，实现增量同步



### Redis 底层数据结构

> 总结：
>
> 1. Redis使用**简单字符串**SDS作为字符串的表示，相对于C语言字符串，SDS具有常数复杂度获取字符串长度，杜绝了缓存区的溢出，减少了修改字符串长度时所需的内存重分配次数，以及二进制安全能存储各种类型的文件，并且还兼容部分C函数。
> 2. 通过为**链表**设置不同类型的特定函数，Redis链表可以保存各种不同类型的值，除了用作列表键，还在发布与订阅、慢查询、监视器等方面发挥作用。
> 3. Redis的**字典**底层使用哈希表实现，每个字典通常有两个哈希表，一个平时使用，另一个用于rehash时使用，使用链地址法解决哈希冲突。
> 4. **跳跃表**通常是有序集合的底层实现之一，表中的节点按照分值大小进行排序。
> 5. **整数集合**是集合键的底层实现之一，底层由数组构成，升级特性能尽可能的节省内存。
> 6. **压缩列表**是Redis为节省内存而开发的顺序型数据结构，通常作为列表键和哈希键的底层实现之一。

1. **简单动态字符串**

   Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string，SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。

   ```c
   struct sdshdr{
        //记录buf数组中已使用字节的数量
        //等于 SDS 保存字符串的长度
        int len;
        //记录 buf 数组中未使用字节的数量
        int free;
        //字节数组，用于保存字符串
        char buf[];
   }
   ```

2. **链表**

   ```c
   typedef` `struct` `list{
      ``//表头节点
      ``listNode *head;
      ``//表尾节点
      ``listNode *tail;
      ``//链表所包含的节点数量
      ``unsigned ``long` `len;
      ``//节点值复制函数
      ``void` `(*``free``) (``void` `*ptr);
      ``//节点值释放函数
      ``void` `(*``free``) (``void` `*ptr);
      ``//节点值对比函数
      ``int` `(*match) (``void` `*ptr,``void` `*key);
   }list;
   ```

   Redis链表特性：

   　　①双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。

   　　②无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL，对链表的访问都是以 NULL 结束。　　

   　　③带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。

   　　④多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。

3. **字典**

   字典又称为符号表或者关联数组、或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键 key 都是唯一的，通过 key 可以对值来进行查找或修改。

4. **跳跃表**

   跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：

   ​		 1、由很多层结构组成；

   　　2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；

   　　3、最底层的链表包含了所有的元素；

   　　4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；

   　　5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；

   ![image-20210723164925342](Java面试总结.assets/image-20210723164925342.png)

   ```c
   typedef struct zskiplistNode {
        //层
        struct zskiplistLevel{
              //前进指针
              struct zskiplistNode *forward;
              //跨度
              unsigned int span;
        }level[];
        //后退指针
        struct zskiplistNode *backward;
        //分值
        double score;
        //成员对象
        robj *obj;
   } zskiplistNode
       
   typedef struct zskiplist{
        //表头节点和表尾节点
        structz skiplistNode *header, *tail;
        //表中节点的数量
        unsigned long length;
        //表中层数最大的节点的层数
        int level;
    
   }zskiplist;
   ```

   

5.  **整数集合**

   整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。

   ```c
   typedef struct intset{
        //编码方式
        uint32_t encoding;
        //集合包含的元素数量
        uint32_t length;
        //保存元素的数组
        int8_t contents[];
    
   }intset;
   ```

6.  **压缩列表**

      　压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

      　![image-20210723165447523](Java面试总结.assets/image-20210723165447523.png)

### zset实现原理/什么是skipList?

zset是 Redis五种数据结构中的一种（String、List、Hash、Set、Zset）。也称为sortedSet，它类似于Java里面是soretdSet和HashMap的结合体，因为它本身具有HashSet中不含重复元素的特性，又包含了SortedSet中内部有序的特性(通过传入一个score，根据score来排序)。但它内部的数据结构却与上述两种完全不同，它内部是通过一种名为 SkipList(跳跃表) 的数据结构来实现的。

#### 什么是skipList?

SkipList是一种随机化的数据结构，是一种层次化的链表结构，它使得在进行增删改查时，都能在可接收的时间范围内完成操作。

它的原理就是每次查找数据时，先在最上层查找，然后在定位到下一层，层层定位，最终找到目标数据，这种查找方式不用遍历整个链表，而是跳跃着查，这样就使得查找的时间复杂度退化到了logn（近似于二分查找），大大提高了查找效率。

一般来说，我们可以按下一层的链表来构造上一层的链表，举个例子，最下一层是所有数据构成的链表，我们将它分段，隔一个节点构造一个新的节点，这样，第二层的链表长度就是第一层的一半，第三层又是第二层的一半，以此类推。但是这里我们会发现一个严重的问题，每次对zset进行更新时，需要重新构建zset，这又增加了时间复杂度，所以zset在构建skiplist的时候，就给每个节点赋予了一个随机的层数，这样就避免了重新构建。
![image-20210725233537909](Java面试总结.assets/image-20210725233537909.png)

#### 为什么不使用List/红黑树或平衡二叉树呢？

List是顺序存储，访问速度很快，但是添加和删除操作是一个(On)的操作，对于Redis这样要求高写入和高读取的数据库来说，List显然不能满足其要求。

至于红黑树和平衡二叉树，每次更新redis的值，都要调整树结构，这样会造成额外的开销，而跳跃表只需要调整表局部的链表结构就行，显然跳跃表更适合。

#### 跳跃表的层数可以一直增加下去吗？

不能， 跳跃表的层数最大只能到达32层，这也被源码ZSKIPLIST_MAXLEVEL 定义了。






## Spring

### 什么是 Spring Framework？

Spring 是一个开源应用框架，旨在降低应用程序开发的复杂度。它是轻量级、松散耦合的。它具有分层体系结构，允许用户选择组件，同时还为 J2EE 应用程序开发提供了一个有凝聚力的框架。它可以集成其他框架，如 Structs、Hibernate、EJB 等，所以又称为框架的框架。

### Spring Framework 中有多少个模块，它们分别是什么？

![image-20210721151514387](Java面试总结.assets/image-20210721151514387.png)

- spring core：提供了框架的基本组成部分，包括控制反转（Inversion of Control，IOC）和依赖注入（Dependency Injection，DI）功能。
- spring beans：提供了BeanFactory，是工厂模式的一个经典实现，Spring将管理对象称为Bean。
- spring context：构建于 core 封装包基础上的 context 封装包，提供了一种框架式的对象访问方法。
- spring jdbc：提供了一个JDBC的抽象层，消除了烦琐的JDBC编码和数据库厂商特有的错误代码解析， 用于简化JDBC。
- spring aop：提供了面向切面的编程实现，让你可以自定义拦截器、切点等。
- spring Web：提供了针对 Web 开发的集成特性，例如文件上传，利用 servlet listeners 进行 ioc 容器初始化和针对 Web 的 ApplicationContext。
- spring test：主要为测试提供支持的，支持使用JUnit或TestNG对Spring组件进行单元测试和集成测试。
- 几个杂项模块:  Messaging – 该模块为 STOMP 提供支持。它还支持注解编程模型，该模型用于从 WebSocket 客户端路由和处理 STOMP 消息。Aspects – 该模块为与 AspectJ 的集成提供支持。



### Spring框架的设计目标，设计理念，和核心是什么？

**Spring设计目标**：Spring为开发者提供一个一站式轻量级应用开发平台；

**Spring设计理念**：在JavaEE开发中，支持POJO和JavaBean开发方式，使应用面向接口开发，充分支持OO（面向对象）设计方法；Spring通过IoC容器实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给IoC容器，实现解耦；

**Spring框架的核心**：IoC容器和AOP模块。通过IoC容器管理POJO对象以及他们之间的耦合关系；通过AOP以动态非侵入的方式增强服务。

IoC让相互协作的组件保持松散的耦合，而AOP编程允许你把遍布于应用各层的功能分离出来形成可重用的功能组件。

### Spring的优缺点是什么？

优点

- 方便解耦，简化开发
  Spring就是一个大工厂，可以将所有对象的创建和依赖关系的维护，交给Spring管理。
- AOP编程的支持
  Spring提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能。
- 声明式事务的支持
  只需要通过配置就可以完成对事务的管理，而无需手动编程。
- 方便程序的测试
  Spring对Junit4支持，可以通过注解方便的测试Spring程序。
- 方便集成各种优秀框架
  Spring不排斥各种优秀的开源框架，其内部提供了对各种优秀框架的直接支持（如：Struts、Hibernate、MyBatis等）。

- 降低JavaEE API的使用难度
  Spring对JavaEE开发中非常难用的一些API（JDBC、JavaMail、远程调用等），都提供了封装，使这些API应用难度大大降低。

缺点

- Spring明明一个很轻量级的框架，却给人感觉大而全
- Spring依赖反射，反射影响性能
- 使用门槛升高，入门Spring需要较长时间



### Spring容器启动流程

1. 在创建Spring容器，也就是启动Spring时
2. 首先会进行扫描，扫描得到所有的BeanDefinition对象，并存在一个Map中

3. 然后筛选出非懒加载的单例BeanDefinition进行创建Bean，对于多例Bean不需要在启动过程中去进行创建，对于多例Bean会在每次获取Bean时利用BeanDefinition去创建
4. 利用BeanDefinition创建Bean就是Bean的创建生命周期，这期间包括了合并BeanDefinition、推断构造方法、实例化、属性填充、初始化前、初始化、初始化后等步骤，其中AOP就是发生在初始化后这一步骤中
5. 单例Bean创建完了之后，Spring会发布一个容器启动事件
6. Spring启动结束
7. 在源码中会更复杂，比如源码中会提供一些模板方法，让子类来实现，比如源码中还涉及到一些
BeanFactoryPostProcessor和BeanPostProcessor的注册，Spring的扫描就是通过
BenaFactoryPostProcessor来实现的，依赖注入就是通过BeanPostProcessor来实现的
8. 在Spring启动过程中还会去处理@Import等注解





###  Spring IoC  ？

**IoC（Inverse of Control:控制反转）是一种设计思想，就是 将原本在程序中手动创建对象的控制权，交由Spring框架来管理。**  

Spring 通过一个配置文件描述 Bean 及 Bean 之间的依赖关系，利用 Java 语言的反射功能实例化 Bean 并建立 Bean 之间的依赖关系。 Spring 的 IoC 容器在完成这些底层工作的基础上，还提供了 Bean 实例缓存、生命周期管理、 Bean 实例代理、事件发布、资源装载等高级服务。

![image-20210721161751058](Java面试总结.assets/image-20210721161751058.png)

### 什么是依赖注入？

依赖注入是Spring实现IoC的一种重要手段，将对象间的依赖关系的控制权从开发人员手里转移到容器。



### Bean 可以通过多少种方式完成依赖注入？

通常，依赖注入可以通过三种方式完成，即：

1. 构造函数注入
2.  setter 注入
3.  接口注入

在 Spring Framework 中，仅使用构造函数和 setter 注入。



### Spring Bean有三种配置方式

- 传统的XML配置方式
- 基于注解的配置
- 基于类的Java Config



### spring 中有多少种 IOC 容器？ 

BeanFactory - BeanFactory 就像一个包含 bean 集合的工厂类。它会在客户端要求时实例化 bean。

ApplicationContext - ApplicationContext 接口扩展了 BeanFactory 接口。它在 BeanFactory 基础上提供了一些额外的功能。

| BeanFactory                | ApplicationContext       |
| -------------------------- | ------------------------ |
| 它使用懒加载               | 它使用即时加载           |
| 它使用语法显式提供资源对象 | 它自己创建和管理资源对象 |
| 不支持国际化               | 支持国际化               |
| 不支持基于依赖的注解       | 支持基于依赖的注解       |

### Spring IoC 的实现机制

Spring 中的 IoC 的实现原理就是工厂模式加反射机制。

```java
interface Fruit {
    public abstract void eat();
} 
class Apple implements Fruit {
    public void eat(){
    System.out.println("Apple");
    }
} 
class Orange implements Fruit {
    public void eat(){
    System.out.println("Orange");
    }
} 
class Factory {
    public static Fruit getInstance(String ClassName) {
        Fruit f=null;
        try {
            f=(Fruit)Class.forName(ClassName).newInstance();
        } catch (Exception e) {
            e.printStackTrace();
        } 
        return f;
    }
} 
class Client {
    public static void main(String[] a) {
        Fruit f=Factory.getInstance("com.kunaly.spring.Apple");
        if(f!=null){
            f.eat();
        }
    }
}
```

### Spring 中 bean 的作用域scope？

1. **singleton :** 单例，唯一 bean 实例，Spring 中的 bean 默认都是单例的。

2. **prototype :** 原型， 每次请求都会创建一个新的 bean 实例。

3. **request :** 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。

4. **session :** 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。

5. **global-session：**全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话

   

### 将一个类声明为Spring的 bean 的注解有哪些?

我们一般使用 @Autowired  注解自动装配 bean，要想把类标识成可用于 @Autowired  注解自动装配的 bean 的类,采用以下注解可实现：

1. **@Component  ：**通用的注解，可标注任意类为 Spring  组件。如果一个Bean不知道属于哪个层，可以使用@Component  注解标注。
2. **@Repository  :** 对应持久层即 Dao 层，主要用于数据库相关操作。
3. **@Service  :** 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。
4. **@Controller  :** 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端⻚面。



### @Component 和 @Bean 的区别是什么？

1. 作用对象不同: @Component  注解作用于类，而 @Bean 注解作用于方法。

2. @Component 标注该类为 Spring  组件，自动装配到Spring容器中。

  @Bean  注解声明当前方法的返回值为一个bean，可替代xml中配置的方式。

3. @Bean  注解比 @Component  注解的自定义性更强，而且很多地方我们只能通过 @Bean  注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，则只能通过 @Bean 来实现。

**@Bean 注解使用示例：**

```java
@Configuration
public class AppConfig {
    @Bean
    public TransferService transferService() {
        return new TransferServiceImpl();
    }
}
```

上面的代码相当于下面的 xml 配置：

```java
<beans>
    <bean id="transferService" class="com.acme.TransferServiceImpl"/>
</beans>
```



### spring bean 容器的生命周期？

spring bean 容器的生命周期流程如下：

**（1）实例化Bean：**

对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。对于ApplicationContext容器，当容器启动结束后，通过获取BeanDefinition对象中的信息，实例化所有的bean。

**（2）设置对象属性（依赖注入）：**

实例化后的对象被封装在BeanWrapper对象中，紧接着，Spring根据BeanDefinition中的信息 以及 通过BeanWrapper提供的设置属性的接口完成依赖注入。

**（3）处理Aware接口：**

接着，Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给Bean：

- ① 如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String beanId)方法，此处传递的就是Spring配置文件中Bean的id值；
- ② 如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory()方法，传递的是Spring工厂自身。
- ③ 如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文；

**（4）处理前置 BeanPostProcessor：**

如果想对Bean进行一些自定义的处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用
postProcessBeforeInitialization(Object obj, String s)方法。

**（5）InitializingBean 与 init-method：**

如果Bean在Spring配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。

**（6）处理后置 BeanPostProcessor：**

如果这个Bean实现了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法；由于这个方法是在Bean初始化结束时调用的，所以可以被应用于内存或缓存技术

`以上几个步骤完成后，Bean就已经被正确创建了，之后就可以使用这个Bean了   `

**7）DisposableBean：**

当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法；

**（8）destroy-method：**

最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法

![image-20210721165026128](Java面试总结.assets/image-20210721165026128.png)



### Spring 如何解决循环依赖?

**什么是循环依赖 ？**

循环依赖就是循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成闭环。

比如 A 依赖 B，B 依赖 C，C 又依赖A。

```java
public class Student {
    private Long id;

    private String name;

    @Autowired
    private ClassRoom classRoom;
}

public class ClassRoom {
    private String name;

    @Autowired
    private Collection<Student> students;
}
```

**Spring 对循环依赖处理的三种情况**

1. 构造器的循环依赖：这种依赖 Spring 是处理不了的，直接抛出 BeanCurrentlylnCreationException 异常。
2. 单例模式下的 setter 循环依赖：通过“三级缓存`singletonFactories`”处理循环依赖。
3. 非单例循环依赖：无法处理。

**Spring 单例对象的初始化**

1. 实例化 createBeanInstance，
2. 填充属性 populateBean，对 Bean 的依赖属性进行填充
3. 调用 init 方法

循环依赖主要发生在第一、第二步。

A 依赖 B 的情况下，伪代码如下：

```java
public Object getBean(String name) {
    //省略根据name获取A的过程
    A a = new A(); //实例化A
    a.setB(getBean("B")); //设置属性，发现a依赖于b，所以先加载b，加载B完成以后再继续加载a
    a.initialze(); //执行初始化方法
    singletonObjects.put(name, a); //将a放入单例池中
    return a;
}
```

**Spring的三级缓存**

三个 Map 是 Spring 设计的处理属性注入循环依赖的关键。

```java
/** 用于存放完全初始化好的bean，从该缓存中取出的bean可以直接使用 */
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256);

/** 存放原始的bean对象，用于解决依赖循环，存放的对象还未被填充属性 */
private final Map<String, Object> earlySingletonObjects = new HashMap<>(16);

/** 存放bean工厂对象，用于解决循环依赖 */
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>(16);
```

**一级缓存：singletonObjects 单例池**

单例 Bean 创建完成后就放在 singletonObjects 这个 Map 里面，这就是一级缓存。

**二级缓存：earlySingletonObjects**

earlySingletonObjects 这个 Map 存放提前暴露 Bean 的引用，实例化以后，就把对象放入到这个 Map 中。

`b.setA(getBean("a"))` 在加载 b 的过程中，可以在 earlySingletonObjects 拿到 a 的引用，此时 a 仅仅经过了实例化，并没有设置属性。

getEarlyBeanReference(beanName, mbd, bean)有可能会进行 AOP 的增强，创建代理类，因此二级缓存 earlySingletonObjects 存放的有可能是经过 AOP 增强的代理对像。

**三级缓存：singletonFactories**

为了解决二级缓存中 AOP 生成新对象的问题，Spring 中的解决方案就是提前 AOP。

在加载 b 的流程中，如果发生了循环依赖，就是说 b 又依赖了 a，我们就要对 a 执行 AOP，提前获取增强以后的 a 对象，这样 b 对象依赖的 a 对象就是增强以后的 a 了。

三级缓存的 key 是 beanName，value 是一个 lambda 表达式，这个 lambda 表达式的作用就是进行提前 AOP。

<img src="Java面试总结.assets/v2-2e8bcfc1622b4c4a2834bde0b2de55c3_1440w.jpg" alt="如何解决Spring的循环依赖" style="zoom:200%;" />

![image-20200706133018669](Java面试总结.assets/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjEzMzAxODY2OS5wbmc)

![在这里插入图片描述](Java面试总结.assets/20200825233756793.png)



### Spring  AOP ？

AOP（Aspect Oriented Programming 面向切面编程），通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。

常用于日志记录，性能统计，安全控制，事务处理，异常处理等等。

**AOP相关术语**

- **切面（Aspect）：**切面是通知（增强）和切入点的结合。通知说明了干什么和什么时候干，而切入点说明了在哪干，这就是一个完整的切面定义。

- **连接点（Join Point）：简单来说，就是允许你使用通知、增强的地方。**就比如在方法前后打印日志一样，我们可以在一段代码的前后做操作，可以在一段代码前做操作，可以在一段代码后做操作，可以在一段代码抛异常之后做操作。所以，在这里这些可以操作的一行行代码（方法等等）都是一个个的连接点。

- **通知（Advice）：**指在切面的某个特定的连接点上执行的动作。Spring切面可以应用5中通知：

  - 前置通知（Before）:在目标方法或者说连接点被调用前执行的通知；

  - 后置通知（After）：指在某个连接点完成后执行的通知；
  - 返回通知（After-returning）：指在某个连接点成功执行之后执行的通知；
  - 异常通知（After-throwing）：指在方法抛出异常后执行的通知；
  - 环绕通知（Around）：指包围一个连接点通知，在被通知的方法调用之前和之后执行自定义的方法。

- **切点（Pointcut）：**把一个个方法等代码看作连接点，那我们从哪个位置打印日志（增强操作）呢，而我们挑选出需要打印日志的位置（也就是连接点的周围），就被称为切入点。

- **引入（Introduction）：**允许我们向现有的类添加新方法属性。这不就是把切面（也就是增强定义的新方法属性）用到目标对象中。

- **目标对象（Target Object）：**目标对象，简单来说是要被增强的对象。

- **AOP代理（AOP Proxy）**：AOP代理是指AOP框架创建的对对象，用来实现切面契约（包括通知方法等功能）

- **织入（Wearving）**：指把切面连接到其他应用出程序类型或者对象上，并创建一个被通知的对象。或者说形成代理对象的方法的过程。



### AOP 有哪些实现方式？ 

#### 什么是代理？

为某一个对象创建一个代理对象，程序不直接用原本的对象，而是由创建的代理对象来控制原对象，通过代理类这中间一层，能有效控制对委托类对象的直接访问，也可以很好地隐藏和保护委托类对象，同时也为实施不同控制策略预留了空间。

#### 静态代理个动态代理  

**静态代理**

由程序创建或特定工具自动生成源代码，从而在编译阶段就可生成 AOP 代理类，在程序运行前，代理类的.class文件就已经存在，因此也称为编译时增强；

- 编译时编织（特殊编译器实现）
-  类加载时编织（特殊的类加载器实现）

**动态代理**

在运行时在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。

- JDK 动态代理
-  CGLIB

[Spring AOP里的静态代理和动态代理，你真的了解嘛 (cnblogs.com)](https://www.cnblogs.com/chenyanbin/p/13306055.html)

### AOP 的动态代理技术

常用的动态代理技术

- JDK 代理 : 基于接口的动态代理技术
- cglib 代理：基于父类的动态代理技术



**JDK 动态代理：**

JDK 动态代理主要涉及到 java.lang.reflect 包中的两个类：Proxy 和 InvocationHandler。InvocationHandler 是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy 利用 InvocationHandler 动态创建一个符合某一接口的实例，生成目标类的代理对象。

**cglib 代理：**

CGLib 全称为 Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展 Java 类与实现 Java 接口，CGLib 封装了 asm，可以再运行期动态生成新的 class。

和 JDK 动态代理相比较：**JDK 创建代理有一个限制，就是只能为接口创建代理实例**，而对于没有通过接口定义业务方法的类，则可以通过 CGLib 创建动态代理。



**JDK 动态代理实现：**

```java
//1.目标类接口
interface TargetInterface {
    public void method();
}

//2.目标类
class Target implements TargetInterface {
    @Override
    public void method() {
        System.out.println("Target running....");
    }
}

public class test {
    public static void main(String[] args) {
        //3 .动态代理代码
        Target target = new Target(); //创建目标对象
        //创建代理对象
        TargetInterface proxy = (TargetInterface) Proxy.newProxyInstance(target.getClass()
                .getClassLoader(),target.getClass().getInterfaces(),new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                System.out.println("前置增强代码...");
                Object invoke = method.invoke(target, args);
                System.out.println("后置增强代码...");
                return invoke;
            }
        });

        // 4. 调用代理对象的方法测试测试
        proxy.method();

    }
}
```

输出结果：

```java
前置增强代码...
Target running....
后置增强代码...
```



**cglib 代理实现：**

```java
package com.proxy.cglib;
import org.springframework.cglib.proxy.Enhancer;
import org.springframework.cglib.proxy.MethodInterceptor;
import org.springframework.cglib.proxy.MethodProxy;

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;

class Target {
    public void save() {
        System.out.println("save running.....");
    }
}

class Advice {
    public void before(){
        System.out.println("前置增强....");
    }
    public void afterReturning(){
        System.out.println("后置增强....");
    }
}

public class ProxyTest {
    public static void main(String[] args) {
        //目标对象
        final Target target = new Target();
        //增强对象
        final Advice advice = new Advice();
        
        //返回值 就是动态生成的代理对象  基于cglib
        //1、创建增强器
        Enhancer enhancer = new Enhancer();
        //2、设置父类（目标）
        enhancer.setSuperclass(Target.class);
        //3、设置回调
        enhancer.setCallback(new MethodInterceptor() {
            public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
                advice.before(); //执行前置
                Object invoke = method.invoke(target, args);//执行目标
                advice.afterReturning(); //执行后置
                return invoke;
            }
        });
        //4、创建代理对象
        Target proxy = (Target) enhancer.create();
        proxy.save();
    }
}

```



### Spring常用注解

**1.声明bean的注解**

**@Component** 组件，没有明确的角色

**@Service** 在业务逻辑层使用（service层）

**@Repository** 在数据访问层使用（dao层）

**@Controller** 在展现层使用，控制器的声明（Controller层）

**2.注入bean的注解**

@Autowired：由Spring提供，自动导入对象到类中

@Inject：由JSR-330提供

@Resource：由JSR-250提供

都可以注解在set方法和属性上，推荐注解在属性上。

**3.java配置类相关注解**

@Configuration 声明当前类为配置类，相当于xml形式的Spring配置（类上）

@Bean 注解在方法上，声明当前方法的返回值为一个bean，替代xml中的方式（方法上）

@Configuration 声明当前类为配置类，其中内部组合了@Component注解，表明这个类是一个bean（类上）

@ComponentScan 用于对Component进行扫描，相当于xml中的（类上）

@WishlyConfiguration 为@Configuration与@ComponentScan的组合注解，可以替代这两个注解

**切面（AOP）相关注解**

Spring支持AspectJ的注解式切面编程。

**@Aspect** 声明一个切面（类上） 
使用**@After、@Before、@Around**定义通知advice，可直接将拦截规则（切点）作为参数。

**@After** 在方法执行之后执行（方法上） 
**@Before** 在方法执行之前执行（方法上） 
**@Around** 在方法执行之前与之后执行（方法上）

**@PointCut** 声明切点 
在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上）



**Bean的属性支持**

**@Scope** 设置Spring容器如何新建Bean实例（方法上，得有@Bean） 
其设置类型包括：

- Singleton （单例,一个Spring容器中只有一个bean实例，默认模式）, 
- Protetype （每次调用新建一个bean）, 
- Request （web项目中，给每个http request新建一个bean）, 
- Session （web项目中，给每个http session新建一个bean）, 
- GlobalSession（给每一个 global http session新建一个Bean实例）

**@PostConstruct**由JSR-250提供，在构造函数执行完之后执行，等价于xml配置文件中bean的initMethod

**@PreDestory** 由JSR-250提供，在Bean销毁之前执行，等价于xml配置文件中bean的destroyMethod



**Value注解**

**@Value** 为属性注入值（属性上）

```java
》注入普通字符
@Value("Michael Jackson")
String name;

》注入表达式结果
@Value("#{ T(java.lang.Math).random() * 100 }") 
String randomNumber;

》注入其它bean属性
@Value("#{domeClass.name}")
String name;

》注入文件资源
@Value("classpath:com/hgs/hello/test.txt")
String Resource file;

》注入网站资源
@Value("http://www.cznovel.com")
Resource url;

》注入配置文件
@Value("${book.name}")
String bookName;
```



**处理常见的 HTTP 请求类型：**

**5 种常见的请求类型:**

- **GET** ：请求从服务器获取特定资源。举个例子：`GET /users`（获取所有学生）
- **POST** ：在服务器上创建一个新的资源。举个例子：`POST /users`（创建学生）
- **PUT** ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：`PUT /users/12`（更新编号为 12 的学生）
- **DELETE** ：从服务器删除特定的资源。举个例子：`DELETE /users/12`（删除编号为 12 的学生）
- **PATCH** ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少。

> `@GetMapping("users")`	 等价于 `@RequestMapping(value="/users",method=RequestMethod.GET)`
> `@PostMapping("users")`   等价于 `@RequestMapping(value="/users",method=RequestMethod.POST)`
>
> `@PutMapping("/users/{userId}")` 等价于`@RequestMapping(value="/users/{userId}",method=RequestMethod.PUT)   `
>
> `@DeleteMapping("/users/{userId}")`等价于`@RequestMapping(value="/users/{userId}",method=RequestMethod.DELETE)`



**异步相关**

**@EnableAsync** 配置类中，通过此注解开启对异步任务的支持，叙事性AsyncConfigurer接口（类上）

**@Async** 在实际执行的bean方法使用该注解来申明其是一个异步任务（方法上或类上*所有的方法都将异步*，需要@EnableAsync开启异步任务）

**定时任务相关**

**@EnableScheduling** 在配置类上使用，开启计划任务的支持（类上）

**@Scheduled** 来申明这是一个任务，包括cron,fixDelay,fixRate等类型（方法上，需先开启计划任务的支持）

**Enable 注解说明**

这些注解主要用来开启对xxx的支持。 
**@EnableAspectJAutoProxy** 开启对AspectJ自动代理的支持

**@EnableAsync** 开启异步方法的支持

**@EnableScheduling** 开启计划任务的支持

**@EnableWebMvc** 开启Web MVC的配置支持

**@EnableConfigurationProperties** 开启对@ConfigurationProperties注解配置Bean的支持

**@EnableJpaRepositories** 开启对SpringData JPA Repository的支持

**@EnableTransactionManagement** 开启注解式事务的支持

**@EnableTransactionManagement** 开启注解式事务的支持

**@EnableCaching** 开启注解式的缓存支持

**测试相关注解**

**@RunWith** 运行器，Spring中通常用于对JUnit的支持

**@ContextConfiguration** 用来加载配置ApplicationContext，其中classes属性用来加载配置类

```java
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes={TestConfig.class})
```

**SpringMVC部分**

**@EnableWebMvc** 在配置类中开启Web MVC的配置支持，如一些ViewResolver或者MessageConverter等，若无此句，重写WebMvcConfigurerAdapter方法（用于对SpringMVC的配置）。

**@Controller** 声明该类为SpringMVC中的Controller

**@RequestMapping** 用于映射Web请求，包括访问路径和参数（类或方法上）

**@ResponseBody** 支持将返回值放在response内，而不是一个页面，通常用户返回json数据（返回值旁或方法上）

**@RequestBody** 允许request的参数在request体中，而不是在直接连接在地址后面。（放在参数前）

**@PathVariable** 用于接收路径参数，比如`@RequestMapping(“/hello/{name}”)`申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。

**@RestController** 该注解为一个组合注解，相当于@Controller和@ResponseBody的组合，注解在类上，意味着，该Controller的所有方法都默认加上了@ResponseBody。

**@ControllerAdvice** 通过该注解，我们可以将对于控制器的全局配置放置在同一个位置，注解了@Controller的类的方法可使用@ExceptionHandler、@InitBinder、@ModelAttribute注解到方法上， 这对所有注解了 @RequestMapping的控制器内的方法有效。

**@ExceptionHandler** 用于全局处理控制器里的异常

**@InitBinder** 用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中。

**@ModelAttribute** 本来的作用是绑定键值对到Model里，在@ControllerAdvice中是让全局的@RequestMapping都能获得在此处设置的键值对。

### SpringMVC 工作原理了解吗?

![image-20210721172655792](Java面试总结.assets/image-20210721172655792.png)

流程说明（重要）：
1. 客户端（浏览器）发送请求，直接请求到 DispatcherServlet 。
2. DispatcherServlet  根据请求信息调用 HandlerMapping ，解析请求对应的 Handler 。
3. 解析到对应的 Handler （也就是我们平常说的 Controller  控制器）后，开始由 HandlerAdapter  适配器处理。
4. HandlerAdapter  会根据 Handler 来调用真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 ModelAndView  对象， Model  是返回的数据对象， View  是个逻辑上的 View 。
6. ViewResolver  会根据逻辑 View  查找实际的 View 。
7. DispaterServlet  把返回的 Model  传给 View （视图渲染）。
8. 把 View  返回给请求者（浏览器）



### 过滤器和拦截器的区别

**①拦截器是基于java的反射机制的，而过滤器是基于函数回调。**

②拦截器不依赖与servlet容器，过滤器依赖与servlet容器。

③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。

④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。

⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。

**⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。**

SpringMVC的机制是由同一个Servlet来分发请求给不同的Controller，其实这一步是在Servlet的service()方法中执行的。所以过滤器、拦截器、service()方法，dispatc()方法的执行顺序应该是这样的，大致如下图：

![img](Java面试总结.assets/3145530-7536e04d98d458c7.png)![img](Java面试总结.assets/c0d9ebd67cd2e22667110755bd0e4b65.png)

拦截器是被包裹在过滤器之中的。

过滤器Filter是在请求进入容器后，但在进入servlet之前进行预处理，请求结束是在servlet处理完以后。

拦截器 Interceptor 是在请求进入servlet后，在进入Controller之前进行预处理的，Controller 中渲染了对应的视图之后请求结束。





### Spring 中都用到了哪些设计模式?

（1）**工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例；**

- Spring使用工厂模式可以通过 `BeanFactory` 或 `ApplicationContext` 创建 bean 对象。

**（2）单例模式：Bean默认为单例模式。**

**（3）代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；**

**（4）模板方法：用来解决代码重复的问题。比如: jdbcTemplate,RestTemplate, JmsTemplate, JpaTemplate。**

（5）观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现--ApplicationListener

**（6）适配器模式 : spring MVC 中用到了适配器模式适配 Controller，Spring AOP 的增强或通知(Advice)使用到了适配器模式，与之相关的接口是`AdvisorAdapter ` 。**

- 在Spring MVC中，`DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由`HandlerAdapter` 适配器处理。`HandlerAdapter` 作为期望接口，具体的适配器实现类用于对目标类进行适配，`Controller` 作为需要适配的类。

- 我们知道 Spring AOP 的实现是基于代理模式，但是 Spring AOP 的增强或通知(Advice)使用到了适配器模式，与之相关的接口是`AdvisorAdapter ` 。

  Advice 常用的类型有：

  `BeforeAdvice`（目标方法调用前,前置通知）、

  `AfterAdvice`（目标方法调用后,后置通知）、

  `AfterReturningAdvice`(目标方法执行结束后，return之前)等等。

  每个类型Advice（通知）都有对应的拦截器:`MethodBeforeAdviceInterceptor`、`AfterReturningAdviceAdapter`、`AfterReturningAdviceInterceptor`。

  Spring预定义的通知要通过对应的适配器，适配成 `MethodInterceptor`接口(方法拦截器)类型的对象（如：`MethodBeforeAdviceInterceptor` 负责适配 `MethodBeforeAdvice`）。

（7）**装饰者模式：**

装饰者模式可以动态地给对象添加一些额外的属性或行为。相比于使用继承，装饰者模式更加灵活。简单点儿说就是当我们需要修改原有的功能，但我们又不愿直接去修改原有的代码时，设计一个Decorator套在原有代码外面。其实在 JDK 中就有很多地方用到了装饰者模式，比如 `InputStream`家族，`InputStream` 类下有 `FileInputStream` (读取文件)、`BufferedInputStream` (增加缓存,使读取文件速度大大提升)等子类都在不修改`InputStream` 代码的情况下扩展了它的功能。

![image-20210722145724094](Java面试总结.assets/image-20210722145724094.png)

Spring 中配置 DataSource 的时候，DataSource 可能是不同的数据库和数据源。我们能否根据客户的需求在少修改原有类的代码下动态切换不同的数据源？

Spring 中用到的包装器模式在类名上含有 `Wrapper`或者 `Decorator`。这些类基本上都是动态地给一个对象添加一些额外的职责。



### Spring AOP 和 AspectJ AOP 有什么区别?

**Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。

Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，

如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。



### Spring使用 BeanFactory或 ApplicationContext 创建 bean 对象的区别

- `BeanFactory` ：延迟注入(使用到某个 bean 的时候才会注入),相比于`ApplicationContext` 来说会占用更少的内存，程序启动速度更快。
- `ApplicationContext` ：容器启动的时候，不管你用没用到，一次性创建所有 bean 。`BeanFactory` 仅提供了最基本的依赖注入支持，` ApplicationContext` 扩展了 `BeanFactory` ,除了有`BeanFactory`的功能还有额外更多功能，所以一般开发人员使用` ApplicationContext`会更多。

**ApplicationContext的三个实现类：**

1. `ClassPathXmlApplication`：把上下文文件当成类路径资源。
2. `FileSystemXmlApplication`：从文件系统中的 XML 文件载入上下文定义信息。
3. `XmlWebApplicationContext`：从Web系统中的XML文件载入上下文定义信息。

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.FileSystemXmlApplicationContext;
 
public class App {
    public static void main(String[] args) {
        ApplicationContext context = new FileSystemXmlApplicationContext(
                "C:/.../src/main/resources/bean-factory-config.xml");
 
        HelloApplicationContext obj = (HelloApplicationContext) context.getBean("helloApplicationContext");
        obj.getMsg();
    }
}

```





### Spring 事务

**Spring 管理事务的方式有几种？** 

1. 编程式事务，在代码中硬编码。(不推荐使用)
2. 声明式事务，在配置文件中配置（推荐使用）

**声明式事务又分为两种：**

1. 基于XML的声明式事务
2. 基于注解的声明式事务



### Spring中的事务的实现原理

1. Spring事务底层是基于数据库事务和AOP机制的
2. 首先对于使用了@Transactional注解的Bean，Spring会创建一个代理对象作为Bean
3. 当调用代理对象的方法时，会先判断该方法上是否加了@Transactional注解
4. 如果加了，那么则利用事务管理器创建一个数据库连接
5. 并且修改数据库连接的autocommit属性为false，禁止此连接的自动提交，这是实现Spring事务非
常重要的一步
6. 然后执行当前方法，方法中会执行sql
7. 执行完当前方法后，如果没有出现异常就直接提交事务
8. 如果出现了异常，并且这个异常是需要回滚的就会回滚事务，否则仍然提交事务
9. Spring事务的隔离级别对应的就是数据库的隔离级别
10. Spring事务的传播机制是Spring事务自己实现的，也是Spring事务中最复杂的
11. Spring事务的传播机制是基于数据库连接来做的，一个数据库连接一个事务，如果传播机制配置为
需要新开一个事务，那么实际上就是先建立一个数据库连接，在此新数据库连接上执行sql



### Spring 事务中的隔离级别有哪几种?

TransactionDefinition 接口中定义了五个表示隔离级别的常量：

- TransactionDefinition.ISOLATION_DEFAULT:  使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别。
- TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
- TransactionDefinition.ISOLATION_READ_COMMITTED:   允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
- TransactionDefinition.ISOLATION_REPEATABLE_READ:  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- TransactionDefinition.ISOLATION_SERIALIZABLE:   最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

### Spring 事务中哪几种事务传播行为? 

什么是事务传播行为？

事务往往在service层进行控制，如果出现service层方法A调用了另外一个service层方法B， A和B方法本身都已经被添加了事务控制，那么A调用B的时候，就需要进行事务的一些协商，这就叫做事务的传播行为。

**支持当前事务的情况：**

TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。

TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。

TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

**不支持当前事务的情况：**

TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。

TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。

TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。

**其他情况：**
TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。



### Spring事务隔离级别与数据库隔离级别不一致怎么办？

**两者的关系：**

数据库是可以控制事务的传播和隔离级别的，Spring在之上又进一步进行了封装，可以在不同的项目、不同的操作中再次对事务的传播行为和隔离级别进行策略控制。

所以说，spring事务本质上使用数据库事务，而数据库事务本质上使用数据库锁，所以spring事务本质上使用数据库锁，开启spring事务意味着使用数据库锁。

Spring事务由 @Transactional 注解实现，隔离级别由它的参数 isolation 控制，Isolation 的 Eum 类中定义了“五个”表示隔离级别的值，其中，`Isolation.DEFAULT `是 PlatfromTransactionManager 默认的隔离级别，它的含义是：`使用数据库默认的事务隔离级别`。

除此之外，另外四个与 JDBC 的隔离级别是相对应的，就好像 Java 里的重写一样，所以说：Spring事务隔离级别是在数据库隔离级别之上又进一步进行了封装。

**不一致会怎么样？**

**以Spring设置的隔离级别为准。**

既然是封装，那么Spring项目应该就是以Spring事务为准的，除非使用 @Transactional（isolation = Isolation.DEFAULT）时，才会使用数据库设置的隔离级别。

JDBC 加载的流程有四步：注册驱动，建立连接，发起请求，输出结果。其中，

```java
conn = DriverManager.getConnection("jdbc:mysql://localhost:3306/my_db","root","root");
```

在创建连接阶段，JDBC 从数据库获取一个连接 Connection 对象，该对象不仅有连接数据库的方法，还有设置**当前连接**的事物隔离级别的方法。

Connection 实体类中包含了 

```java
void setTransactionIsolation(int level) throws SQLException;
```

设置设置**当前连接**的事物隔离级别的方法。该方法的注释说明：尝试将**此连接**对象的事务隔离级别更改为给定的级别，如果在事务期间调用此方法，则结果由实现定义。强调的是本次连接 Connection，所以，**如果 spring 与数据库事务隔离级别不一致时，以 spring 为准。**



### spring事务什么时候会自动回滚？

**Spring事务回滚机制是这样的：当所拦截的方法有指定异常抛出，事务才会自动进行回滚！**

在java中异常的基类为Throwable，他有两个子类xception与Errors。同时RuntimeException就是Exception的子类，只有RuntimeException才会进行回滚；

 我们需要注意的地方有四点： 如果你在开发当中引入Spring进行事务管理，但是事务没能正常的自动回滚，可以对照下面四点，缺一不可。

- ① 被拦截方法-—— 注解式：方法或者方法所在类被@Transactional注解；

- ② 异常—— 该方法的执行过程必须出现异常，这样事务管理器才能被触发，并对此做出处理；

- ③ 指定异常——  默认配置下，事务只会对Error与RuntimeException及其子类这些UNChecked异常，做出回滚。 一般的Exception这些Checked异常不会发生回滚（如果一般Exception想回滚要做出配置）；

- ④ 异常抛出—— 即方法中出现的指定异常，只有在被事务管理器捕捉到以后，事务才会据此进行事务回滚；如果异常被try{}捕捉到，那么事务管理器就无法再捕捉异常，所以就无法做出反应，事务不回滚；

  

### spring事务什么情况会失效？

**事务失效的7种情况：**

1. 未启用spring事务管理功能
2. 方法不是public类型的
3. 数据源未配置事务管理器
4. 自身调用问题
5. 异常类型错误
6. 异常被吞了
7. 业务和spring事务代码必须在一个线程中

#### **1.1、未启用spring事务管理功能**

@EnableTransactionManagement 注解用来启用spring事务自动管理事务的功能，这个注解千万不要忘记写了。

#### **1.2、方法不是public类型的**

@Transaction 可以用在类上、接口上、public方法上，如果将@Trasaction用在了非public方法上，事务将无效。

#### **1.3、数据源未配置事务管理器**

spring是通过事务管理器了来管理事务的，一定不要忘记配置事务管理器了，要注意为每个数据源配置一个事务管理器：

```javascript
@Bean
public PlatformTransactionManager transactionManager(DataSource dataSource) {
    return new DataSourceTransactionManager(dataSource);
}
```

#### **1.4、自身调用问题**

spring是通过aop的方式，对需要spring管理事务的bean生成了代理对象，然后通过代理对象拦截了目标方法的执行，在方法前后添加了事务的功能，所以必须通过代理对象调用目标方法的时候，事务才会起效。

看下面代码，大家思考一个问题：当外部直接调用m1的时候，m2方法的事务会生效么？

```javascript
@Component
public class UserService {
    public void m1(){
        this.m2();
    }
    
    @Transactional
    public void m2(){
        //执行db操作
    }
}
```

显然不会生效，因为m1中通过this的方式调用了m2方法，而this并不是代理对象，this.m2()不会被事务拦截器，所以事务是无效的，如果外部直接调用通过UserService这个bean来调用m2方法，事务是有效的，上面代码可以做一下调整，如下，@1在UserService中注入了自己，此时m1中的m2事务是生效的

```java
@Component
public class UserService {
    @Autowired //@1
    private UserService userService;

    public void m1() {
        this.userService.m2();
    }

    @Transactional
    public void m2() {
        //执行db操作
    }
}
```

**重点：必须通过代理对象访问方法，事务才会生效。**

#### **1.5、异常类型错误**

spring事务回滚的机制：对业务方法进行try catch，当捕获到有指定的异常时，spring自动对事务进行回滚，那么问题来了，哪些异常spring会回滚事务呢？

并不是任何异常情况下，spring都会回滚事务，默认情况下，RuntimeException和Error的情况下，spring事务才会回滚。

也可以自定义回滚的异常类型：

```java
@Transactional(rollbackFor = {异常类型列表})
```

#### **1.6、异常被吞了**

当业务方法抛出异常，spring感知到异常的时候，才会做事务回滚的操作，若方法内部将异常给吞了，那么事务无法感知到异常了，事务就不会回滚了。

如下代码，事务操作2发生了异常，但是被捕获了，此时事务并不会被回滚

```java
@Transactional
public void m1(){
    事务操作1
    try{
        事务操作2，内部抛出了异常
    }catch(Exception e){
        
    }
}
```

#### **1.7、业务和spring事务代码必须在一个线程中**

spring事务实现中使用了ThreadLocal，ThreadLocal大家应该知道吧，可以实现同一个线程中数据共享，必须是同一个线程的时候，数据才可以共享，这就要求业务代码必须和spring事务的源码执行过程必须在一个线程中，才会受spring事务的控制，比如下面代码，方法内部的子线程内部执行的事务操作将不受m1方法上spring事务的控制，这个大家一定要注意

```java
@Transactional
public void m1() {
    new Thread() {
        一系列事务操作
    }.start();
}
```



## MyBatis

### MyBatis

 Mybatis是一个优秀的持久层ORM框架，它对jdbc的操作数据库的过程进行封装，使得开发者只需要关注SQL本身。不需要花费精力去处理一些重复和繁琐的步骤。通过java对象和statement中的sql进行映射生成最终执行的sql语句。最后由mysql框架执行sql并将结果映射成java对象并返回。

### MyBatis的优点

- 基于SQL语句编程，相当灵活。SQL写在XML中，解除sql与程序代码的耦合，便于统一管理。提供XML标签，支持编写动态SQL语句，并可重用
- 消除了 JDBC 大量冗余的代码，不需要手动开关连接；
- 很好的与各种数据库兼容
- 能够与 Spring 很好的集成；
- 提供映射标签，支持对象与数据库的 ORM 字段关系映射；提供对象关系映射标签，支持对象关系组件维护。

### MyBatis框架的缺点

- SQL 语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL 语句的功底有一定要求。
- SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

### MyBatis与Hibernate有哪些不同

- MyBatis是一个半ORM框架，需要自己编写sql语句，灵活性高，但是需要自定义多套sql映射文件，工作量大
- Hibernate数据库无关性好，节省代码，提高效率

### MyBatis 编程步骤

- 通过SqlSessionFactoryBuilder（构造器）创建SqlSessionFactory
- 通过SqlSessionFactory（工厂接口）创建SqlSession
- 通过sqlsession（会话）执行数据库操作
- 调用session.commit()提交事务
- 调用session.close关闭会话

### MyBatis的工作原理

- 读取MyBatis配置文件。（获取MyBatis的运行环境等信息）
- 加载映射文件。（SQL映射文件，其中配置了操作数据库的SQL语句）
- 构造会话工厂：通过MyBatis的环境等配置信息构建会话工厂SqlSessionFactory
- 创建会话对象：有会话工厂创建SqlSession对象，该对象包括了执行SQL语句的所有方法
- Executor执行器：根据SqlSession传递的参数动态的生成需要执行的SQL语句，同时负责查询缓存的维护
- Mappredstatement对象：用于存储要映射的SQL语句的id、参数等信息
- 输入参数映射：参数类型可以为Map、List等集合类型也可以使用基本数据类型和POJO类型
- 输出结果映射：和输入类似。



### Mapper/Dao接口的工作原理是什么

Dao接口就是Mapper接口。

- 接口的全限定名就是映射文件的namespace的值
- 接口的方法名就是映射文件中Mapper的Statement的id值
- 接口方法内的参数就是传递给sql的参数

Mapper接口是没有实现类的，当调用接口方法的时候，`接口的全限定名+方法名`拼接字符串作为key值，可以唯一定位一个MapperStatement。在MyBatis中，每一个<select>、<insert>、<update>、<delete>标签都会被解析为一个MapperStatement对象。

**Mapper接口的工作原理是JDK动态代理，MyBatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。**



### #{}和${}的区别是什么？

- #{}是预编译处理、是占位符， ${}是字符串替换、是拼接符

2. Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 来赋值
3. Mybatis 在处理${}时， 就是把${}替换成变量的值，调用 Statement 来赋值
- 使用#{}可以有效的防止SQL注入，提高系统安全性

  

### 当实体类的属性名和表中的字段名不一致如何处理

- 通过在查询的sql语句中定义字段名的**别名**，让字段名的别名和实体类的属性名一致。
- 通过<resultMap>类映射字段名和实体类属性名的一一对应的关系



### Dao接口的方法，参数不同时，方法能重载吗

Mapper接口里的方法，是不能重载的，因为使用`全限定名+方法名`的保存和寻找策略。所以不能重载。

Mapper接口的工作原理是JDK动态代理，MyBatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。

### MyBatis是如何进行分页的以及分页插件的原理是什么

MyBatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理的分页功能，或者使用分页插件来完成物理分页

分页插件的基本原理就是使用MyBatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect，添加对应的物理分页语句和物理分页参数。

### Mybatis是如何将sql执行机构封装为对象并返回的？有哪些映射形式

- 使用<resultMap>标签，逐一定义数据库列名和对象属性名之间的映射关系。
- 使用sql列的别名功能，将列别名书写为对象属性名

有了列名和属性名的映射关系后，MyBatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的

### MyBatis动态sql

MyBatis动态sql可以在Xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值完成逻辑判断并动态拼接sql功能。

MyBatis提供了九种sql标签

- trim
- where
- set
- foreach
- if
- choose
- when
- otherwise
- bind

### XML文件标签

- select
- insert
- update
- delete
- resultMap
- parameterMap
- sql
- include
- selectKey

### MyBatis的Xml映射文件中，不同的Xml文件id是否可以重复

如果配置了namespace那么id可以重复，要是没有配置namespace，id就不可以重复

原因就是 namespace+id 是作为 Map<String, MapperStatement>的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。



### MyBatis是否支持延迟加载，以及如何实现

Mybatis仅支持association关联对象和collection关联集合对象的延迟加载。可以通过配置lazyLoadingEnabled来进行配置。

**原理**

使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。



### Mybatis 缓存

Mybatis 中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指 SqlSession 级别的缓存，当在同一个 SqlSession 中进行相同的 SQL 语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存 1024 条 SQL。二级缓存是指可以跨 SqlSession 的缓存。是 mapper 级别的缓存，对于 mapper 级别的缓存不同的sqlsession 是可以共享的。

![image-20210722024417631](Java面试总结.assets/image-20210722024417631.png)

**Mybatis 的一级缓存原理（sqlsession 级别）** 

第一次发出一个查询 sql，sql 查询结果写入 sqlsession 的一级缓存中，缓存使用的数据结构是一个 map。 

key：MapperID+offset+limit+Sql+所有的入参 

value：用户信息 

同一个 sqlsession 再次发出相同的 sql，就从缓存中取出数据。如果两次中间出现 commit 操作（修改、添加、删除），本 sqlsession 中的一级缓存区域全部清空，下次再去缓存中查询不到所以要从数据库查询，从数据库查询到再写入缓存。

**二级缓存原理（mapper 级别）**

二级缓存的范围是 mapper 级别（mapper 同一个命名空间），mapper 以命名空间为单位创建缓存数据结构，结构是 map。mybatis 的二级缓存是通过 CacheExecutor 实现的。CacheExecutor 其实是 Executor 的代理对象。所有的查询操作，在 CacheExecutor 中都会先匹配缓存中是否存在，不存在则查询数据库。 

key：MapperID+offset+limit+Sql+所有的入参 

具体使用需要配置： 

1. Mybatis 全局配置中启用二级缓存配置， 全局开关在 **mybatis-config.xml** 中如下配置:

   ```java
   <settings>
     <!--全局地开启或关闭配置文件中的所有映射器已经配置的任何缓存。 -->
     <setting name="cacheEnabled" value="true"/>
   </settings>
   ```

2. 在对应的 Mapper.xml 中配置 cache 节点 

3. 在对应的 select 查询节点中添加 useCache=true

**mybatis二级缓存存在的问题**

**多表操作会产生脏数据**

多表操作一定不能使用二级缓存，例如两个表：role和user_role，如果我想查询出某个用户的全部角色role，就一定会涉及到多表的操作。不管是写到RoleMapper.xml还是UserRoleMapper.xml，或者是一个独立的XxxMapper.xml中。如果使用了二级缓存，都会导致上面这个查询结果可能不正确。

所以，只能在【只有单表操作】的表上使用缓存，不只是要保证这个表在整个系统中只有单表操作，而且和该表有关的全部操作必须全部在一个namespace下。

**解决办法：**通过拦截器判断执行的sql涉及到那些表（可以用jsqlparser解析），然后把相关表的缓存自动清空。但是这种方式对缓存的使用效率是很低的。建议放弃二级缓存，在业务层使用可控制的缓存代替更好。



### MyBatis的接口绑定，以及实现方式

接口绑定：就是在MyBatis中任意定义接口，然后把接口里面的方法和SQL语句进行绑定，我们在使用的时候直接调用接口方法即可

实现方式

- 通过注解绑定
- 通过xml里面写sql语句来绑定，需要指定xml中namespace必须为接口的全路径名。

### Mybatis的mapper接口调用时有哪些要求

- Mapper接口的方法名和mapper.xml中sql的id相同
- Mapper 接口方法的输入参数类型和 mapper.xml 中定义的每个 sql 的parameterType 的类型相同
- Mapper 接口方法的输出参数类型和 mapper.xml 中定义的每个 sql 的resultType 的类型相同
- Mapper.xml 文件中的 namespace 即是 mapper 接口的全限定名

### ResultType和ResultMap的区别

首先MyBatis在查询进行select映射的时候，返回类型可以用resultType也可以用resultMap，其中resultType是直接表示返回类型的，而resultMap则是对外部ResultMap的引用。这两不能同时存在。

在MyBatis进行查询映射的时候，其实查询出来的每一个属性都是放在一个对应的Map中，键是属性名、值是对应的值。

###  简述 Mybatis 的插件运行原理，以及如何编写一个插件

**什么是Mybatis插件**

与其称为Mybatis插件，不如叫Mybatis拦截器，更加符合其功能定位，实际上它就是一个拦截器，应用代理模式，在方法级别上进行拦截。

**支持拦截的方法**

- 执行器Executor（update、query、commit、rollback等方法）；
- 参数处理器ParameterHandler（getParameterObject、setParameters方法）；
- 结果集处理器ResultSetHandler（handleResultSets、handleOutputParameters等方法）；
- SQL语法构建器StatementHandler（prepare、parameterize、batch、update、query等方法）；

Mybatis 仅可以编写针对 ParameterHandler 、 ResultSetHandler 、 StatementHandler 、 Executor  这 4 种接口的插件，Mybatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler  的 invoke() 方法，当然，只会拦截那些你指定需要拦截的方法。

实现 Mybatis 的 Interceptor 接口并复写 intercept() 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，最后，别忘了在配置文件中配置你编写的插件。

### MyBatis有哪些Executor执行器，他们之间的区别是什么

有三种基本的Executor执行器：SimpleExecutor、ReuseExxecutor、BatchExecutor。

#### SimpleExecutor

每执行一次update或者select就开启一个Statement对象，用完就立即关闭。

#### ReuseRxecutor

执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map<String, Statement>内，供下一次使用。简⾔之，就是重复使用 Statement 对象。

#### BatchExecutor

执行update，将所有sql都添加到批处理中，等待同一执行。其缓存了多个Statement对象。每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。



### 简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？

答：Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中， `<parameterMap>` 标签会被解析为 ParameterMap  对象，其每个子元素会被解析为 ParameterMapping 对象。 `<resultMap> `标签会被解析为 ResultMap  对象，其每个子元素会被解析为 ResultMapping  对象。每一个 `<select><insert><update><delete> `标签均会被解析为 MappedStatement  对象，标签内的 sql 会被解析为 BoundSql 对象。



## Spring Boot

### 什么是 Spring Boot？

Spring Boot 是由 Pivotal 团队提供的全新框架，其设计目的是用来**简化 Spring 应用**的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而**使开发人员不再需要定义样板化的配置**。通过这种方式，Spring Boot 致力于在蓬勃发展的快速应用开发领域(rapid application development)成为领导者

### Spring Boot 特点 ？

**一、独立运行**

Spring Boot而且内嵌了各种servlet容器，Tomcat、Jetty等，现在不再需要打成war包部署到容器中，Spring Boot只要打成一个可执行的jar包就能独立运行，所有的依赖包都在一个jar包内。

**二、简化配置**

spring-boot-starter-web启动器自动依赖其他组件，简少了maven的配置

**三、自动配置**

Spring Boot能根据当前类路径下的类、jar包来自动配置bean，如添加一个spring-boot-starter-web启动器就能拥有web的功能，无需其他配置。

**四、无代码生成和XML配置**

Spring Boot配置过程中无代码生成，也无需XML配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的，这也是Spring4.x的核心功能之一。

**五、应用监控**

Spring Boot提供一系列端点可以监控服务及应用，做健康检测



### Spring Boot 有哪些优点？ 

1、减少开发，测试时间和努力。

2、使用 JavaConfig 有助于避免使用 XML。

3、避免大量的 Maven 导入和各种版本冲突。

4、提供意见发展方法。

5、通过提供默认值快速开始开发。

6、没有单独的 Web 服务器需要。这意味着你不再需要启动 Tomcat，Glassfish或其他任何东西。

7、需要更少的配置 因为没有 web.xml 文件。只需添加用@ Configuration 注释的类，然后添加用@Bean 注释的方法，Spring 将自动加载对象并像以前一样对其进行管理。您甚至可以将@Autowired 添加到 bean 方法中，以使 Spring 自动装入需要的依赖关系中。

8、基于环境的配置 使用这些属性，您可以将您正在使用的环境传递到应用程序：-Dspring.profiles.active = {enviornment}。在加载主应用程序属性文件后，Spring 将在（application{environment} .properties）中加载后续的应用程序属性文件。



### Spring Boot 的核心注解`@SpringBootApplication`？ 

启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下3 个注解：

1. `@SpringBootConfiguration：`组合了 @Configuration 注解，实现配置文件的功能。
2. `@EnableAutoConfiguration：`打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能：@SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。
3. `@ComponentScan：`Spring组件扫描，默认扫描该类所在包及其子包下所有带有指定注解的类，将它们自动装配到bean容器中，会被自动装配的注解包括@Controller、@Service、@Component、@Repository等。也可以指定扫描路径。



### 运行Spring Boot有哪几种方式 

1）打包用命令或者放到容器中运行

2）用 Maven/Gradle 插件运行

3）直接执行 main 方法运行

### 什么是Spring Boot Starters？

Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成Spring及其他技术，而不需要到处找示例代码和依赖包。

如你想使用Spring JPA访问数据库，只要加入springboot-starter-data-jpa启动器依赖就能使用了。Starters包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。

### 什么是 JavaConfig？

Spring JavaConfig 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯Java 方法。因此它有助于避免使用 XML 配置。

使用 JavaConfig 的优点在于：

1. **面向对象的配置**。由于配置被定义为 JavaConfig 中的类，因此用户可以充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean 方法等。
2. **减少或消除 XML 配置**。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。
3. **类型安全和重构友好**。JavaConfig 提供了一种类型安全的方法来配置 Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。



### Spring Boot自动配置原理？

Spring Boot通过@EnableAutoConfiguration注解开启自动配置，对jar包下的META-INF/spring.factories文件进行扫描，这个文件中包含了可以进行自动配置的类，当满足@Condition注解指定的条件时，便在依赖的支持下进行实例化，注册到Spring容器中。

<img src="Java面试总结.assets/image-20210722155027408.png" alt="image-20210722155027408" style="zoom:80%;" />



### @Condition

在上面的步骤中我们得到了一个动配置类的全限定名数组，这些配置类需要在满足@Condition后才能真正的被注册到Spring容器之中。但在Spring Boot项目中我们更多的是看到@Condition注解的衍生注解，如下：

- @ConditionOnBean	在容器中有指定Bean的条件下。
- @ConditionalOnMissingBean	在容器中没有指定Bean的条件下。
- @ConditionOnClass	在classpath类路径下有指定类的条件下。
- @ConditionalOnMissingClass	在classpath类路径下没有指定类的条件下。
- @ConditionalOnResource	类路径是否有指定的值。
- @ConditionalOnWebApplication	在项目是一个Web项目的条件下。
- @ConditionOnProperty	在指定的属性有指定的值条件下。
- ......



### Spring Boot 的加载流程

<img src="Java面试总结.assets/20200806150352650.png" alt="img"  />

1. SpringBoot的启动类是TestApplication，以注解@SpringBootApplication注明。

   该启动类默认只有一个main方法，调用的是SpringApplication.run方法。

   ```java
   @SpringBootApplication
   public class TestApplication {
       public static void main(String[] args) {
           SpringApplication.run(TestApplication.class, args);
       }
   }
   ```

2. 启动程序执行SpringApplication.run方法，run方法创建了一个SpringApplication实例并执行run方法。

   ```java 
   public static ConfigurableApplicationContext run(Object source, String... args) {
           return run(new Object[]{source}, args);
       }
   ...
   public static ConfigurableApplicationContext run(Object[] sources, String[] args) {
           return (new SpringApplication(sources)).run(args);//sources为具体的TestApplication.class类
       }
   ...
   ```

   查看SpringApplication构造方法：

   ```java
       public SpringApplication(ResourceLoader resourceLoader, Class<?>... primarySources) {
           this.sources = new LinkedHashSet();
           this.bannerMode = Mode.CONSOLE;
           this.logStartupInfo = true;
           this.addCommandLineProperties = true;
           this.addConversionService = true;
           this.headless = true;
           this.registerShutdownHook = true;
           this.additionalProfiles = Collections.emptySet();
           this.isCustomEnvironment = false;
           this.lazyInitialization = false;
           this.applicationContextFactory = ApplicationContextFactory.DEFAULT;
           this.applicationStartup = ApplicationStartup.DEFAULT;
           this.resourceLoader = resourceLoader;
           Assert.notNull(primarySources, "PrimarySources must not be null");
           this.primarySources = new LinkedHashSet(Arrays.asList(primarySources));
           this.webApplicationType = WebApplicationType.deduceFromClasspath();
           this.bootstrapRegistryInitializers = this.getBootstrapRegistryInitializersFromSpringFactories();
           this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class));
           this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class));
           this.mainApplicationClass = this.deduceMainApplicationClass();
       }
   ```

   初始化方法主要做了几步：

   1. **配置source**，将source放入SpringApplication的sources属性中管理，sources是一个LinkedHashSet()，这意味着我们可以同时创建多个自定义不重复的Application，但是目前只有一个。

   2. **配置是否为web环境**(javax.servlet.Servlet和org.springframework.web.context.ConfigurableWebApplicationContext都必须在类加载器中存在，并设置到webEnvironment属性中 。
   3. **创建初始化构造器**，从spring.factories中找出ApplicationContextInitializer并设置到初始化器initializers。
   4. **配置应用监听器**，spring.factories中找出ApplicationListener，并实例化后设置到SpringApplication的监听器listeners属性中。这个过程就是找出所有的应用程序事件监听器。
   5. **配置应用的主方法所在类**。

3. SpringApplication构造和初始化完成后，便是运行其run方法：

   ```java
       public ConfigurableApplicationContext run(String... args) {
           StopWatch stopWatch = new StopWatch(); // 构造一个任务执行观察器
           stopWatch.start();// 开始执行，记录开始时间
           DefaultBootstrapContext bootstrapContext = this.createBootstrapContext();
           ConfigurableApplicationContext context = null;
           // 配置Headless属性，Headless模式是在缺少显示屏、键盘或者鼠标时候的系统配置
           this.configureHeadlessProperty();
           // 获取SpringApplicationRunListeners，内部只有一个EventPublishingRunListener
           SpringApplicationRunListeners listeners = this.getRunListeners(args);
           //启动监听
           listeners.starting(bootstrapContext, this.mainApplicationClass);
   
           try {
                // 构造一个应用程序参数持有类
               ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
                // 加载配置环境
               ConfigurableEnvironment environment = this.prepareEnvironment(listeners, bootstrapContext, applicationArguments);
               this.configureIgnoreBeanInfo(environment);
               // 打印Banner信息
               Banner printedBanner = this.printBanner(environment);
               // 创建Spring容器
               context = this.createApplicationContext();
               context.setApplicationStartup(this.applicationStartup);
               // 设置容器配置环境，监听等
               this.prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner);
               // 刷新容器
               this.refreshContext(context);
               this.afterRefresh(context, applicationArguments);
               stopWatch.stop();// 执行结束，记录执行时间
               if (this.logStartupInfo) {
                   (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch);
               }
   
               listeners.started(context);//发布ApplicationStartedEvent事件
               this.callRunners(context, applicationArguments);
           } catch (Throwable var10) {
               this.handleRunFailure(context, var10, listeners);
               throw new IllegalStateException(var10);
           }
   
           try {
               listeners.running(context);//发布ApplicationReadyEvent事件
               return context;// 返回Spring容器
           } catch (Throwable var9) {
               this.handleRunFailure(context, var9, (SpringApplicationRunListeners)null);
               throw new IllegalStateException(var9);
           }
       }
   ```

   run方法过程分析如上，该方法几个关键步骤如下：

   1. **创建一个StopWatch并执行start方法，这个类主要记录任务的执行时间；**

   2. 配置**Headless**属性，Headless模式是在缺少显示屏、键盘或者鼠标时候的系统配置；

   3. 在文件META-INF\spring.factories中获取**应用启动监听器SpringApplicationRunListener**接口的实现类EventPublishingRunListener，主要发布SpringApplicationEvent；

   4. 构造一个应用程序参数持有类，DefaultApplicationArguments类；

   5. **创建配置环境ConfigurableEnvironment**，并设置比如环境信息，系统熟悉，输入参数和profile信息；

   6. **打印Banner信息；**

   7. **创建Spring容器：ApplicationContext**，根据WebApplicationTyp来创建Context类，如果非web项目则创建AnnotationConfigApplicationContext，在构造方法中初始化AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner；

   8. **设置容器配置环境，监听等**，准备application的上下文初始化；

   9. **refresh() 刷新上下文**，在这里真正加载bean到容器中。如果是web容器，会在onRefresh方法中创建一个Server并启动。

      refresh()方法做了很多核心工作比如BeanFactory的设置，BeanFactoryPostProcessor接口的执行、BeanPostProcessor接口的执行、自动化配置类的解析、spring.factories的加载、bean的实例化、条件注解的解析、国际化的初始化等等。
      

   

### SpringBoot中配置文件的加载顺序是怎样的？

优先级从高到低，高优先级的配置覆盖低优先级的配置，所有配置会形成互补配置。
1. 命令行参数。所有的配置都可以在命令行上进行指定；
2. Java系统属性（System.getProperties()）；
3. 操作系统环境变量 ；
4. jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件
5. jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 再来加载不带profile
6. jar包外部的application.properties或application.yml(不带spring.profile)配置文件
7. jar包内部的application.properties或application.yml(不带spring.profile)配置文件
8. @Configuration注解类上的@PropertySource





## RabbitMQ

### 什么是 rabbitmq?

采用 AMQP (Advanced Message Queuing Protocol，高级消息队列协议）的一种消息队列技术,最大的特点就是消费并不需要确保提供方存在，实现了服务之间的高度解耦。

RabbitMQ的基础架构如下：

![image-20210722171506436](Java面试总结.assets/image-20210722171506436.png)



### 为什么要使用 rabbitmq？

1. 在分布式系统下具备异步、削峰、负载均衡等一系列高级功能；
2. 拥有持久化的机制，进程消息，队列中的信息也可以保存下来。
3. 实现消费者和生产者之间的解耦。

4. 对于高并发场景下，利用消息队列可以使得同步访问变为串行访问达到一定量的限流，利于数据库的操作。

5. 可以使用消息队列达到异步下单的效果，排队中，后台进行逻辑下单



### 使用 rabbitmq 的场景 

1. 服务间异步通信
2. 顺序消费
3. 定时任务
4. 请求削峰



### Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别？ 

对于吞吐量来说kafka和RocketMQ支撑高吞吐，ActiveMQ和RabbitMQ比他们低一个数量级。对于延迟量来说RabbitMQ是最低的。

![image-20210722170828342](Java面试总结.assets/image-20210722170828342.png)



### mq 的缺点 

**系统可用性降低**

系统引入的外部依赖越多，越容易挂掉，本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一MQ 挂了怎么办？

**系统复杂性提高**

硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？

**一致性问题**

A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，你这数据就不一致了。

所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉。



### RabbitMQ 中的相关概念

- **Broker：**接收和分发消息的应用，RabbitMQ Server就是 Message Broker。
- **Virtual host：**出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个vhost，每个用户在自己的 vhost 创建 exchange／queue 等。
- **Connection：**publisher／consumer 和 broker 之间的 TCP 连接。
- **Channel：**如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的 channel 进行通讯，AMQP method 包含了channel id 帮助客户端和message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销。
- **Exchange：**message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast)。
- **Queue：**消息最终被送到这里等待 consumer 取走。
- **Binding：**exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key。Binding 信息被保存
  到 exchange 中的查询表中，用于 message 的分发依据。



### RabbitMQ  6 种工作模式

RabbitMQ 提供了 6 种工作模式：简单模式、work queues、Publish/Subscribe 发布与订阅模式、Routing路由模式、Topics 主题模式、RPC 远程调用模式（远程调用，不太算 MQ；暂不作介绍）。（现在好像又多了一种Publisher Confirms 模式，详细信息看下面的官方链接）

官网对应模式介绍：https://www.rabbitmq.com/getstarted.html

![image-20210722171958605](Java面试总结.assets/image-20210722171958605.png)

#### 简单模式(Hello World)：

![image-20210722185142949](Java面试总结.assets/image-20210722185142949.png)

在上图的模型中，有以下概念：

- P：生产者，也就是要发送消息的程序
- C：消费者：消息的接收者，会一直等待消息到来
- queue：消息队列，图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息



#### 工作队列模式(Work queues)：

![image-20210722185334935](Java面试总结.assets/image-20210722185334935.png)

-  Work Queues：与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息。消费者之间对于同一个消息的关系是`竞争`的关系。
- 应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。



####  订阅模式( Pub/Sub):

![img](Java面试总结.assets/python-three.png)

在订阅模型中，多了一个 Exchange 角色，而且过程略有变化：

-  P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机）
- C：消费者，消息的接收者，会一直等待消息到来
-  Queue：消息队列，接收消息、缓存消息

 Exchange：交换机（X）。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。

**Exchange有常见以下3种类型：**

- ➢ Fanout：广播，将消息交给所有绑定到交换机的队列
- ➢ Direct：定向，把消息交给符合指定routing key 的队列
- ➢ Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列
- ➢ Headers Exchanges：不处理路由键。而是根据发送的消息内容中的headers属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到RabbitMQ时会取到该消息的headers与Exchange绑定时指定的键值对进行匹配；如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers属性是一个键值对，可以是Hashtable，键值对的值可以是任何类型。而fanout，direct，topic 的路由键都需要要字符串形式的。

> Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失！



#### 路由模式(Routing ):

- 队列与交换机的绑定，不能是任意绑定了，而是要指定一个 RoutingKey（路由key）
- 消息的发送方在向 Exchange 发送消息时，也必须指定消息的 RoutingKey
- Exchange 不再把消息交给每一个绑定的队列，而是根据消息的 Routing Key 进行判断，只有队列的Routingkey 与消息的 Routing key 完全一致，才会接收到消息

![image-20210722190658599](Java面试总结.assets/image-20210722190658599.png)

图解：

- P：生产者，向 Exchange 发送消息，发送消息时，会指定一个routing key
- X：Exchange（交换机），接收生产者的消息，然后把消息递交给与 routing key 完全匹配的队列
- C1：消费者，其所在队列指定了需要 routing key 为 error 的消息
- C2：消费者，其所在队列指定了需要 routing key 为 info、error、warning 的消息



####  通配符模式(Topics):

- Topic 类型与 Direct 相比，都是可以根据 RoutingKey 把消息路由到不同的队列。只不过 Topic 类型Exchange 可以让队列在绑定 Routing key 的时候使用通配符！
- Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 
- 通配符规则：# 匹配一个或多个词，* 匹配不多不少恰好1个词，例如：item.# 能够匹配 item.insert.abc 或者 item.insert，item.* 只能匹配 item.insert

![image-20210722190832401](Java面试总结.assets/image-20210722190832401.png)

图解：

Queue1：绑定的是 `*.orange.*` ，因此凡是以`orange`在中间部分的 routing key 都会被匹配到

Queue2：绑定的是 `*.*.rabbite`和`Lazy.#`，因此凡是以 `*.*.rabbite`和`Lazy`开头的 routing key 都会被匹配



> 工作模式总结：
>
> 1.简单模式 HelloWorld
>
> 一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。
>
> 2.工作队列模式 Work Queue
>
> 一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。
>
> 3.发布订阅模式 Publish/subscribe
>
> 需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。
>
> 4.路由模式 Routing
>
> 需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。
>
> 5.通配符模式 Topic
>
> 需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。



### 消息基于什么传输？ 

由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。

### abbitMQ 为什么需要信道？为什么不是TCP直接通信？

1. TCP的创建和销毁，开销大，创建需要三次握手，销毁需要四次分手

2. 如果不使用信道，那么引用程序就会使用TCP的方式连接到rabbitmq，高峰时每秒成千上万条连接会造成资源的巨大浪费(一条tcp消耗资源，成千上万的tcp会非常消耗资源)，而且操作系统每秒处理TCP连接数量也是有限的，必定会造成性能瓶颈

3. 信道的原理是一条线程一条信道，多条线程多条信道共同使用一条TCP连接。一条TCP连接可以容纳无限的信道，及时每秒造成成千上万的请求也不会造成性能瓶颈



### 如何保证消息的可靠传输？

**数据的丢失问题，可能出现在生产者、MQ、消费者中：**

**生产者丢失**：

生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。

- **可以选择用 RabbitMQ 提供的事务功能**，就是生产者发送数据之前开启 RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。吞吐量会下来，因为太耗性能。

  使用channel下列方法，完成事务控制：

  - txSelect()： 用于将当前channel设置成transaction模式

  - txCommit()：用于提交事务
  - txRollback()：用于回滚事务

- **可以开启confirm模式**，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个ack消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ 接收了之后会异步回调你一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用confirm机制的 。

  

  > **rabbitmq 整个消息投递的路径为：**
  >
  > `producer--->rabbitmq broker--->exchange--->queue--->consume`
  >
  > 消息从 producer 到 exchange 则会返回一个 confirmCallback 。
  >
  > 消息从 exchange-->queue 投递失败则会返回一个 returnCallback 。
  >
  > - ➢ 设置ConnectionFactory的publisher-confirms="true" 开启 **确认模式**。
  > - ➢ 使用rabbitTemplate.setConfirmCallback设置回调函数。当消息发送到exchange后回调confirm方法。在方法中判断ack，如果为true，则发送成功，如果为false，则发送失败，需要处理。
  > - ➢ 设置ConnectionFactory的publisher-returns="true" 开启 **退回模式。**
  > - ➢ 使用rabbitTemplate.setReturnCallback设置退回函数，当消息从exchange路由到queue失败后，如果设置了rabbitTemplate.setMandatory(true)参数，则会将消息退回给producer。并执行回调函数returnedMessage。



**MQ中丢失**：

就是 RabbitMQ 自己弄丢了数据，这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。

设置持久化有两个步骤：

创建 queue 的时候将其设置为**持久化**，这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是不会持久化 queue 里的数据。第二个是发送消息的时候将消息的deliveryMode 设置为 2，就是将消息设置为持久化的，此时的RabbitMQ 就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个 queue 里的数据。持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ 挂了，就会导致内存里的一点点数据丢失 。



**消费端丢失：**

你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

这个时候得用 RabbitMQ 提供的ack机制，简单来说，就是你关闭 RabbitMQ 的自动ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

> **ack指Acknowledge，确认。 表示消费端收到消息后的确认方式。**
>
> 有三种确认方式：
>
> - 自动确认：acknowledge="none"
> - 手动确认：acknowledge="manual"
> -  根据异常情况确认：acknowledge="auto"，（这种方式使用麻烦，不作讲解）
>
> 其中自动确认是指，当消息一旦被Consumer接收到，则自动确认收到，并将相应 message 从 RabbitMQ 的消息缓存中移除。但是在实际业务处理中，很可能消息接收到，业务处理出现异常，那么该消息就会丢失。如果设置了手动确认方式，则需要在业务处理成功后，调用channel.basicAck()，手动签收，如果出现异常，则调用channel.basicNack()方法，让其自动重新发送消息。

![image-20210722193811373](Java面试总结.assets/image-20210722193811373.png)



### TTL

➢ TTL 全称 Time To Live（存活时间/过期时间）。

➢ 当消息到达存活时间后，还没有被消费，会被自动清除。

➢ RabbitMQ可以对消息设置过期时间，也可以对整个队列（Queue）设置过期时间。

> ➢ 设置队列过期时间使用参数：x-message-ttl，单位：ms(毫秒)，会对整个队列消息统一过期。
> ➢ 设置消息过期时间使用参数：expiration。单位：ms(毫秒)，当该消息在队列头部时（消费时），会单独判断这一消息是否过期。
> ➢ 如果两者都进行了设置，以时间短的为准。

![image-20210722200901766](Java面试总结.assets/image-20210722200901766.png)

### 死信队列

队列绑定死信交换机：

给队列设置参数： x-dead-letter-exchange 和 x-dead-letter-routing-key

- 死信交换机和死信队列和普通的没有区别
- 当消息成为死信后，如果该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队
  列
- 消息成为死信的三种情况：
  1. 队列消息长度到达限制；
  2. 消费者拒接消费消息，并且不重回队列；
  3. 原队列存在消息过期设置，消息到达超时时间未被消费；

![image-20210722200624093](Java面试总结.assets/image-20210722200624093.png)



### 延迟队列

延迟队列，即消息进入队列后不会立即被消费，只有到达指定时间后，才会被消费。

需求：

1. 下单后，30分钟未支付，取消订单，回滚库存。
2. 新用户注册成功7天后，发送短信问候。

![image-20210722201105478](Java面试总结.assets/image-20210722201105478.png)

很可惜，在RabbitMQ中并未提供延迟队列功能。但是可以使用：TTL+死信队列 组合实现延迟队列的效果。

![image-20210722201132394](Java面试总结.assets/image-20210722201132394.png)







## 计算机网络

###  OSI与TCP/IP各层的结构？

![image-20210721030634326](Java面试总结.assets/image-20210721030634326.png)

**答:OSI分层 （7层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。**

**TCP/IP分层（4层）：网络接口层、 网际层、运输层、 应用层。**

**五层协议 （5层）：物理层、数据链路层、网络层、运输层、 应用层。**

**每一层的作用如下：**

物理层：通过媒介传输比特,确定机械及电气规范（比特Bit）

数据链路层：将比特组装成帧和点到点的传递（帧Frame）

网络层：负责数据包从源到宿的传递和网际互连（包PackeT）

传输层：提供端到端的可靠报文传递和错误恢复（段Segment）

会话层：建立、管理和终止会话（会话协议数据单元SPDU）

表示层：处理两个通信系统中信息交换的表示方式，对数据进行翻译、加密和压缩（表示协议数据单元PPDU）

应用层：允许访问OSI环境的手段（应用协议数据单元APDU）

**每一层的协议如下：**

物理层：CLOCK、IEEE802.2 （中继器，集线器）

数据链路：PPP、FR、HDLC、VLAN、MAC （网桥，交换机）

网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器）

传输层：TCP、UDP、SPX

会话层：NFS、SQL、NETBIOS、RPC

表示层：JPEG、MPEG、ASII

应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS

![preview](https://pic3.zhimg.com/v2-2af488004591cbc12cd82c44518523de_r.jpg)



### TCP与UDP 协议的区别？

| 传输控制协议（TCP）                        | 用户数据报协议（UDP）                         |
| ------------------------------------------ | --------------------------------------------- |
| TCP是一种面向连接的数据传输协议            | UDP是面向数据报的数据传输协议                 |
| 保证数据可以安全到达接收器                 | 无法保证数据可以安全到达接收器                |
| 使用数据确认和流控制来执行深入的错误检查   | 使用校验和来搜索传输中的基本错误              |
| 数据排序由TCP处理                          | 数据排序需要由应用程序处理                    |
| TCP比UDP慢，并且是重量级协议               | UDP比TCP更快，是一种轻量级协议                |
| HTTP，SMPT，FTP和Telnet使用TCP进行数据交换 | DNS，DHCP，TFTP，VoIP和RIP利用UDP进行数据交换 |
| TCP不允许广播                              | UDP允许广播                                   |
| 标头长度可以在20到80个字节之间变化         | 标头长度固定为8个字节                         |

### TCP 报文格式

![image-20210826103457609](Java面试总结.assets/image-20210826103457609.png)



### TCP三次握手与四次挥手？

#### 三次握手过程理解

![image-20210721031313777](Java面试总结.assets/image-20210721031313777.png)

第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。

第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；

第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。

> 客户端–发送带有 SYN 标志的数据包–一次握手–服务端
> 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端
> 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端

#### 四次挥手过程理解

![image-20210721031401050](Java面试总结.assets/image-20210721031401050.png)

1）**客户端进程发出连接释放报文，并且停止发送数据。**释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，**客户端进入FIN-WAIT-1（终止等待1）状态**。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

2）**服务器收到连接释放报文，发出确认报文，**ACK=1，ack=u+1，并且带上自己的序列号seq=v，**此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。**TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

3）**客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态**，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

4）**服务器将最后的数据发送完毕后，就向客户端发送连接释放报文**，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。

5）**客户端收到服务器的连接释放报文后，必须发出确认，A**CK=1，ack=w+1，而自己的序列号是seq=u+1，此时，**客户端就进入了 TIME-WAIT（时间等待）状态。**注意此时TCP连接还没有释放，必须经过2∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

6）**服务器只要收到了客户端发出的确认，立即进入CLOSED状态。**同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些



#### 【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？

这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。

但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了，但是还能接收数据；但未必己方所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示同意现在关闭连接，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

#### 【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？

**第一，为了保证A发送的最后一个ACK报文能够到达B。**这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常的步骤进入CLOSED状态。 
**第二，避免上一次TCP连接的数据包影响到下一次的TCP连接。**A在发送完ACK报文段后，再经过2MSL(Maximum Segment Lifetime)时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求的报文段。 

#### 【问题3】为什么不能用两次握手进行连接？

3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。

#### 【问题4】如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。



### TCP 协议如何保证可靠传输？

1. 应用数据被分割成 TCP 认为最适合发送的数据块。 
2. **确认应答+序列号：TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。** 
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，⽬的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
4. **TCP 的接收端会丢弃重复的数据**。 
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 **（TCP 利用滑动窗口实现流量控制）**
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ协议（自动重传请求 Automatic Repeat-reQuest，ARQ）：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待⽬的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

#### 流量控制

**什么是流量控制？**

如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止分组丢失，它是构成TCP可靠性的一方面。

**如何实现流量控制？**

由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。

**流量控制引发的死锁？怎么避免死锁的发生？**

当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。
为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。

#### 拥塞控制

拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；

常用的方法就是：（ 1 ）慢开始、拥塞避免（ 2 ）快重传、快恢复。

**拥塞控制的算法**

**（一）慢开始算法：**

慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。

**（二）拥塞避免算法：**

拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。

**（三）快重传算法：**

快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

**（四）快恢复算法：**

与快重传配合使用的还有快恢复算法，其过程有以下两个要点：

1. 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh 减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。
2. 由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的拥塞，就不会一连有好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口 cwnd 现在不设置为 1），而是把 cwnd 值设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

![img](Java面试总结.assets/2010101123101842.jpg)



### 什么是TCP粘包问题？

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

**造成TCP粘包的原因**

（1）发送方原因

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

- 只有上一个分组得到确认，才会发送下一个分组
- 收集多个小分组，在一个确认到来时一起发送

 Nagle 算法造成了发送方可能会出现粘包问题

（2）接收方原因

TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

**如何处理粘包现象？**

（1）发送方

对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

（2）接收方

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

（2）应用层

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成，但是如何判断每条数据的长度呢？

1. 格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
2. 发送长度：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。



### TCP半关闭,半连接,半打开

**半关闭：**
当TCP链接中A向B发送 FIN 请求关闭，另一端B回应ACK之后，并没有立即发送 FIN 给A，A方处于半连接状态（半开关），此时A可以接收B发送的数据，但是A已经不能再向B发送数据。

**半连接：**
发生在TCP三次握手中，如果A向B发起链接，B也按照正常情况响应了，但是A不进行三次握手，这就是半连接。
**半连接攻击：半连接，会造成B分配的内存资源就一直这么耗着，直到资源耗尽。（SYN攻击）**

**半打开：**
如果一方关闭或者异常关闭（断电，断网），而另一方并不知情，这样的链接称之为半打开。处于半打开的连接，如果双方不进行数据通信，是发现不了问题的，只有在通信是才真正的察觉到这个连接已经处于半打开状态，如果双方不传输数据的话，仍处于连接状态的一方就不会检测另外一方已经出现异常。

**解决方法：**

如何解决半打开问题，引入心跳机制就可以察觉半打开。

如果需要发数据的话，这边收到之后 其实发现这个连接并不存在了，就会回复RST包告知，这个时候就需要重新建立连接了。



**SYN泛洪攻击：**

SYN攻击利用的是TCP的三次握手机制，攻击端利用伪造的 IP 地址向被攻击端发出请求，而被攻击端发出的响应报文将永远发送不到目的地，那么被攻击端在等待关闭这个连接的过程中消耗了资源，如果有成千上万的这种连接，主机资源将被耗尽，从而达到攻击的目的。

**SYN泛洪攻击的防范措施：**

对于SYN泛洪攻击的防范，优化主机系统设置是常用的手段。如降低SYN timeout时间，使得主机尽快释放半连接的占用；又比如采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文。此外合理地采用防火墙等外部网络安全设施也可缓解SYN泛洪攻击。



### Socket 通信的基本步骤

<img src="Java面试总结.assets/image-20210917232632976.png" alt="image-20210917232632976" style="zoom:150%;" />

根据socket通信基本流程图，总结通信的基本步骤：
服务器端：
第一步：创建一个用于监听连接的Socket对像；
第二步：用指定的端口号和服务器的ip建立一个EndPoint对像；
第三步：用socket对像的Bind()方法绑定EndPoint；
第四步：用socket对像的Listen()方法开始监听；
第五步：接收到客户端的连接，用socket对像的Accept()方法创建一个新的用于和客户端进行通信的socket对像;
第六步：通信结束后一定记得关闭socket;
客户端：
第一步：建立一个Socket对像；
第二步：用指定的端口号和服务器的ip建立一个EndPoint对像；
第三步：用socket对像的Connect()方法以上面建立的EndPoint对像做为参数，向服务器发出连接请求；
第四步：如果连接成功，就用socket对像的Send()方法向服务器发送信息；
第五步：用socket对像的Receive()方法接受服务器发来的信息 ;
第六步：通信结束后一定记得关闭socket；

<img src="Java面试总结.assets/image-20210917232728209.png" alt="image-20210917232728209"  />

服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。



### 在浏览器中输入url地址 ->> 显示页面的过程

> 1. DNS解析
> 2. TCP连接
> 3. 发送HTTP请求
> 4. 服务器处理请求并返回HTTP报文
> 5. 浏览器解析渲染页面
> 6. 连接结束

1、客户端浏览器通过DNS解析到`www.baidu.com`的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.181.27.48，然后通过TCP进行封装数据包，输入到网络层。

2、在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。

3、客户端的网络层不用关心应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，就是通过查找路由表决定通过那个路径到达服务器。

4、客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

![image-20210721034623062](Java面试总结.assets/image-20210721034623062.png)



### 什么是DNS?DNS端口号是多少?

**DNS**全称是domain name service即:域名解析服务。DNS端口号是 53。

DNS是互联网中的一项核心服务，是用于实现域名和IP地址相互映射的一个分布式数据库，它将简单明了的域名翻译成可由计算机识别的IP地址，使用户可以更快速便捷地访问互联。

### 什么是DNS服务器?

**DNS服务器**就是域名服务器,即提供域名解析的服务器。

互联网连通的是全球资源，单一的域名服务器不足以支撑全部的地址转换操作，因此全球有多套域名服务器相互配合使用。早在1983年互联网就开始采用层次树状结构的命名方法，并使用分布式的域名系统进行解析操作。这样既提升了域名解析的效率，同时也保障了域名解析的稳定性，如果系统中单个域名服务器出现故障，不会对整个DNS系统的正常运行造成太大影响。

### DNS域名解析原理？

DNS的工作原理及过程分下面几个步骤：

![image-20210826021841573](Java面试总结.assets/image-20210826021841573.png)

（1）查看浏览器缓存

当用户通过浏览器访问某域名时，浏览器首先会在自己的缓存中查找是否有该域名对应的 IP 地址（若曾经访问过该域名且没有清空缓存便存在）。

（2）查看系统缓存

当浏览器缓存中无域名对应 IP 则会自动检查用户计算机系统 Hosts 文件 DNS 缓存是否有该域名对应 IP。

（3）查看路由器缓存

当浏览器及系统缓存中均无域名对应 IP 则进入路由器缓存中检查，以上三步均为客服端的 DNS 缓存。

（4）查看ISP DNS 缓存

当在用户客服端查找不到域名对应 IP 地址，则将进入 ISP DNS 缓存中进行查询。比如你用的是电信的网络，则会进入电信的 DNS 缓存服务器中进行查找。

（5）询问根域名服务器

当以上均未完成，则进入根服务器进行查询。全球仅有 13 台根域名服务器，1 个主根域名服务器，其余 12 为辅根域名服务器。根域名收到请求后会查看区域文件记录，若无则将其管辖范围内顶级域名（如.com、.cn等）服务器 IP 告诉本地 DNS 服务器。

（6）询问顶级域名服务器

顶级域名服务器收到请求后查看区域文件记录，若无记录则将其管辖范围内权威域名服务器的 IP 地址告诉本地 DNS 服务器。

（7）询问权威域名（主域名）服务器

权威域名服务器接受到请求后查询自己的缓存，如果没有则进入下一级域名服务器进行查找，并重复该步骤直至找到正确记录。

（8）保存结果至缓存

本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时将该结果反馈给客户端，客户端通过这个 IP 地址即可访问目标Web服务器。至此，DNS递归查询的整个过程结束。



### 为什么DNS既使用TCP又使用UDP？

**DNS在进行区域传输的时候使用TCP协议，其它时候则使用UDP协议;**

DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送（zone transfer）。

区域传输是DNS的事务，对准确性要求比较高，而且会产生大于512字节的数据包，因此使用TCP协议。

**为什么既使用TCP又使用UDP？**

首先了解一下TCP与UDP传送字节的长度限制。

*UDP报文的最大长度为512字节，而TCP则允许报文长度超过512字节*。当DNS查询超过512字节时，协议的TC标志出现删除标志，这时则使用TCP发送。通常传统的UDP报文一般不会大于512字节。

**区域传送时使用TCP，主要有一下两点考虑**

1. 辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。
2. TCP是一种可靠的连接，保证了数据的准确性。

**域名解析时使用UDP协议**

客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

> 大多数情况下，DNS解析请求和响应都很小，使用UDP协议更加高效，虽然没有TCP可靠，但是速度快，消耗的系统资源更少，非常适合少量数据包的传输。
> 一些DNS事务，比如区域传输或其他附加查询，可能会产生大于512字节的数据包，因此使用TCP更加可靠，使用TCP会减少丢包和重新发包的情况，因此更加可靠与高效。



### HTTP协议

**HTTP 简介：**

HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。

HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。

HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。

HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。

**HTTP 特点：**

1. 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。

2. 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。

3. 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。

4. 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。

5. 支持B/S及C/S模式。

### HTTP 状态码

状态代码有三位数字组成，第一个数字定义了响应的类别，共分五种类别:

**1xx：指示信息--表示请求已接收，继续处理**

**2xx：成功--表示请求已被成功接收、理解、接受**

**3xx：重定向--要完成请求必须进行更进一步的操作**

**4xx：客户端错误--请求有语法错误或请求无法实现**

**5xx：服务器端错误--服务器未能实现合法的请求**

常见状态码：

```
200 OK                      //客户端请求成功
400 Bad Request             //客户端请求有语法错误，不能被服务器所理解
401 Unauthorized            //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 
403 Forbidden               //服务器收到请求，但是拒绝提供服务
404 Not Found               //请求资源不存在，eg：输入了错误的URL
500 Internal Server Error   //服务器发生不可预期的错误
503 Server Unavailable      //服务器当前不能处理客户端的请求，一段时间后可能恢复正常
```

[HTTP状态码 | 菜鸟教程 (runoob.com)](https://www.runoob.com/http/http-status-codes.html)

### HTTP 请求方法

根据HTTP标准，HTTP请求可以使用多种请求方法。

HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。

HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。

```
GET     请求指定的页面信息，并返回实体主体。
HEAD     类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头
POST     向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
PUT     从客户端向服务器传送的数据取代指定的文档的内容。
DELETE      请求服务器删除指定的页面。
CONNECT     HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。
OPTIONS     允许客户端查看服务器的性能。
TRACE     回显服务器收到的请求，主要用于测试或诊断。
```

### HTTP 的请求头

HTTP头字段(HTTP header fields),是指在超文本传输协议(HTTP)的请求和响应消息中的消息头部分

它们定义了一个超文本传输协议事务中的操作参数

HTTP头部字段可以自己根据需要定义，因此可能在 Web服务器和浏览器上发现非标准的头字段

下面是一个HTTP请求的请求头：

```
GET /home.html HTTP/1.1 Host: developer.mozilla.org 
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0 
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 
Accept-Language: en-US,en;q=0.5 
Accept-Encoding: gzip, deflate, br 
Referer: https://developer.mozilla.org/testpage.html 
Connection: keep-alive 
Upgrade-Insecure-Requests: 1 
If-Modified-Since: Mon, 18 Jul 2016 02:36:04 GMT 
If-None-Match: "c561c68d0ba92bbeb8b0fff2a9199f722e3a621a" 
Cache-Control: max-age=0 
```

常见的请求字段如下表所示：

| 字段名            | 说明                                                         | 示例                                                         |
| :---------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| Accept            | 能够接受的回应内容类型（Content-Types）                      | Accept: text/plain                                           |
| Accept-Charset    | 能够接受的字符集                                             | Accept-Charset: utf-8                                        |
| Accept-Encoding   | 能够接受的编码方式列表                                       | Accept-Encoding: gzip, deflate                               |
| Accept-Language   | 能够接受的回应内容的自然语言列表                             | Accept-Language: en-US                                       |
| Authorization     | 用于超文本传输协议的认证的认证信息                           | Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==            |
| Cache-Control     | 用来指定在这次的请求/响应链中的所有缓存机制 都必须 遵守的指令 | Cache-Control: no-cache                                      |
| Connection        | 该浏览器想要优先使用的连接类型                               | Connection: keep-alive Connection: Upgrade                   |
| Cookie            | 服务器通过 Set- Cookie （下文详述）发送的一个 超文本传输协议Cookie | Cookie: $Version=1; Skin=new;                                |
| Content-Length    | 以 八位字节数组 （8位的字节）表示的请求体的长度              | Content-Length: 348                                          |
| Content-Type      | 请求体的 多媒体类型                                          | Content-Type: application/x-www-form-urlencoded              |
| Date              | 发送该消息的日期和时间                                       | Date: Tue, 15 Nov 1994 08:12:31 GMT                          |
| Expect            | 表明客户端要求服务器做出特定的行为                           | Expect: 100-continue                                         |
| Host              | 服务器的域名(用于虚拟主机 )，以及服务器所监听的传输控制协议端口号 | Host: en.wikipedia.org:80 Host: en.wikipedia.org             |
| If-Match          | 仅当客户端提供的实体与服务器上对应的实体相匹配时，才进行对应的操作。主要作用时，用作像 PUT 这样的方法中，仅当从用户上次更新某个资源以来，该资源未被修改的情况下，才更新该资源 | If-Match: "737060cd8c284d8af7ad3082f209582d"                 |
| If-Modified-Since | 允许在对应的内容未被修改的情况下返回304未修改                | If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT             |
| If-None-Match     | 允许在对应的内容未被修改的情况下返回304未修改                | If-None-Match: "737060cd8c284d8af7ad3082f209582d"            |
| If-Range          | 如果该实体未被修改过，则向我发送我所缺少的那一个或多个部分；否则，发送整个新的实体 | If-Range: "737060cd8c284d8af7ad3082f209582d"                 |
| Range             | 仅请求某个实体的一部分                                       | Range: bytes=500-999                                         |
| User-Agent        | 浏览器的浏览器身份标识字符串                                 | User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0 |
| Origin            | 发起一个针对 跨来源资源共享 的请求                           | Origin: http://www.example-social-network.com                |



### HTTP工作原理

HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。

以下是 HTTP 请求/响应的步骤：

**1、客户端连接到Web服务器**

一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如，`http://www.baidu.com`。

**2、发送HTTP请求**

通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。

**3、服务器接受请求并返回HTTP响应**

Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。

**4、释放连接TCP连接**

若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;

**5、客户端浏览器解析HTML内容**

客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。

例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程：

1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;

2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接

3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;

4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;

5、释放TCP连接;

6、浏览器将该 html 文本并显示内容; 　　



### GET和POST请求的区别

**GET请求**

```
GET /users/?sex=man&name=kunaly HTTP/1.1
Host: www.wrox.com
User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)
Gecko/20050225 Firefox/1.0.1
Connection: Keep-Alive
```

**POST请求**

```
POST / HTTP/1.1
Host: www.wrox.com
User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)
Gecko/20050225 Firefox/1.0.1
Content-Type: application/x-www-form-urlencoded
Content-Length: 40
Connection: Keep-Alive

name=kunaly%20Ajax&publisher=Wiley
```

1、GET提交，请求的数据会附在URL之后（就是把数据放置在HTTP协议头中），以?分割URL和传输数据，多个参数用&连接；例 如：login.action?name=kunaly&password=idontknow&verify=%E4%BD%A0 %E5%A5%BD。如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。

POST提交：把提交的数据放置在是HTTP包的包体中。

**因此，GET提交的数据会在地址栏中显示出来，而POST提交，地址栏不会改变**

**2、传输数据的大小：**首先声明：HTTP协议没有对传输的数据大小进行限制，HTTP协议规范也没有对URL长度进行限制。

而在实际开发中存在的限制主要有：

**GET**: 特定浏览器和服务器对URL长度有限制，例如 IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。

因此对于GET提交时，传输数据就会受到URL长度的 限制。

**POST**: 由于不是通过URL传值，理论上数据不受限。但实际各个WEB服务器会规定对post提交数据大小进行限制，Apache、IIS6都有各自的配置。

**3、安全性**

POST的安全性要比GET的安全性高。比如：通过GET提交数据，用户名和密码将明文出现在URL上，因为(1)登录页面有可能被浏览器缓存；(2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了，除此之外，使用GET提交数据还可能会造成Cross-site request forgery攻击。





### URI和URL的区别

**URI，是uniform resource identifier，统一资源标识符，用来唯一的标识一个资源。**

Web上可用的每种资源如HTML文档、图像、视频片段、程序等都是一个来URI来定位的。

URI一般由三部组成：

①访问资源的命名机制

②存放资源的主机名

③资源自身的名称，由路径表示，着重强调于资源。

**URL是uniform resource locator，统一资源定位器，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。**

URL是Internet上用来描述信息资源的字符串，主要用在各种WWW客户程序和服务器程序上，特别是著名的Mosaic。

采用URL可以用一种统一的格式来描述各种信息资源，包括文件、服务器的地址和目录等。URL一般由三部组成：

①协议(或称为服务方式)

②存有该资源的主机IP地址(有时也包括端口号)

③主机资源的具体地址。如目录和文件名等



### HTTP是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。

也就是说 HTTP  协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？

Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物⻋，当你要添加商品到购物⻋的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

Cookie 被禁用怎么办?

最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。



### session 认证流程：

![image-20210830031852242](Java面试总结.assets/image-20210830031852242.png)

1. 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session
2. 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器
3. 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名
4. 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

**根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。**



### Cookie 的作用是什么?和Session 有什么区别？

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

Cookie 一般用来保存用户信息，比如：

① 我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；

② 一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；

③ 登录一次网站后访问网站其他页面不需要重新登录。Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物⻋，当你要添加商品到购物⻋的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

**Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。**

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

[Cookie和Session的区别（面试必备）](https://blog.csdn.net/chen13333336677/article/details/100939030)

**Cookie 和 Session 的区别**

- **安全性：** Session 比 Cookie 安全，Session 是存储在服务器端的，Cookie 是存储在客户端的。
- 存取值的类型不同：Cookie 只支持存字符串数据，想要设置其他类型的数据，需要将其转换成字符串，Session 可以存任意数据类型。
- **有效期不同：** Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭（默认情况下）或者 Session 超时都会失效。
- **存储大小不同：** 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie，但是当访问量过多，会占用过多的服务器资源。

### 什么是 Token（令牌）

- **访问资源接口（API）时所需要的资源凭证**
- **简单 token 的组成**： uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）
- **特点**：
  服务端无状态化、可扩展性好
  支持移动端设备
  安全
  支持跨程序调用

**token 的身份验证流程：**

![image-20210830031947127](Java面试总结.assets/image-20210830031947127.png)1、客户端使用用户名跟密码请求登录
2、服务端收到请求，去验证用户名与密码
3、验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端
4、客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里
5、客户端每次向服务端请求资源的时候需要带着服务端签发的 token
6、服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据

每一次请求都需要携带 token，需要**把 token 放到 HTTP 的 Header 里**

**基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库**

**token 完全由应用管理，所以它可以避开同源策略**



**另外一种 token——refresh token**

refresh token 是专用于刷新 access token 的 token。如果没有 refresh token，也可以刷新 access token，但每次刷新都要用户输入登录用户名与密码，会很麻烦。有了 refresh token，可以减少这个麻烦，客户端直接用 refresh token 去更新 access token，无需用户进行额外的操作。

![image-20210830032253431](Java面试总结.assets/image-20210830032253431.png)

Access Token 的有效期比较短，当 Acesss Token 由于过期而失效时，使用 Refresh Token 就可以获取到新的 Token，如果 Refresh Token 也失效了，用户就只能重新登录了。

Refresh Token 及过期时间是存储在服务器的数据库中，只有在申请新的 Acesss Token 时才会验证，不会对业务接口响应时间造成影响，也不需要向 Session 一样一直保持在内存中以应对大量的请求。

**Token 和 Session 的区别**

- Session 是一种**记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息**。而 **Token 是令牌**，**访问资源接口（API）时所需要的资源凭证。Token 使服务端无状态化，不会存储会话信息**。
- Session 和 Token 并不矛盾，**作为身份认证 Token 安全性比 Session 好，因为每一个请求都有签名还能防止监听以及重放攻击，而 Session 就必须依赖链路层来保障通讯安全了。如果你需要实现有状态的会话，仍然可以增加 Session 来在服务器端保存一些状态**。
- 所谓 Session 认证只是简单的把 User 信息存储到 Session 里，因为 SessionID 的不可预测性，暂且认为是安全的。**而 Token ，如果指的是 OAuth Token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对 App** 。其目的是让某 App 有权利访问某用户的信息。这里的 Token 是唯一的。不可以转移到其它 App上，也不可以转到其它用户上。Session 只提供一种简单的认证，即只要有此 SessionID ，即认为有此 User 的全部权利。是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方 App。所以简单来说：**如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token** 。如果永远只是自己的网站，自己的 App，用什么就无所谓了。



### HTTP 和 HTTPS 的区别？

**HTTP协议（超文本传输协议）**被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

为了解决HTTP协议的这一缺陷，需要使用另一种协议：**安全套接字层超文本传输协议HTTPS**，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。



**HTTPS和HTTP的主要区别**

1. **https协议需要到CA申请证书**，一般免费证书较少，因而需要一定费用。   

2. **http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl/tls加密传输协议。**
3. http和https使用的是完全不同的连接方式，用的**端口也不一样，前者是80，后者是443。**
4. http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。



### Https加密过程

![image-20210730011345843](Java面试总结.assets/image-20210730011345843.png)

1. **客户端发起`HTTPS`请求**

2. **服务端的配置**

   采用`HTTPS`协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。这套证书其实就是一对公钥和私钥（私钥1）。如果对公钥不太理解，可以想象成一把钥匙和一个锁头，只是世界上只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。

3. **传送证书**

   这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。

4. **客户端解析证书**

   这部分工作是由客户端的SSL/TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警示框，提示证书存在的问题。如果证书没有问题，那么就生成一个**随机值**(私钥2)。然后用证书（也就是公钥）对这个随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。

5. **传送加密信息**

   这部分传送的是用证书加密后的随机值，目的是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。

6. **服务端解密信息**

   服务端用私钥1解密后，得到了客户端传过来的随机值(私钥2)，然后把内容通过该随机值进行对称加密，将信息和私钥2通过某种算法混合在一起，这样除非知道私钥2，不然无法获取内容，而正好客户端和服务端都知道这个私钥2，所以只要加密算法够彪悍，私钥2够复杂，数据就够安全。

7. **传输加密后的信息**

   这部分信息就是服务端用私钥2加密后的信息，可以在客户端用随机值解密还原。

8. **客户端解密信息**

   客户端用之前生产的私钥2解密服务端传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。


![](Java面试总结.assets/image-20210730012959382.png)

- Client Hello:握手第一步是客户端向服务端发送 Client Hello 消息，这个消息里包含了一个客户端生成的随机数 Random1、客户端支持的加密套件（Support Ciphers）和 SSL Version 等信息
- Server Hello:第二步是服务端向客户端发送 Server Hello 消息，这个消息会从 Client Hello 传过来的 Support Ciphers 里确定一份加密套件，这个套件决定了后续加密和生成摘要时具体使用哪些算法，另外还会生成一份随机数 Random2。注意，至此客户端和服务端都拥有了两个随机数（Random1+ Random2），这两个随机数会在后续生成对称秘钥时用到。
- Certificate:这一步是服务端将自己的证书下发给客户端，让客户端验证自己的身份，客户端验证通过后取出证书中的公钥
- Server Hello Done:通知客户端 Server Hello 过程结束。
- Certificate Verify:客户端收到服务端传来的证书后，先从 CA 验证该证书的合法性，验证通过后取出证书中的服务端公钥，再生成一个随机数 Random3，再用服务端公钥非对称加密 Random3生成 PreMaster Key
- Client Key Exchange:上面客户端根据服务器传来的公钥生成了 PreMaster Key，Client Key Exchange 就是将这个 key 传给服务端，服务端再用自己的私钥解出这个 PreMaster Key 得到客户端生成的 Random3。至此，客户端和服务端都拥有 Random1 + Random2 + Random3，两边再根据同样的算法就可以生成一份秘钥，握手结束后的应用层数据都是使用这个秘钥进行对称加密。为什么要使用三个随机数呢？这是因为 SSL/TLS 握手过程的数据都是明文传输的，并且多个随机数种子来生成秘钥不容易被暴力破解出来。
- Change Cipher Spec(Client):这一步是客户端通知服务端后面再发送的消息都会使用前面协商出来的秘钥加密了，是一条事件消息
- Encrypted Handshake Message(Client):这一步对应的是 Client Finish 消息，客户端将前面的握手消息生成摘要再用协商好的秘钥加密，这是客户端发出的第一条加密消息。服务端接收后会用秘钥解密，能解出来说明前面协商出来的秘钥是一致的
- Change Cipher Spec(Server):这一步是服务端通知客户端后面再发送的消息都会使用加密，也是一条事件消息
- Encrypted Handshake Message(Server):这一步对应的是 Server Finish 消息，服务端也会将握手过程的消息生成摘要再用秘钥加密，这是服务端发出的第一条加密消息。客户端接收后会用秘钥解密，能解出来说明协商的秘钥是一致的。
- Application Data:到这里，双方已安全地协商出了同一份秘钥，所有的应用层数据都会用这个秘钥加密后再通过 TCP 进行可靠传输



#### 对称加密

对称加密就是指，加密和解密使用同一个密钥的加密方式。

发送方使用密钥将明文数据加密成密文，然后发送出去，接收方收到密文后，使用同一个密钥将密文解密成明文读取。

![image-20210730010305989](Java面试总结.assets/image-20210730010305989.png)

#### 非对称加密

与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥（public key）和私有密钥（private key）。

公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。

![image-20210730010339795](Java面试总结.assets/image-20210730010339795.png)

> **在HTTPS中，这两种加密方式混合使用**
>
> **HTTPS 在内容传输的加密上使用的是`对称加密`，`非对称加密`只作用在证书验证阶段**。

![image-20210730010355636](Java面试总结.assets/image-20210730010355636.png)

#### 数字证书认证

由于公钥在下发的时候也容易被替换劫持，所以需要个第三方认证机构确认公钥的正确性

**CA：数字证书认证机构**，是客户端服务端都认可的第三方机构，负责数字签名服务端公钥

**数字签名：**签名就是一种证明身份的机制，是一种校验机制（简单说是用私钥加密内容的hash,公钥解密对比hash判断内容是否完整）

**数字证书：**由一个可信的组织验证和签发的识别信息。

HTTPS中数字认证流程如下:

![img](Java面试总结.assets/1685507-20191101132559652-1495242555.png)

### HTTP1.0、HTTP2.0 、HTTP3的区别

HTTP1.x 有连接无法重复使用、队头堵塞、协议开销大和安全因素等诸多缺陷（TCP）。
HTTP2 通过二进制流、多路复用、header压缩等技术大大提高了性能（TCP）。
HTTP3是基于UDP实现的，该协议基于UDP又吸取了TCP的精华，实现了快又可靠的协议。

[HTTP1.0、HTTP1.1、HTTP2.0 、HTTP3](https://blog.csdn.net/shshaohy/article/details/118936176)



### 计算机网络的地址的分类

计算机网络地址共分为五类：A类、B类、C类、D类、E类。

**A类地址:0-127**

A类地址的表示范围为：0.0.0.0~126.255.255.255，默认网络掩码为：255.0.0.0；A类地址分配给规模特别大的网络使用。A类网络用第一组数字表示网络本身的地址，后面三组数字作为连接于网络上的主机的地址。分配给具有大量主机（直接个人用户）而局域网络个数较少的大型网络。例如IBM公司的网络。

**B类地址：128-191**

B类地址的表示范围为：128.0.0.0~191.255.255.255，默认网络掩码为：255.255.0.0；B类地址分配给一般的中型网络。B类网络用第一、二组数字表示网络的地址，后面两组数字代表网络上的主机地址。

**C类地址：192-223**

C类地址的表示范围为：192.0.0.0~223.255.255.255，默认网络掩码为：255.255.255.0；C类地址分配给小型网络，如一般的局域网和校园网，它可连接的主机数量是最少的，采用把所属的用户分为若干的网段进行管理。C类网络用前三组数字表示网络的地址，最后一组数字作为网络上的主机地址。

**D类地址：**

D类地址主要是用于组播，前面4位主要起的作用是引导，后面28位位组播的地址ID。

**E类地址：**

总是以1111四位引导 ，E类地址用于研究用。

**特殊的IP地址**

1.网络地址：

IP中主机地址为0的地址表示网络地址，如128.211.0.0。

2.广播地址：

网络号后跟所有位全是1的后缀，就是直接广播地址。

3.回送地址：

即127.0.0.1，用于测试。



> IP地址与子网掩码相与得到网络号：
>
> ip    : 192.168.2.110
>
> &
>
> Submask : 255.255.255.0
>
> \----------------------------
>
> 网络号  ：192.168.2  .0
>
> 注:
>
> 主机号，全为0的是网络号（例如：192.168.2.0），主机号全为1的为广播地址（192.168.2.255）



### Socket 通信流程

**什么是Socket**

Socket就是一组API，对TCP/IP协议进行封装的API！

可以将Socket理解为处于传输层和应用层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用以实现进程在网络中通信。

**Socket通信流程图如下：**

![image-20210811234706651](Java面试总结.assets/image-20210811234706651.png)

简单描述一下Socket的通信流程：

1. 服务端这边首先创建一个Socket（Socket()），然后绑定IP地址和端口号（Bind()），之后注册监听（Listen()），这样服务端就可以监听指定的Socket地址了；
2. 客户端这边也创建一个Socket（Socket()）并打开，然后根据服务器IP地址和端口号向服务器Socket发送连接请求（Connect()）；
3. 服务器Socket监听到客户端Socket发来的连接请求之后，被动打开，并调用Accept()函数接收请求，这样客户端和服务器之间的连接就建立好了；
4. 成功建立连接之后就可以进行数据交互了，客户端和服务器进行数据交互（Receive()、Send()）；
   在数据传输完成之后，各自关闭连接（Close()），交互结束；



### 客户端与服务端长连接的几种方? WebSocket？

在日常 Web 项目中，通常使用的是短连接。即一个 Request 对应一个 Response，发起请求后建立TCP 连接，数据传输后连接关闭。但是对于股票信息更新、即时通讯、在线游戏这种数据交互频繁的场景就需要使用长连接。今天记录一下长连接的几种方式。

#### 一、ajax 轮询

实现原理：ajax 轮询指客户端每间隔一段时间向服务端发起请求，保持数据的同步。

优点：可实现基础（指间隔时间较短）的数据更新。

缺点：这种方法也只是尽量的模拟即时传输，但并非真正意义上的即时通讯，很有可能出现客户端请求时，服务端数据并未更新。或者服务端数据已更新，但客户端未发起请求。导致多次请求资源浪费，效率低下。

#### 二、long poll 长轮询

实现原理：

long poll 指的是客户端发送请求之后，如果没有数据返回，服务端会将请求挂起放入队列（不断开连接）处理其他请求，直到有数据返回给客户端。然后客户端再次发起请求，以此轮询。在 HTTP1.0 中客户端可以设置请求头 Connection:keep-alive，服务端收到该请求头之后知道这是一个长连接，在响应报文头中也添加 Connection:keep-alive。客户端收到之后表示长连接建立完成，可以继续发送其他的请求。在 HTTP1.1 中默认使用了 Connection:keep-alive 长连接。

优点：减少客户端的请求，降低无效的网络传输，保证每次请求都有数据返回，不会一直占用线程。

缺点：无法处理高并发，当客户端请求量大，请求频繁时对服务器的处理能力要求较高。服务器一直保持连接会消耗资源，需要同时维护多个线程，服务器所能承载的 TCP 连接数是有上限的，这种轮询很容易把连接数顶满。每次通讯都需要客户端发起，服务端不能主动推送。

#### 三、iframe 长连接

实现原理：

在网页上嵌入一个 iframe 标签，该标签的 src 属性指向一个长连接请求。这样服务端就可以源源不断地给客户端传输信息。保障信息实时更新。

优点：消息及时传输。

缺点：消耗服务器资源。

#### 四、WebSocket

**实现原理：**

Websocket 实现了客户端与服务端的双向通信，只需要连接一次，就可以相互传输数据，很适合实时通讯、数据实时更新等场景。

Websocket 协议与 HTTP 协议没有关系，它是一个建立在 TCP 协议上的全新协议，为了兼容 HTTP 握手规范，在握手阶段依然使用 HTTP 协议，握手完成之后，数据通过 TCP 通道进行传输。

Websoket 数据传输是通过 frame 形式，一个消息可以分成几个片段传输。这样大数据可以分成一些小片段进行传输，不用考虑由于数据量大导致标志位不够的情况。也可以边生成数据边传递消息，提高传输效率。

**与 HTTP 的区别：**

以下是一个 WebSoket 协议的请求响应报文头，与 HTTP 协议的区别是：

1. URL是以 ws: 开头，如果是对应的 HTTPS，则以 wss: 开头。WebSocket 使用 ws 或 wss 为统一资源标志符，其中 wss 表示在 TLS 之上的 Websocket。

2. Status Code：101。该状态码表示协议切换。服务器返回了 101 ，表示没有释放 TCP 连接。WebSoket 协议握手阶段还是依赖于 HTTP 协议，到数据传输阶段便切换协议。

3. Conection：upgrade，表示协议升级。在 HTTP 协议中，该请求头有两个值，一个是 close ， HTTP/1.0 默认值，表示客户端或服务端想要关闭连接。另一个是 keep-alive，HTTP/1.1 默认值，表示长连接。

4. 以下头部字段是只有 WebSocket 协议才有的字段。

   - 请求头：
     Sec-WebSocket-Extension：表示客户端协商的拓展特性。
     Sec-WebSocket-Key：是一个 Base64 encode 的密文，由浏览器随机生成，用来验证是否是 WebSocket 协议。
     Sec-WebSocket-Version：表示 WebSocket 协议版本。

   - 响应头：
     Sec-WebSocket-Extension：表示服务端支持的拓展特性。
     Sec-WebSocket-Accept：与客户端的 Sec-WebSocket-Key 相对应，是经过服务器确认，加密过后的 Sec-WebSocket-Key。

     ![image-20210726000106601](Java面试总结.assets/image-20210726000106601.png)

**优点：**

双向通信。客户端和服务端双方都可以主动发起通讯。

没有同源限制。客户端可以与任意服务端通信，不存在跨域问题。

数据量轻。第一次连接时需要携带请求头，后面数据通信都不需要带请求头，减少了请求头的负荷。

传输效率高。因为只需要一次连接，所以数据传输效率高。

**缺点：**

长连接需要后端处理业务的代码更稳定，推送消息相对复杂；

长连接受网络限制比较大，需要处理好重连。

兼容性，WebSocket 只支持 IE10 及其以上版本。

服务器长期维护长连接需要一定的成本，各个浏览器支持程度不一；

成熟的 HTTP 生态下有大量的组件可以复用，WebSocket 则没有，遇到异常问题难以快速定位快速解决。



## Linux

### 内核态与用户态的区别?

> 内核态（Kernel Mode）：运行操作系统程序，操作硬件
>
> 用户态（User Mode）：运行用户程序

- 内核态与用户态是操作系统的两种运行级别，当程序运行在`R3`级特权级上时，就可以称之为运行在用户态。**因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；**
- 当程序运行在`R0`级特权级上时，就可以称之为运行在内核态。

区别：

- 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的
- 处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。

**指令划分：**

特权指令：只能由操作系统使用、用户程序不能使用的指令。 举例：启动I/O  内存清零 修改程序状态字 设置时钟 允许/禁止终端 停机

非特权指令：用户程序可以使用的指令。 举例：控制转移 算数运算 取数指令 **访管指令**（使用户程序从用户态陷入内核态）

### 用户态如何切换到内核态？

- **系统调用：**其实系统调用本身就是中断，但是软件中断，跟硬中断不同。
- **异常：**如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。
- **外围设备的中断：**当外设完成用户的请求时，会向CPU发送中断信号。

> **用户态--->内核态：**唯一途径是通过中断、异常、陷入机制（访管指令）
>
> **内核态--->用户态：**设置程序状态字PSW



### Linux - 内存分配算法

**伙伴（Buddy）分配算法**

伙伴系统算法（Buddy system），顾名思义，就是把相同大小的页通过链表串起来，多张页就像手拉手的好伙伴（算法名称的由来）。伙伴算法负责大块连续物理内存的分配和释放，以页为基本单位。

伙伴分配算法的原理就是：将所有的空闲页框分组为 11 个块链表，每个块链表分别包含大小为 1，2，4，8，16，32，64，128，256，512 和 1024 个连续页的页块。最大可以申请 1024 个连续页，对应 4MB 大小的连续内存。因为任何正整数都可以由 2^n 的和组成，所以总能找到合适大小的内存块分配出去，减少了外部碎片产生 。
![image-20210812120528653](Java面试总结.assets/image-20210812120528653.png)

**Slab 算法**

它的基本思想是：**将内核中经常使用的对象放到高速缓存中，并且由系统保持为初始的可利用状态。比如进程描述符，内核中会频繁对此数据进行申请和释放**。

Slab 内存分配器是对伙伴分配算法的补充。Slab 缓存负责小块物理内存的分配，并且它也作为高速缓存，主要针对内核中经常分配并释放的对象。

![image-20210812122326132](Java面试总结.assets/image-20210812122326132.png)

kmem_cache 是一个cache_chain 的链表组成节点，代表的是一个内核中的相同类型对象的高速缓存，每个kmem_cache 通常是一段连续的内存块，包含了三种类型的 slabs 链表：

slabs_full：完全分配的 slab 链表

slabs_partial：部分分配的 slab 链表

slabs_empty：没有被分配对象的 slab 链表



### Linux 内核使用的各种同步方式

| **技术**            | **说明**                             | **适用范围**     |
| ------------------- | ------------------------------------ | ---------------- |
| 每CPU变量           | 在CPU之间复制数据结构                | 所有CPU          |
| 原子操作            | 对一个计数器原子地“读-修改-写”的指令 | 所有CPU          |
| 内存屏障            | 避免指令重新排序                     | 本地CPU或所有CPU |
| 自旋锁              | 加锁时忙等                           | 所有CPU          |
| 信号量              | 加锁时阻塞等待                       | 所有CPU          |
| 顺序锁              | 基于访问计数器的锁                   | 所有CPU          |
| 本地中断的禁止      | 禁止单个CPU上的中断处理              | 本地CPU          |
| 本地软中断的禁止    | 禁止单个CPU上的可延迟函数处理        | 本地CPU          |
| 读-复制-更新（RCU） | 通过指针而不是锁来访问共享数据结构   | 所有CPU          |





## 操作系统

### 进程和线程有什么区别？

- 进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位；
- 线程依赖于进程而存在，一个进程至少有一个线程；
- 进程有自己的独立地址空间，线程共享所属进程的地址空间；
- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等；
- 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销；
- 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行；
- 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮

#### 同一进程中的线程可以共享哪些数据？

- 进程代码段
- 进程的公有数据（全局变量、静态变量...）
- 进程打开的文件描述符
- 进程的当前目录
- 信号处理器/信号处理函数：对收到的信号的处理方式
- 进程ID与进程组ID

#### 线程独占哪些资源？

- 线程ID
- 一组寄存器的值
- 线程自身的栈（堆是共享的）
- 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；
- 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）

### 什么是协程？

协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

### 协程多与线程进行比较？

1. 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。
2. 线程进程都是同步机制，而协程则是异步
3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态

### 进程间通信有哪些方式？

1. 管道(Pipe)
2. 命名管道
3. 消息队列
4. 信号(Signal)
5. 共享内存
6. 信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态
7. 套接字(Socket)

### 线程同步有哪些方式？

> 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。

- **互斥量** Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源；
- **信号量** Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过`ReleaseSemaphore`函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量；
- **事件** Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒**一个**等待中的线程，然后自动恢复为未激发状态。
- **临界区** Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。



### 并发、并行、异步的区别？

并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的；

多线程：并发运行的一段代码。是实现异步的手段

并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的

异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事

### 进程有哪几种状态？

- 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
- 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
- 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

### 进程调度策略有哪些？

**批处理系统：**

1. **先来先服务 first-come first-serverd（FCFS）**

   按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）；

   对短进程不利，对IO密集型进程不利。

2. **最短作业优先 shortest job first（SJF）**

   按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题；

   对短进程提供好的响应时间，对长进程不利。

3. **最短剩余时间优先 shortest remaining time next（SRTN）**

   按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间；

   可能导致饥饿问题，对长进程不利。

4. **最高响应比优先 Highest Response Ratio Next（HRRN）**

   响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。

**交互式（分时系统）系统：**
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. **时间片轮转 Round Robin**

   将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间；

   若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。

2. **优先级调度算法**

   为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

3. **多级反馈队列调度算法 Multilevel Feedback Queue**

   设置多个就绪队列1、2、3...，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。

   抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。



### 什么叫优先级反转？如何解决？

高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。

**解决方法：**

- 优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。
- 优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。

### 什么是僵尸进程和孤儿进程？

我们知道在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

**僵尸进程：一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。**它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

**危害**：占用进程号，而系统所能使用的进程号是有限的；占用内存。

**孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。**



### 什么是IO多路复用？怎么实现？

IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。

实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。

### select/poll/epoll三者的区别？

- `select`：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，**开销大**），由内核根据就绪状态修改该集合的内容。（缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：**轮询的方式效率较低**），当文件描述符的数量增加时，效率会线性下降；
- `poll`：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；
- `epoll`：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。

总结，区别主要在于：

- 一个线程/进程所能打开的最大连接数
- 文件描述符传递方式（是否复制）
- 水平触发 or 边缘触发
- 查询就绪的描述符时的效率（是否轮询）

**什么时候使用select/poll，什么时候使用epoll？**

当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。

**什么是文件描述符？**

文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

内核通过文件描述符来访问文件。文件描述符指向一个文件。

##### 什么是水平触发？什么是边缘触发？

- **水平触发（LT，Level Trigger）模式下**，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；
- **边缘触发（ET，Edge Trigger）模式下，**当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。
- 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。
- 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。

### 有哪些IO模型？

- 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够；
- 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源；
- IO多路复用
- 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。

### 什么是用户态和内核态？

为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。

- 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取；
- 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。

所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用**陷阱指令**，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。

##### 为什么要分用户态和内核态？

- 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源；
- 封装性：用户程序不需要实现更加底层的代码；
- 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。

##### 如何从用户态切换到内核态？

- **系统调用：**比如读取命令行输入。本质上还是通过中断实现
- **用户程序发生异常时：**比如缺页异常
- **外围设备的中断：**外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序

### 什么是死锁？

在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。

**死锁产生的必要条件？**

- **互斥**：一个资源一次只能被一个进程使用；
- **占有并等待**：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源；
- **非抢占**：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放；
- **循环等待**：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。

### 死锁有哪些处理方法？

**鸵鸟策略**

直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

**死锁预防**

基本思想是破坏形成死锁的四个必要条件：

- **破坏互斥条件：**允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限；
- **破坏占有并等待条件：**
  - 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）；
  - 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）；
  - 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性；
- **破坏非抢占条件：**允许进程强行抢占被其它进程占有的资源。会降低系统性能；
- **破坏循环等待条件：**对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。

**死锁避免**

动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。

> 银行家算法

**死锁解除**

> 如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。

死锁解除的方法：

- 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态；

- 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点；

- 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。

  

### 分页和分段有什么区别？

- 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻；
- 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻；
- 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。

**区别：**

- 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间；
- 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定；
- 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）；
- 分段便于信息的保护和共享；分页的共享收到限制；
- 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满）

### 什么是虚拟内存？

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。

虚拟内存的优点是让程序可以获得更多的可用内存。

### 有哪些页面置换算法？

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

- **最佳页面置换算法**OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略；
- **先进先出**FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高；
- **第二次机会算法**SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0；
- **时钟算法** Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销；
- **最近未使用算法**NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）；
- **最近最少使用算法**LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
- **最不经常使用算法**NFU：置换出访问次数最少的页面

### 磁盘调度

过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法：

- **先来先服务算法（FCFS），**

- **最短寻道时间优先算法（SSTF），**

-  **扫描算法（SCAN），又叫电梯算法：**电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

- **循环扫描算法（C-SCAN），**

- **FSCAN：分步电梯调度算法(分两个队列)**

  



## 数据结构

### 排序算法总结

排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。用一张图概括：

![image-20210730164600663](Java面试总结.assets/image-20210730164600663.png)

![image-20210730164632964](Java面试总结.assets/image-20210730164632964.png)

关于稳定性

稳定性：排序后 2 个相等键值的顺序和排序之前它们的顺序相同

稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序。

不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。

#### 1. 冒泡排序

**算法步骤：**

比较相邻的元素。如果第一个比第二个大，就交换他们两个。

对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。

针对所有的元素重复以上的步骤，除了最后一个。

持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。

**动图演示：**

![img](Java面试总结.assets/bubbleSort.gif)

**代码实现**

```java
public class BubbleSort implements IArraySort {
    
    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);
        for (int i = 1; i < arr.length; i++) {
            // 设定一个标记，若为true，则表示此次循环没有进行交换，
            //也就是待排序列已经有序，排序已经完成,直接跳出循环。
            boolean flag = true;

            for (int j = 0; j < arr.length - i; j++) {
                if (arr[j] > arr[j + 1]) {
                    int tmp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = tmp;

                    flag = false;
                }
            }
            if (flag) {
                break;
            }
        }
        return arr;
    }
}
```



#### 2. 选择排序

**算法步骤**

首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。

再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。

重复第二步，直到所有元素均排序完毕。

**动图演示**

![img](Java面试总结.assets/selectionSort.gif)

```java
public class SelectionSort implements IArraySort {

    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);

        // 总共要经过 N-1 轮比较
        for (int i = 0; i < arr.length - 1; i++) {
            int min = i;

            // 每轮需要比较的次数 N-i
            for (int j = i + 1; j < arr.length; j++) {
                if (arr[j] < arr[min]) {
                    // 记录目前能找到的最小值元素的下标
                    min = j;
                }
            }

            // 将找到的最小值和i位置所在的值进行交换
            if (i != min) {
                int tmp = arr[i];
                arr[i] = arr[min];
                arr[min] = tmp;
            }

        }
        return arr;
    }
}
```



#### 3. 插入排序

**算法步骤**

将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。

从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）

**动图演示**

![img](Java面试总结.assets/insertionSort.gif)

**代码实现**

```java
public class InsertSort implements IArraySort {

    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);

        // 从下标为1的元素开始选择合适的位置插入，因为下标为0的只有一个元素，默认是有序的
        for (int i = 1; i < arr.length; i++) {

            // 记录要插入的数据
            int tmp = arr[i];

            // 从已经排序的序列最右边的开始比较，找到比其小的数
            int j = i;
            while (j > 0 && tmp < arr[j - 1]) {
                arr[j] = arr[j - 1];
                j--;
            }

            // 存在比其小的数，插入
            if (j != i) {
                arr[j] = tmp;
            }

        }
        return arr;
    }
}
```

#### 4. 希尔排序

**算法步骤**

选择一个增量序列 t1，t2，……，tk，其中 ti > tj，tk = 1；

按增量序列个数 k，对序列进行 k 趟排序；

每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。

**动图演示**

![img](Java面试总结.assets/Sorting_shellsort_anim.gif)



**代码实现**

```java
public static void shellSort(int[] arr) {
    int length = arr.length;
    int temp;
    for (int step = length / 2; step >= 1; step /= 2) {
        for (int i = step; i < length; i++) {
            temp = arr[i];
            int j = i - step;
            while (j >= 0 && arr[j] > temp) {
                arr[j + step] = arr[j];
                j -= step;
            }
            arr[j + step] = temp;
        }
    }
}
```

#### 5. 归并排序

**算法步骤**

1. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；
2. 设定两个指针，最初位置分别为两个已经排序序列的起始位置；
3. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；
4. 重复步骤 3 直到某一指针达到序列尾；
5. 将另一序列剩下的所有元素直接复制到合并序列尾。

 **动图演示**

![img](Java面试总结.assets/mergeSort.gif)

**代码实现**

```java
package Algorithm.sort;

public class MergeSort {
    public static void main(String[] args) {
        int[] data = new int[] { 5, 3, 6, 2, 1, 9, 4, 8, 7 };
        print(data);
        mergeSort(data);
        System.out.println("排序后的数组：");
        print(data);
    }
    public static void mergeSort(int[] data) {
        sort(data, 0, data.length - 1);
    }
    public static void sort(int[] data, int left, int right) {
        if (left >= right)
            return;
        // 找出中间索引
        int center = (left + right) / 2;
        // 对左边数组进行递归
        sort(data, left, center);
        // 对右边数组进行递归
        sort(data, center + 1, right);
        // 合并
        merge(data, left, center, right);
        print(data);
    }

    /**
     * 将两个数组进行归并，归并前面2个数组已有序，归并后依然有序
     *
     * @param data   数组对象
     * @param left   左数组的第一个元素的索引
     * @param center 左数组的最后一个元素的索引，center+1是右数组第一个元素的索引
     * @param right  右数组最后一个元素的索引
     */
    public static void merge(int[] data, int left, int center, int right) {
        // 临时数组
        int[] tmpArr = new int[data.length];
        // 右数组第一个元素索引
        int mid = center + 1;
        // third 记录临时数组的索引
        int third = left;
        // 缓存左数组第一个元素的索引
        int tmp = left;
        while (left <= center && mid <= right) {
            // 从两个数组中取出最小的放入临时数组
            if (data[left] <= data[mid]) {
                tmpArr[third++] = data[left++];
            } else {
                tmpArr[third++] = data[mid++];
            }
        }
        // 剩余部分依次放入临时数组（实际上两个while只会执行其中一个）
        while (mid <= right) {
            tmpArr[third++] = data[mid++];
        }
        while (left <= center) {
            tmpArr[third++] = data[left++];
        }
        // 将临时数组中的内容拷贝回原数组中
        // （原left-right范围的内容被复制回原数组）
        while (tmp <= right) {
            data[tmp] = tmpArr[tmp++];
        }
    }

    public static void print(int[] data) {
        for (int i = 0; i < data.length; i++) {
            System.out.print(data[i] + "\t");
        }
        System.out.println();
    }
}
```

#### 6. 快速排序

**算法步骤**

1. 从数列中挑出一个元素，称为 "基准"（pivot）;
2. 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；
3. 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；

**动态演示**

![img](Java面试总结.assets/quickSort.gif)

**代码实现**

```java
public class QuickSort {
    public static void main(String[] args) {
        int[] nums = new int[]{1,2,3,5,4,1,7,4,9,8,6,5,4,1};
        quickSort(nums,0,nums.length-1);
        for (int num : nums) {
            System.out.print(num+" ");
        }
    }

    private static void quickSort(int[] nums, int left, int right) {
        if(left > right) return;
        int i = left, j = right;
        int key = nums[left];
        while (i < j){
            while(i < j && nums[j] >= key){
                j --;
            }
            while(i < j && nums[i] <= key){
                i++;
            }
            if (i < j) {
                swap(nums, i, j);
            }
        }
        swap(nums,left,i);
        quickSort(nums,left,i-1);
        quickSort(nums,i+1,right);
    }

    private static void swap(int[] nums, int end, int start) {
        int temp = nums[start];
        nums[start] = nums[end];
        nums[end] = temp;
    }
}
```

#### 7. 堆排序

**算法步骤**

1. 创建一个堆 H[0……n-1]；
2. 把堆首（最大值）和堆尾互换；
3. 把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置；
4. 重复步骤 2，直到堆的尺寸为 1。

**动图演示**

![img](Java面试总结.assets/heapSort.gif)



![img](Java面试总结.assets/Sorting_heapsort_anim.gif)

**代码实现**

```java
public class HeapSort {
    public static void main(String[] args) {
        int[] nums = new int[]{5,2,3,5,4,1,7,4,9,8,6,5,4,1};
        heapSort(nums);
        for (int num : nums) {
            System.out.print(num+" ");
        }
    }

    //堆排序
    private static void heapSort(int[] arr) {
        //创建堆
        for(int i = (arr.length-1)/2; i>=0; i--){
            //从第一个非叶子节点开始，从下到上，从右到左
            adjustHeap(arr,i,arr.length);
        }
        //交换堆顶元素和末尾元素 调整堆
        for(int i = arr.length-1; i >= 0; i--){
            int temp = arr[i];
            arr[i] = arr[0];
            arr[0] = temp;
            adjustHeap(arr,0, i);
        }
    }

    //调整堆
    private static void adjustHeap(int[] arr, int parent, int length) {
        int temp = arr[parent];
        //左孩子
        int lChild = 2 * parent + 1;
        while(lChild < length){
            //右孩子
            int rChild = lChild + 1;
            if(rChild <  length && arr[lChild] < arr[rChild]){
                lChild++;
            }
            if(arr[lChild] > temp){
                arr[parent] = arr[lChild];
                parent = lChild;
                lChild = 2 * lChild + 1;
            }else{
                break;
            }
            arr[parent] = temp;
        }
    }
}
```

#### 8. 计数排序

**算法步骤**

（1）找出待排序的数组中最大和最小的元素

（2）统计数组中每个值为i的元素出现的次数，存入数组C的第i项

（3）对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）

（4）反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1

**动图演示**

![img](Java面试总结.assets/countingSort.gif)

**代码实现**

```java
public class CountingSort implements IArraySort {

    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);

        int maxValue = getMaxValue(arr);

        return countingSort(arr, maxValue);
    }

    private int[] countingSort(int[] arr, int maxValue) {
        int bucketLen = maxValue + 1;
        int[] bucket = new int[bucketLen];

        for (int value : arr) {
            bucket[value]++;
        }

        int sortedIndex = 0;
        for (int j = 0; j < bucketLen; j++) {
            while (bucket[j] > 0) {
                arr[sortedIndex++] = j;
                bucket[j]--;
            }
        }
        return arr;
    }

    private int getMaxValue(int[] arr) {
        int maxValue = arr[0];
        for (int value : arr) {
            if (maxValue < value) {
                maxValue = value;
            }
        }
        return maxValue;
    }
}
```

#### 9.  桶排序

元素分布在桶中：

![img](Java面试总结.assets/Bucket_sort_1.svg_.png)

然后，元素在每个桶中排序：

![img](Java面试总结.assets/Bucket_sort_2.svg_.png)

**代码实现**

```java
public class BucketSort implements IArraySort {

    private static final InsertSort insertSort = new InsertSort();

    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);

        return bucketSort(arr, 5);
    }

    private int[] bucketSort(int[] arr, int bucketSize) throws Exception {
        if (arr.length == 0) {
            return arr;
        }

        int minValue = arr[0];
        int maxValue = arr[0];
        for (int value : arr) {
            if (value < minValue) {
                minValue = value;
            } else if (value > maxValue) {
                maxValue = value;
            }
        }

        int bucketCount = (int) Math.floor((maxValue - minValue) / bucketSize) + 1;
        int[][] buckets = new int[bucketCount][0];

        // 利用映射函数将数据分配到各个桶中
        for (int i = 0; i < arr.length; i++) {
            int index = (int) Math.floor((arr[i] - minValue) / bucketSize);
            buckets[index] = arrAppend(buckets[index], arr[i]);
        }

        int arrIndex = 0;
        for (int[] bucket : buckets) {
            if (bucket.length <= 0) {
                continue;
            }
            // 对每个桶进行排序，这里使用了插入排序
            bucket = insertSort.sort(bucket);
            for (int value : bucket) {
                arr[arrIndex++] = value;
            }
        }

        return arr;
    }

    /**
     * 自动扩容，并保存数据
     *
     * @param arr
     * @param value
     */
    private int[] arrAppend(int[] arr, int value) {
        arr = Arrays.copyOf(arr, arr.length + 1);
        arr[arr.length - 1] = value;
        return arr;
    }
}
```

#### 10. 基数排序

**动图演示**

![img](Java面试总结.assets/radixSort.gif)

**代码实现**

```java
/**
 * 基数排序
 * 考虑负数的情况还可以参考： https://code.i-harness.com/zh-CN/q/e98fa9
 */
public class RadixSort implements IArraySort {

    @Override
    public int[] sort(int[] sourceArray) throws Exception {
        // 对 arr 进行拷贝，不改变参数内容
        int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);

        int maxDigit = getMaxDigit(arr);
        return radixSort(arr, maxDigit);
    }

    /**
     * 获取最高位数
     */
    private int getMaxDigit(int[] arr) {
        int maxValue = getMaxValue(arr);
        return getNumLenght(maxValue);
    }

    private int getMaxValue(int[] arr) {
        int maxValue = arr[0];
        for (int value : arr) {
            if (maxValue < value) {
                maxValue = value;
            }
        }
        return maxValue;
    }

    protected int getNumLenght(long num) {
        if (num == 0) {
            return 1;
        }
        int lenght = 0;
        for (long temp = num; temp != 0; temp /= 10) {
            lenght++;
        }
        return lenght;
    }

    private int[] radixSort(int[] arr, int maxDigit) {
        int mod = 10;
        int dev = 1;

        for (int i = 0; i < maxDigit; i++, dev *= 10, mod *= 10) {
            // 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10)
            int[][] counter = new int[mod * 2][0];

            for (int j = 0; j < arr.length; j++) {
                int bucket = ((arr[j] % mod) / dev) + mod;
                counter[bucket] = arrayAppend(counter[bucket], arr[j]);
            }

            int pos = 0;
            for (int[] bucket : counter) {
                for (int value : bucket) {
                    arr[pos++] = value;
                }
            }
        }

        return arr;
    }

    /**
     * 自动扩容，并保存数据
     *
     * @param arr
     * @param value
     */
    private int[] arrayAppend(int[] arr, int value) {
        arr = Arrays.copyOf(arr, arr.length + 1);
        arr[arr.length - 1] = value;
        return arr;
    }
}
```





### 红黑树

![image-20210926125953321](Java面试总结.assets/image-20210926125953321.png)

红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：

- 性质1：每个节点要么是黑色，要么是红色。
- 性质2：根节点是黑色。
- 性质3：每个叶子节点（NIL）是黑色。
- 性质4：每个红色结点的两个子结点一定都是黑色。
- **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**

从性质5又可以推出：

- 性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点

**不是完全平衡：从根节点到叶子节点的最长路径不大于最短路径的 2 倍**



## 设计模式

### 设计模式分为三大类

1. **创建型**

  a. 工厂模式（Factory Pattern）

  b. 抽象工厂模式（Abstract Factory Pattern）

  c. 单例模式（Singleton Pattern）

  d. 建造者模式（Builder Pattern）

  e. 原型模式（Prototype Pattern）

2. **结构型**

  a. 适配器模式（Adapter Pattern）

  b. 桥接模式（Bridge Pattern）

  c. 过滤器模式（Filter、Criteria Pattern）

  d. 组合模式（Composite Pattern）

  e. 装饰器模式（Decorator Pattern）

  f. 外观模式（Facade Pattern）

  g. 享元模式（Flyweight Pattern）

  h. 代理模式（Proxy Pattern）

3. **行为型**

  a. 责任链模式（Chain of Responsibility Pattern）

  b. 命令模式（Command Pattern） 

  c. 解释器模式（Interpreter Pattern） 

  d. 迭代器模式（Iterator Pattern）

  e. 中介者模式（Mediator Pattern）

  f. 备忘录模式（Memento Pattern）

  g. 观察者模式（Observer Pattern）

  h. 状态模式（State Pattern）

  i. 空对象模式（Null Object Pattern）

  j. 策略模式（Strategy Pattern）

  k. 模板模式（Template Pattern）

  l. 访问者模式（Visitor Pattern）

  

### 单例模式

因程序需要，有时我们只需要`某个类在整个系统中同一时刻只有一个实例存在`，不希望有更多对象，此时，我们则应考虑单例模式的设计。

**单例模式的实现**

1. **懒汉模式**

   ```java
   public class SingletonDemo {
       private static SingletonDemo instance;
       private SingletonDemo(){
   
       }
       public static SingletonDemo getInstance(){
           if(instance==null){
               instance=new SingletonDemo();
           }
           return instance;
       }
   }
   ```

2. **线程安全的懒汉模式**

   ```java
   public class SingletonDemo {
       private static SingletonDemo instance;
       private SingletonDemo(){
   
       }
       public static synchronized SingletonDemo getInstance(){
           if(instance==null){
               instance=new SingletonDemo();
           }
           return instance;
       }
   }
   ```

3. **饿汉模式**

   ```java
   public class SingletonDemo {
       private static SingletonDemo instance=new SingletonDemo();
       private SingletonDemo(){
   
       }
       public static SingletonDemo getInstance(){
           return instance;
       }
   }
   ```

4. **静态类内部加载**

   ```java
   public class SingletonDemo {
       private static class SingletonHolder{
           private static SingletonDemo instance=new SingletonDemo();
       }
       private SingletonDemo(){
           System.out.println("Singleton has loaded");
       }
       public static SingletonDemo getInstance(){
           return SingletonHolder.instance;
       }
   }
   ```

5. **枚举方法**

   ```java
   enum SingletonDemo{
       INSTANCE;
       public void otherMethods(){
           System.out.println("Something");
       }
   }
   //如果我们想调用它的方法时，仅需要以下操作：
   public class Hello {
       public static void main(String[] args){
           SingletonDemo.INSTANCE.otherMethods();
       }
   }
   ```

6. **双重校验锁法**

   ```java
   //双重校验锁
   public class Singleton {
       private volatile static Singleton uniqueInstance;
       private Singleton() {
       }
       public  static Singleton getUniqueInstance() {
          //先判断对象是否已经实例过，没有实例化过才进入加锁代码
           if (uniqueInstance == null) {
               //类对象加锁
               synchronized (Singleton.class) {
                   if (uniqueInstance == null) {
                       uniqueInstance = new Singleton();
                   }
               }
           }
           return uniqueInstance;
       }
   }
   ```
   
   > 另外，需要注意 `uniqueInstance` 采用 `volatile` 关键字修饰也是很有必要。
   >
   > `uniqueInstance` 采用 `volatile` 关键字修饰也是很有必要的， `uniqueInstance = new Singleton();` 这段代码其实是分为三步执行：
   >
   > 1. 为 `uniqueInstance` 分配内存空间
   > 2. 初始化 `uniqueInstance`
   > 3. 将 `uniqueInstance` 指向分配的内存地址
   >
   > 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 `getUniqueInstance`() 后发现 `uniqueInstance` 不为空，因此返回 `uniqueInstance`，但此时 `uniqueInstance` 还未被初始化。
   >
   > 使用 `volatile` 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。
   
   
   

### 工厂模式

简单工厂

抽象工厂





## 分布式微服务

### 说说你了解的分布式锁实现

分布式锁所要解决的问题的本质是：能够对分布在多台机器中的线程对共享资源的互斥访问。

在这个原理上可以有很多的实现方式：

1. 基于Mysql，分布式环境中的线程连接同一个数据库，利用数据库中的行锁来达到互斥访问，但是Mysql的加锁和释放锁的性能会比较低，不适合真正的实际生产环境；
2. 基于Zookeeper，Zookeeper中的数据是存在内存的，所以相对于Mysql性能上是适合实际环境的，并且基于Zookeeper的顺序节点、临时节点、Watch机制能非常好的来实现的分布式锁；
3. 基于Redis，Redis中的数据也是在内存，基于Redis的消费订阅功能、数据超时时间，lua脚本等功能，也能很好的实现的分布式锁；



### SpringCloud各组件功能，与Dubbo的区别

1. Eureka：注册中心，用来进行服务的自动注册和发现
2. Ribbon：负载均衡组件，用来在消费者调用服务时进行负载均衡
3. Feign：基于接口的申明式的服务调用客户端，让调用变得更简单
4. Hystrix：断路器，负责服务容错
5. Zuul：服务网关，可以进行服务路由、服务降级、负载均衡等
6. Nacos：分布式配置中心以及注册中心
7. Sentinel：服务的熔断降级，包括限流
8. Seata：分布式事务
9. Spring Cloud Config：分布式配置中心
10. Spring Cloud Bus：消息总线
11. ...

Spring Cloud是一个微服务框架，提供了微服务领域中的很多功能组件，Dubbo一开始是一个RPC调用框架，核心是解决服务调用间的问题，Spring Cloud是一个大而全的框架，Dubbo则更侧重于服务调用，所以Dubbo所提供的功能没有Spring Cloud全面，但是Dubbo的服务调用性能比Spring Cloud高，不过Spring Cloud和Dubbo并不是对立的，是可以结合起来一起使用的。



### 简述 CAP 理论

CAP理论是分布式领域非常重要的一个理论，很多分布式中间件在实现时都需要遵守这个理论，其中：
1. C表示一致性：指的的是分布式系统中的数据的一致性
2. A表示可用性：表示分布式系统是否正常可用
3. P表示分区容忍性：表示分布式系统出现网络问题时的容错性

CAP理论是指，在分布式系统中不能同时保证C和A，也就是说在分布式系统中要么保证CP，要么保证
AP，也就是一致性和可用性只能取其一，如果想要数据的一致性，那么就需要损失系统的可用性，如果需要系统高可用，那么就要损失系统的数据一致性，特指强一致性。

CAP理论太过严格，在实际生产环境中更多的是使用BASE理论，BASE理论是指分布式系统不需要保证数据的强一致，只要做到最终一致，也不需要保证一直可用，保证基本可用即可。



### 什么是BASE理论

由于不能同时满足CAP，所以出现了BASE理论：
1. BA：Basically Available，表示基本可用，表示可以允许一定程度的不可用，比如由于系统故障，请求时间变长，或者由于系统故障导致部分非核心功能不可用，都是允许的。
2. S：Soft state：表示分布式系统可以处于一种中间状态，比如数据正在同步。
3. E：Eventually consistent，表示最终一致性，不要求分布式系统数据实时达到一致，允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的。



### 分布式ID是什么？有哪些解决方案？

在开发中，我们通常会需要一个唯一ID来标识数据，如果是单体架构，我们可以通过数据库的主键，或直接在内存中维护一个自增数字来作为ID都是可以的，但对于一个分布式系统，就会有可能会出现ID冲突，此时有以下解决方案：
1. uuid，这种方案复杂度最低，但是会影响存储空间和性能
2. 利用单机数据库的自增主键，作为分布式ID的生成器，复杂度适中，ID长度较之uuid更短，但是受到单机数据库性能的限制，并发量大的时候，此方案也不是最优方案
3. 利用redis、zookeeper的特性来生成id，比如redis的自增命令、zookeeper的顺序节点，这种方案和单机数据库(mysql)相比，性能有所提高，可以适当选用
4. 雪花算法，一切问题如果能直接用算法解决，那就是最合适的，利用雪花算法也可以生成分布式ID，底层原理就是通过某台机器在某一毫秒内对某一个数字自增，这种方案也能保证分布式架构中的系统id唯一，但是只能保证趋势递增。业界存在tinyid、leaf等开源中间件实现了雪花算法。



### 分布式锁的使用场景是什么？有哪些实现方案？

在单体架构中，多个线程都是属于同一个进程的，所以在线程并发执行时，遇到资源竞争时，可以利用ReentrantLock、synchronized等技术来作为锁，来控制共享资源的使用。

而在分布式架构中，多个线程是可能处于不同进程中的，而这些线程并发执行遇到资源竞争时，利用ReentrantLock、synchronized等技术是没办法来控制多个进程中的线程的，所以需要分布式锁，意思就是，需要一个分布式锁生成器，分布式系统中的应用程序都可以来使用这个生成器所提供的锁，从而达到多个进程中的线程使用同一把锁。

⽬前主流的分布式锁的实现方案有两种：

1. zookeeper：利用的是zookeeper的临时节点、顺序节点、watch机制来实现的，zookeeper分布式锁的特点是高一致性，因为zookeeper保证的是CP，所以由它实现的分布式锁更可靠，不会出现混乱。
2. redis：利用redis的setnx、lua脚本、消费订阅等机制来实现的，redis分布式锁的特点是高可用，因为redis保证的是AP，所以由它实现的分布式锁可能不可靠，不稳定（一旦redis中的数据出现了不一致），可能会出现多个客户端同时加到锁的情况。



### 什么是分布式事务？有哪些实现方案？

在分布式系统中，一次业务处理可能需要多个应用来实现，比如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存，而对于一次下单，订单创建与减库存应该是要同时成功或同时失败的，但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败，那么解决这类问题，就需要用到分布式事务。常用解决方案有：

1. 本地消息表：创建订单时，将减库存消息加入在本地事务中，一起提交到数据库存入本地消息表，然后调用库存系统，如果调用成功则修改本地消息状态为成功，如果调用库存系统失败，则由后台定时任务从本地消息表中取出未成功的消息，重试调用库存系统。

2. 消息队列：⽬前RocketMQ中支持事务消息，它的工作原理是：

  a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者而⾔是不可⻅的。
  b. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback。
  c. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功。
  d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束。
  e. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理。

3. Seata：阿里开源的分布式事务框架，支持AT、TCC等多种模式，底层都是基于两阶段提交理论来实现的。

### Zookeeper中的领导者选举的流程？

对于Zookeeper集群，整个集群需要从集群节点中选出一个节点作为Leader，大体流程如下：

1. 集群中各个节点首先都是观望状态（LOOKING），一开始都会投票给自己，认为自己比较适合作为leader
2. 然后相互交互投票，每个节点会收到其他节点发过来的选票，然后pk，先比较zxid，zxid大者获胜，zxid如果相等则比较myid，myid大者获胜
3. 一个节点收到其他节点发过来的选票，经过PK后，如果PK输了，则改票，此节点就会投给zxid或myid更大的节点，并将选票放入自己的投票箱中，并将新的选票发送给其他节点
4. 如果pk是平局则将接收到的选票放入自己的投票箱中
5. 如果pk赢了，则忽略所接收到的选票
6. 当然一个节点将一张选票放入到自己的投票箱之后，就会从投票箱中统计票数，看是否超过一半的节点都和自己所投的节点是一样的，如果超过半数，那么则认为当前自己所投的节点是leader
7. 集群中每个节点都会经过同样的流程，pk的规则也是一样的，一旦改票就会告诉给其他服务器，所以最终各个节点中的投票箱中的选票也将是一样的，所以各个节点最终选出来的leader也是一样的，这样集群的leader就选举出来了



### Zookeeper集群中节点之间数据是如何同步的

1. 首先集群启动时，会先进行领导者选举，确定哪个节点是Leader，哪些节点是Follower和Observer
2. 然后Leader会和其他节点进行数据同步，采用发送快照和发送Diff⽇志的方式
3. 集群在工作过程中，所有的写请求都会交给Leader节点来进行处理，从节点只能处理读请求
4. Leader节点收到一个写请求时，会通过两阶段机制来处理
5. Leader节点会将该写请求对应的⽇志发送给其他Follower节点，并等待Follower节点持久化⽇志成功
6. Follower节点收到⽇志后会进行持久化，如果持久化成功则发送一个Ack给Leader节点
7. 当Leader节点收到半数以上的Ack后，就会开始提交，先更新Leader节点本地的内存数据
8. 然后发送commit命令给Follower节点，Follower节点收到commit命令后就会更新各自本地内存数据
9. 同时Leader节点还是将当前写请求直接发送给Observer节点，Observer节点收到Leader发过来的写请求后直接执行更新本地内存数据
10. 最后Leader节点返回客户端写请求响应成功
11. 通过同步机制和两阶段提交机制来达到集群中节点数据一致



### Dubbo内置负载均衡策略

Dubbo内置了4种负载均衡策略:

1. RandomLoadBalance:随机负载均衡。随机的选择一个。是Dubbo的**默认**负载均衡策略。
2. RoundRobinLoadBalance:轮询负载均衡。轮询选择一个。
3. LeastActiveLoadBalance:最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。
4. ConsistentHashLoadBalance:一致性哈希负载均衡。相同参数的请求总是落在同一台机器上。



### Spring Cloud有哪些常用组件

1. Eureka：注册中心
2. Nacos：注册中心、配置中心
3. Consul：注册中心、配置中心
4. Spring Cloud Config：配置中心
5. Feign/OpenFeign：RPC调用
6. Kong：服务网关
7. Zuul：服务网关
8. Spring Cloud Gateway：服务网关
9. Ribbon：负载均衡
10. Spring CLoud Sleuth：链路追踪
11. Zipkin：链路追踪
12. Seata：分布式事务
13. Dubbo：RPC调用

14. Sentinel：服务熔断

15. Hystrix：服务熔断

    



## 项目与HR

### 自我介绍

面试官好，我叫刘坤。现在是就读于杭州电子科技大学计算机技术专业的研究生。

XX公司是我一直比较向往的公司，我应聘的是JAVA后端开发工程师的工作，从事后端开发也是我一直以来对自己工作的职业规划。为此呢，我很早就结合工作岗位的要求进行了相关学习。

 我在本科时候就加入了学校的ACM集训队，参加了一些大学生程序竞赛，学习了一些算法知识。

后来加到了java实验室，从零开始参与开发了学校的一个毕业生论文选题管理的一个教务系统。系统使用的是SSM的框架，主要是对毕业生导师双选，论文选题，开题，答辩，整个流程的管理，这个系统从18届毕业生开始正式上线使用。

 研究生阶段呢，我的实验室叫做工业互联网研究院；我也重点参与了实验室的相关项目研发；

前期呢，主要是针对Linux系统进行一些实时性优化的研究；另外就是，在生产线平台上，负责然后在业务层OPC UA协议的相关接口,再通过这个协议将数据发送到监控平台，使用redis对监控状态做了个缓存，用消息队列和websocket对报警信息进行一个异步推送和入库。

最后呢，希望能够加入公司，从事后端研发相关的工作，谢谢！



计算机学院学生第五党支部 副书记 2019.07 – 至今

负责计算机学院学生第五党支部党务工作。



信息学院青年志愿者协会 编辑部部长  2016.03-2017.10

负责维护学院青公众号平台；

策划和组织日常活动，编写新闻发布稿，活动策划书等。



### 项目介绍

**项目名称：灌装饮料生产线智能管理云平台 2020.09 - 2021.03**

项目描述：此项目为互联网+工业 4.0 解决方案，实现对工业生产线中异构生产设备的远程监控，提供工业生产线的一站式执行服务，对设备运行状态实现实时在线监测、预警、具有自动记录，生产定制、异常监测、数据通信等功能，实现对设备生产，监控等全方位一体化高效管理，降低人员维护成本，以减少事故发生或事故的扩大化。

涉及技术：Spring Boot、MyBatis、MySQL、Redis、WebSocket、RabbitMQ、OPC UA、Quartz等。

责任描述： 

\1. 负责完成底层数据采集，基于 OPC UA 协议实现网关协议转换； 

\2. 负责在客户端提供 OPC UA 协议相关接口，读取 OPC UA Server 端数据； 

\3. 使用 Redis 缓存监控设备信息，降低数据库访问压力；

\4. 通过 WebSocket 和 RabbitMQ 完成设备实时数据监控和报警提示； 

\5. 负责对接现场六轴工业机器人部分、完成机器人控制程序开发；

**项目名称：基于自主平台的装备实时优化控制方法与关键技术  2019.09 - 2020.01**

项目描述：在研究 EtherCAT 协议的过程中，针对传统 Linux 系统难以满足工业以太网实时性的问题，其在嵌入式应用中有一定的局限性，对可编程控制器进行实时性优化，通过在 Ubuntu16.04系统上进行Xenomai实时内核的移植和修改，构建一种具有实时网络的 Linux 系统，以达到硬时要求。

责任描述： 

\1. 进行 Xenomai 实时内核的移植，实现嵌入式 Linux 内核的硬实时性； 

\2. 利用 RTnet 对 Linux 进行网络实时化改造，实现 linux 系统在工业上的应用。



Xenomai 基于Adeos(Adaptive Domain Environment for Operating System)实现双内核机制。Adeos 是扩展Linux 的基础环境，

Adeos 的设计目标是为操作系统提供一个灵活的、可扩展的自适应环境，在这个环境下，多个相同或不同的操作系统可以共存，共享硬件资源。目前，Adeos 是基于Linux 内核实现的，主要的应用是在Linux 的实时化方面，使基于Linux 的系统能满足强实时的要求（例如Xenomai 和RTAI3.2 以上版本都是基于Adeos 实现的）。在基于Adeos 的系统中，每个操作系统都是在独立的域内运行（但不一定所有的域实现的都是操作系统，也可以是完成其它功能的软件实体），每个域可以有独立的地址空间和类似于进程、虚拟内存等的软件抽象层，而且这些资源也可以由不同的域共享。

Xenomai 在Adeos 系统中的域优先级高于Linux 域，每当中断到来之后，Adeos先调度Xenomai 对该中断进行处理、执行中断相应的实时任务，只有当Xenomai 没有实时任务和中断需要处理的时候，Adeos 才会调度Linux 运行，这就保证了Xenomai的中断响应速度和实时任务不受Linux 的影响，从而提供了实时系统的可确定性。

Xenomai 实时内核为开发强实时应用提供了丰富的功能，主要包括实时线程调度与管理、用户空间实时任务支持、线程同步服务、时钟服务、中断服务、动态内存申请和实时对象注册服务等。



**Linux在实时应用中的技术障碍**

　　尽管Linux本身提供了一些支持实时性的机制，然而，由于Linux系统是以高的吞吐量和公平性为追求目标，基本上没有考虑实时应用所要满足的时间约束，它只是提供了一些相对简单的任务调度策略。因此，实时性问题是将Linux应用于嵌入式系统开发的一大障碍,无法在硬实时系统中得到应用。 Linux在实时应用中的技术障碍具体表现在:

　　(1)Linux系统时钟精度太过粗糙，时钟中断周期为10ms，使得其时间粒度过大，加大了任务响应延迟。

　　(2) Linux的内核是不可抢占的, 当一个任务通过系统调用进入内核态运行时,一个具有更高优先级的进程，只有等待处于核心态的系统调用返回后方能执行，这将导致优先级逆转。实时任务执行时间的不确定性，显然不能满足硬实时应用的要求。

　　(3) Linux采用对临界区操作时屏蔽中断的方式，在中断处理中是不允许进行任务调度的，从而抑制了系统及时响应外部操作的能力。

　　(4) 缺乏有效的实时任务调度机制和调度算法。



**项目名称：郑州师范毕业生论文选题系统 2017.07 - 2018.01**

项目描述：此系统用于管理毕业生的论文选题信息，帮助完成学生与老师之间的双选，选题，任务书，开题报告，论文答，成绩分析，整个流程的管理。方便统计查看论文完成进度，审核状态等信息。系统采用 SSM 框架开发，使用MySQL数据库进行数据存储，并搭配前端技术LayUI、JQuery、bootstrap、Echarts进行页面展示。系统按照学院毕业设计(论文)的时间安排及流程顺序进行相应功能模块的设计与开发，贴合实际应用环境，降低了整个毕业设计(论文)阶段中人工进行数据统计整合的参与度，最大程度的保证相关数据的完整性、时效性；已从信息学院2018 届毕业生开始上线使用，大大提高了流程管理效率。

涉及技术：SpringMVC、Spring、MyBatis、Maven、MySQL 数据库、LayUI、JQuery、bootstrap、Echarts 等。 

责任描述： 

\1. 从0到1参与整个项目的研发、负责项目的需求分析，数据库表设计； 

\2. 负责双选、选题、统计分析等部分模块的开发；

\3. 负责对项目使用过程中的 bug 修复和完善；



### Redis 缓存一致性

对于主页数据（监控设备的属性信息（（阈值，单位等）））提前放入缓存中。

写：(在配置页面更新参数时，先更新数据库，同时删除缓存)

读：

缓存中有 直接读

如果缓存中没有，同时将所要监控的设备属性信息从数据库读取并保存到缓存中（阈值，单位等）



请求监控，缓存中有 直接返回。

如果缓存中没有 将要监控的设备属性ID加入到监控列表里，定时任务通过这个列表去读取底层状态数据 将读取数据存入 redis 缓存中 

定时任务会将读取数据与redis中的数据进行比较 不一致 更新缓存 websocket 推送新的数据状态 



### 报警是怎么做的

比较现在的状态值  和  设备的阈值    是否发生报警  比较次数操过3次不一致 报警

产生异常报警 报警信息加入消息队列消费端 使用rabbitMQ 订阅 报警信息

解耦  接收到订阅消息队列的报警消息后  

异步报警 将报警信息队列的数据通过WebSocket推送到前端对应用户 不在线的用户通过邮件提醒

报警信息异步入库

报警信息入库时 判断 当前设备 当前属性 报警类型 根据是否处理的状态 进行入库  未处理就不入库。

间隔报警 只入库一次   阶段报警 一直入库



### 为什么用 websocket？

在websocket以前大多是长轮询实现，长轮询需要不停的主动去连接服务器询问是否有新消息，耗费性能。而websocket浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。

在websocket以前大多是长轮询实现，长轮询需要不停的主动去连接服务器询问是否有新消息，耗费性能。而websocket浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。

Rabbitmq消息队列简单组成就可以看成是生产者，队列，消费者，生产者创建信息通过队列发送给消费者，消费者接收消息。两者结合起来，用户登录时就创建websocket连接，建立起一个浏览器和服务器的通道，同时创建一个特定的Rabbitmq消费者，用来代表这个用户来处理生产者发送过来的消息。那么生产者发送信息，消费者只要在线就能自动收取到信息，通过建立好的通道推送到前端。

因此，我们可以使用RabbitMQ的订阅发布技术，订阅后，当RabbitMQ端有新的数据就直接发布到指定的queue，订阅端接收到订阅队列的数据直接通过WebSocket推送到前端，前端拿到数据之后实时解析上显，此过程相比传统的Rest接口定时请求，减去了数据入库、读库、客户端不断的请求服务器和刷新页面，大大的减小了服务器的压力和减少了请求时间。该设计更适用于实时数据接收后直接推送到前端上显的一些不需要处理和统计的场景，如实时船舶的上显，导航等。

### 为什么用 Quartz？

Quartz 可以满足复杂的调度需求。

Quartz可以通过cron表达式精确到特定时间执行

多线程；可以做数据存储型的定时任务，维护性高；

quartz 支持分布式 Quartz是有cluster支持的

**对异常的处理**

Quartz的某次执行任务过程中抛出异常，不影响下一次任务的执行，当下一次执行时间到来时，定时器会再次执行任务。

SpringTask不同，一旦某个任务在执行过程中抛出异常，则整个定时器生命周期就结束，以后永远不会再执行定时器任务。



### 项目的难点和遇到的问题

**Linux实时性不够，实时内核**

百度、谷歌、老师、请教大牛、论文、开源项目、解决问题、总结问题、博客分享记录

尝试方式：抢占式的 RT-Preempt 补丁 、英特尔ACRN实时架构、Xenomai 实时内核(双内核)+rtnet实时网卡驱动

//1.根据系统内核linux4.9版本,xenomai3.7版本、2.解压内核、对应的补丁、3.配置、编译、安装、4.更新GRUB  5.测试实时内核 



RTnet调试相关问题，启动实时网卡导致非实时网卡不能启动

Rtnet是xenomai下提供的实时网络通信框架。在调试中遇到的问题主要是两块网卡无法分别使用。官网上提供的参考方法是针对于比较老的网卡，按照他们提供的配置方法会出现cards参数不识别的现象。

对内核的网卡模块驱动做了相应改变，富士康提供的网卡用的是igb驱动，所以在相应文件夹下对main文件做了相关修改。文件路径/usr/src/linux-4.9.90/drivers/xenomai/net/drivers/igb/igb_main.c,该文件其实是一个链接文件，其真实路径为：/usr/src/xenomai-3.0.7/kernel/drivers/net/drivers/igb/igb_main.c。

**解决办法：**

通过dmesg命令可以查看到registered rteth0只注册了一次。其它加载时仅出现*****not first call*****

显示所有的网卡 **ifconfig -a**  查看网卡所需驱动   **ethtool -i 网卡名**   查看网卡型号  **lspci -nn | grep "Eth"**

查看目标内核的网卡驱动是否支持当前型号网卡  **modinfo命令查看*.ko对哪种设备型号的支持**

修改驱动文件：这里我是在igb_main.c添加一个全局变量然后再在igb_probe函数中加一个判断，限制实时网卡的注册次数。重新编译这个驱动文件，将生成驱动文件拷贝到对应的目录，执行`depmod`加载模块依赖,这样我们的执行modprobe 才会加载新的驱动文件。



**websocket链接断开服务器报错 java.io.EOFException**

websocket间隔几秒十几秒断开，由于加上了断线重连，所以就是一直断一直连，一直报错 java.io.EOFException 然候网上各种百度。

websocket需要进行心跳包维持连接，浏览器不会帮你维持，所以隔段时间就断开了，你自己实现的客户端就需要维持这个连接、检查代码发现没做心跳。。。。加上心跳异常就解决了。 10 min

新技术的使用尽量在开发前期就发现问题、避免上线之后手忙脚乱。



### 你的职业规划？

走技术方向，CTO路线，向架构师发展。

首席技术官（外语词全称chief technology officer，外语词缩略语CTO）是[技术资源](https://baike.baidu.com/item/技术资源/2422923)的行政管理者。

不论在长期还是短期，我的个人策略是根据当前目标评价自己所处的位置，然后相应地修改自己的计划。比如，我每五年就制定一项个人计划，这个计划中包含一个总体目标和一系列短期目标。每6 个月我就回顾一下自己的进展，然后做出必要的修改。很明显，我当前的计划就是实现职业转变，也就是找到更满意的工作。除此之外，我已经实现了近期制定的个人目标。e

**你认为你未来两年内达到什么标准是比较满意的？**

两年内，通过对Java后端的技术栈的丰富，给一个项目，能够达到对一个项目的整个系统架构，从上到下的技术栈都能有一定的了解，能够快速构建项目的系统架构，和选择合适的技术栈去解决每一层可能的问题。最好是能达到一个独立带领团队的效果。

**为什么申请这个岗位？**

首先，本身就是计算机专业的，在学校做的项目也和java后端开发工程师这个岗位相关。

 

### 你希望通过这份工作获得什么?

对我来说，最重要的是自己所做的工作是否适合我。我的意思是说，这份工作应该能让我发挥专长——这会给我带来一种满足感。我还希望所做的工作能够对我目前的技能水平形成挑战，从而能促使我提升自己。



### 给你一个任务，你会怎么做?



### 你个人的优缺点？

**你认为你的优势/核心竞争力是什么？**

优点：

本科和硕士都是 计算机专业的，有相对扎实的计算机基础常识。

适应能力强，注重团队合作意识，包括组织协调能力，能快速融入团队。本科在青协、研究生党支部副书记，协调和组织一些活动。

有计划、目标坚定、反思，遇到问题会坚持不懈。

学习能力强，有良好的学习习惯，自学能力。技术视野开阔，喜欢学习和研究一些新技术;

缺点：

表达能力不是太好，容易紧张，有些东西可能自己比较清楚、再传达给别人就表达的不是很好，这就导致我面试其实是很吃亏的。能力够了反而没有别人面试的好。

另外就是，因为是学生，一直在学校，所以比较有学生气，所以对问题的思考会站在一个学生的角度，考虑不够全面，如果作为一个员工的话，肯定更多的考虑是为公司的利益。

 

### 请描述一件最有成就感的事情？

就是在我刚上大学的时候加入了学校的校ACM集训队，其实刚上大学的时候大家都还是比较想玩的，而集训队呢，需要打比赛，要一直在机房里刷题学习。所以当时集训队也有着这么一句话：“一入机房深似海，从此假期是路人”，也正是因为在集训队的那段时间，养成了一个良好的自学习惯，遇到问题不断地钻研。

 

### 如果工作当中你和别人发生了冲突，你会如何处理？

首先，以我的性格很少会与他人冲突。

如果说产生冲突，我会先冷静一下，分析问题的原因，如果是我的问题，我会道歉认错，反思。

如果是别人的问题，我会先冷静，事后再去讨论，或者找其他人帮忙以旁观者的角度去分析，帮忙协调。

 

### 你期望的薪资是多少？

行业标准都能接受。

薪资是税前还是税后？

有没有试用期？试用期薪资会不会有折扣？

有没有加班费？

### 你还有什么问题要问我的？

部门业务？

多久会有反馈结果？

一共有几轮面试？

您感觉我面试过程如何，有哪些地方需要注意和改进的？

新员工的培养？

晋升机制？



### 谈薪问题？

多久会调薪一次？

适用期多久？工资会有折扣吗？

公积金缴纳比例？缴纳基数？薪资结构？

是双休吗？平时加班多吗？加班费怎么算的？

年终奖怎么算的？一般会拿多少？

实习期的时间，有没有年终奖？

有没有什么其他补贴，员工福利？

我能考虑一下吗？最迟什么时候给你回复？



### 你有什么崇拜的人吗？

**林纳斯·托瓦兹（Linus Torvalds）**

我最崇拜Linux操作系统的创始人利纳斯托瓦兹，欣赏他的创造力，他写的代码改变了这个世界，我希望自己有一天也可以写出来一个牛x的产品。也正是因为他，才会有优秀的开源软件吸引更多人对开源进行贡这样的机制，然后开源软件事实上是在他的倡导下发展了。

“有些人生来就具有统率百万人的领袖风范；另一些人则是为写出颠覆世界的软件而生。唯一一个能同时做到这两者的人，就是托瓦兹。”美国《时代》周刊对“Linux之父”林纳斯·托瓦兹（Linus Torvalds）给出了极高的评价。

著有自传《乐者为王》。

以前学习内核的时候，看了linus 的 Linux 0.11内核的源代码。说下感觉吧，一脸的懵逼的进去，一脸懵逼的出来。巨他妈的复杂。最后一段段看，每个函数加上了注释。然后编译过一遍，发现能通过。 Linux 本身只是一个内核，以这个内核为基础，诞生了这个世界上的绝大多数电子设备（路由器，交换机，手机，服务器）



### 如何将一个开源项目变为自己的项目？

<img src="Java面试总结.assets/clip_image002.jpg" alt="img" align=left />

###  项目介绍怎么写？

项目介绍本系统是X委托Y开发的用于Z的系统，系统包括A、B、C、D等模块。系统使用了Java企业级开发的开源框架E以及前端技术F。表示层运用了G架构，使用H作为视图I作为控制器并实现了REST风格的请求；业务逻辑层运用了J模式，并通过K实现事务、日志和安全性等功能，通过L实现缓存服务；持久层使用了M封装CRUD操作，底层使用N实现数据存取。整个项目采用了P开发模型。 项目开发流程（根据情况依次填入）可行性分析 >>> 可行性分析报告 / 项目开发计划书需求分析 >>> 需求规格说明书设计 >>> 概要设计说明书/详细设计说明书编码测试 >>> 测试报告 / 缺陷报告交付和维护 >>> 用户手册 / 操作手册

 

项目简介：主要用于描述整个项目流程，按照数据流的输入到输出来写或者从前端到后端逻辑来写，基于某些技术或框架实现了某种功能，最终达到了某种效果。

实际操作-可以将项目流程先在纸上画出来，然后对照流程进行从头至尾的描述，可以把主要环节用到的什么技术解决了什么问题突出即可，也不用面面俱到。

举例：本项目基于Spring MVC + Spring + Mybatis框架，利用× ×埋点记录× ×日志，利用Redis实现对××数据的缓存，处理后的数据最终落地MySQL等等，最终实现了对× ×指标监控分析。

 

项目职责：只要写项目亮点和你负责的技术，比如说，利用某种技术解决了某种问题，优化了数据的访问，提高了n倍的速度，或者说，设计出某种技术，实现了某种功能。

实际操作-找出你项目中希望被面试官问到的点，或者你认为属于项目亮点的部分，突出你对项目的优化部分。

 

举例：

●使用nginx实现了负载均衡，提高了访问速度

●定义热点数据并缓存在Redis，降低了数据库访问压力

●利用zookeeper实现HA，解决单点故障

●利用JVM指令排查出GC问题，调整JVM配置，降低GC次数

 

工作时间：2016-10到2017-09公司名称：xxx有限公司 | 所在部门：xxx | 所在岗位：java开发工程师

工作描述：

1 NETTY通信框架下的物联网连接服务器开发

2 基于微框架springboot+mybatis-plus+springmvc的后台服务器接口开发

3 能在linux环境下使用docker打包部署项目，后期进行监控维护调试

4 涉及物联网相关通信技术：MQTT，SOAP，Kafka，activeMq，zookeeper的使用

5 使用树莓派模拟开发。



### 华为机试题目

1.

```java
package bishi.HUAWEI;

import java.util.Scanner;

public class HUAWEI_Demo1 {

    public static void main(String[] args) {
        Scanner in = new Scanner(System.in);
        int x = in.nextInt();
        int n = in.nextInt();
        int[] price = new int[n];
        int[] count = new int[n];
        int[] love = new int[n];
        for(int i = 0; i < n; i++){
            price[i] = in.nextInt();
            count[i] = in.nextInt();
            love[i] = in.nextInt();
        }
        int[] dp = new int[x+1];
        for(int i = 0; i < n; i++){
            if(price[i] * count[i] >= x){
                for(int j = price[i];j <= x; j++){
                    dp[j] = Math.max(dp[j],dp[j-price[i]]+love[i]);
                }
            }else{
                int k = 1;
                int temp = count[i];
                while(k < temp){
                    int v_temp = k * price[i];
                    for(int j = x; j >= v_temp; j--){
                        dp[j] = Math.max(dp[j],dp[j-v_temp]+k*love[i]);
                    }
                    temp -= k;
                    k *= 2;
                }
                for(int j = x; j >= temp * price[i];j--){
                    dp[j] = Math.max(dp[j],dp[j-temp*price[i]]+temp*love[i]);
                }
            }
        }
        System.out.println(dp[x]);
    }
}
```

2.

```java
package bishi.HUAWEI;

import java.util.Scanner;

public class HUAWEI_Demo2 {
    public static void main(String[] args) {

        Scanner in = new Scanner(System.in);
        int x = in.nextInt();
        int m = in.nextInt();
        int[] price = new int[m];
        for(int i = 0; i < m; i++){
            price[i] = in.nextInt();
        }

        int[] dp = new int[x+1];
        dp[0] = 1;
        for(int i = 0; i < m; i++){
            for(int j = x; j >= price[i]; j--){
                //dp[j] = Math.max(dp[j],dp[j-price[i]]+1);
                if(dp[j - price[i]] != 0){
                    dp[j] = dp[j] + dp[j-price[i]];
                }
            }
        }
        if(dp[x] == 0){
            System.out.println("-1");
        }else{
            System.out.println(dp[x]);
        }

    }
}
```

3.

```java
package bishi.HUAWEI;

import java.util.Scanner;

public class HUAWEI_Demo3 {
    static int ans = Integer.MAX_VALUE;
    public static void main(String[] args) {
        Scanner in = new Scanner(System.in);
        int m = in.nextInt();
        int n = in.nextInt();
        boolean[][] visit = new boolean[m][n];
        int[][] map = new int[m][n];
        for (int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++){
                map[i][j] = in.nextInt();
                visit[i][j] = false;
            }
        }
        int x1 = in.nextInt();
        int y1 = in.nextInt();
        int x2 = in.nextInt();
        int y2 = in.nextInt();

        DFS(map,visit,x1,y1,x2,y2,0);
        System.out.println(ans);

    }

    private static void DFS(int[][] map, boolean[][] visit, int i,int j,int x2, int y2, int count) {
        if(i < 0 || j < 0 || i > map.length || j > map[0].length){
            return ;
        }
        if(count > 0 && i == x2 && j == y2){
            ans =  Math.min(ans,count);
        }
        visit[i][j] = true;
        count ++;
        int[][] dis = {{0,0,1,-1},{1,-1,0,0}};
        for(int k = 0; k < 4; k++){
            int dx = i + dis[0][k];
            int dy = j + dis[1][k];
            if((dx >= 0 && dy >= 0 && dx < map.length && dy < map[0].length && map[dx][dy] == 0 && !visit[dx][dy]) || (dx == x2 && dy == y2)){
                visit[dx][dy] = true;
                DFS(map,visit,dx,dy,x2,y2,count);
                visit[dx][dy] = false;
            }
        }
    }
}
```



//多重背包：

```java
package Algorithm.DP.beibao;

import java.util.Scanner;

public class BeibaoDuochong {
    public static void main(String[] args) {
        Scanner in = new Scanner(System.in);
        int V = in.nextInt(); //背包容量
        int n = in.nextInt();//物品种类
        int[] w = new int[n];//物品的重量
        int[] v = new int[n];//物品的价值
        int[] num = new int[n];//物品的数量

        for (int i = 0; i < n; i++) {
            w[i] = in.nextInt();
            v[i] = in.nextInt();
            num[i] = in.nextInt();
        }

        int[] dp = new int[V+1];
        for (int i = 0; i < n; i++) {
            for (int j = 1; j <= num[i]; j++) {
                for (int k = V; k >= w[i]; k--) {
                    dp[k] = Math.max(dp[k],dp[k-w[i]]+v[i]);
                }
            }
        }
        System.out.println(dp[V]);
    }
}
```



## 常见代码模板

### 死锁代码

```java
package com.kun.thread.demo;

public class ThreadTest11 {
    public static void main(String[] args) {
        //两个线程共享o1,o2
        Object o1 = new Object();
        Object o2 = new Object();
        Thread t1 = new MyThread01(o1,o2);
        Thread t2 = new MyThread02(o1,o2);
        t1.start();
        t2.start();
    }
}

class MyThread01 extends  Thread {
    Object o1;
    Object o2;

    public MyThread01(Object o1, Object o2) {
        this.o1 = o1;
        this.o2 = o2;
    }

    @Override
    public void run() {
        synchronized (o1) {
            try {
                System.out.println(Thread.currentThread().getName()+"获得o1资源，等待o2资源");
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            synchronized (o2) {
            }
        }
    }
}
class  MyThread02 extends Thread {
    Object o1;
    Object o2;

    public MyThread02(Object o1, Object o2) {
        this.o1 = o1;
        this.o2 = o2;
    }

    @Override
    public void run() {
        synchronized (o2) {
            try {
                System.out.println(Thread.currentThread().getName()+"获得o2资源，等待o1资源");
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            synchronized (o1) {
            }
        }
    }
}
```



### 生产者消费者

```java
package com.kun.thread.demo;

import java.util.ArrayList;
import java.util.List;

//List模拟仓库,容量为1，即生产一个消费一个
public class ProductConsumerDemo {
    public static void main(String[] args) {
        //创建一个仓库对象，共享的
        List list = new ArrayList();
        //创建两个线程对象
        //生产者线程
        Thread t1 = new Thread(new Producer(list));
        //消费者线程
        Thread t2 = new Thread(new Consumer(list));
        t1.setName("生产者线程：");
        t2.setName("消费者线程：");
        t1.start();
        t2.start();
    }
}
//生产线程
class Producer implements Runnable{
    //仓库
    private List list;

    public Producer(List list) {
        this.list = list;
    }

    @Override
    public void run() {
        //一直生产
        while(true) {
            synchronized (list) {//给仓库资源加锁
                if (list.size() > 0) {
                    //当前线程进入等待状态，释放锁，不放锁的话，消费者线程无法访问资源（生产者线程）
                    try {
                        list.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                //程序能执行到这里说明仓库为空，可以生产
                Object obj = new Object();
                list.add(obj);
                System.out.println(Thread.currentThread().getName()+"-->"+"生产了"+ list.size() + "个"+obj +",消费者可以消费了。");
                //唤醒消费者消费
                list.notify();
            }
        }
    }
}
//消费线程
class Consumer implements Runnable{
    //同一个仓库
    private List list;
    public Consumer(List list) {
        this.list = list;
    }
    @Override
    public void run() {
        //一直消费
        while (true){
            synchronized (list){//没有得到锁，以下代码都不能执行
                if(list.size()==0){
                    //仓库空了，停止消费，消费线程进入阻塞，释放list集合的锁
                    try {
                        list.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                //程序能够执行到这，说明仓库有数据，进行消费
                Object obj= list.remove(0);
                System.out.println(Thread.currentThread().getName()+"-->"+"消费了" + obj + "还剩"+list.size()+"个,生产者该生产了。。。");
                //唤醒生产者进行生产
                list.notify();

            }
        }
    }
}
```

### LRU 实现

```java
package mianshi.HUAWEI;

import java.util.HashMap;
import java.util.LinkedList;
import java.util.Queue;

public class LRUdemo {
    private Queue<Integer> queue;
    private HashMap<Integer,Integer> map;
    private int capacity;

    public LRUdemo(int capacity) {
        queue = new LinkedList<>();
        map = new HashMap<>();
        this.capacity = capacity;
    }

    public int get(int key){
        Integer value = map.get(key);
        if(value == null){
            return -1;
        }else{
            queue.remove(key);
            queue.offer(key);
            return value;
        }
    }

    public void put(int key,int value){
        Integer val = map.get(key);
        if(val == null){
            if(queue.size() >= capacity){
                int head = queue.poll();
                map.remove(head);
            }
            queue.offer(key);
            map.put(key, value);
        }else{
            queue.remove(key);
            queue.offer(key);
            map.put(key,value);
        }
    }

    public static void main(String[] args) {
        LRUdemo lru = new LRUdemo(3);
        lru.put(1,1);
        lru.put(2,2);
        lru.put(3,3);
        lru.put(4,4);
        lru.get(3);
        while (!lru.queue.isEmpty()){
            System.out.println(lru.queue.poll());
        }
    }
}
```

### 最长公共子序列

```java
package Algorithm.DP;

/**
 * 最长公共子序列长度
 * s1 = "abcde"
 * s2 = "ace"
 * ans = 3
 */
public class LongestSubXulie {
    public static void main(String[] args) {
        String s1 = "abcde";
        String s2 = "ace";
        int ans = longestCommonSubsequence(s1,s2);
        System.out.println(ans);
    }

    private static int longestCommonSubsequence(String s1, String s2) {
        int n = s1.length();
        int m = s2.length();
        int[][] dp = new int[n+1][m+1];
        dp[0][0] = 0;
        for (int i = 1; i <= n; i++) {
            for (int j = 1; j <= m ; j++) {
                if(s1.charAt(i-1) == s2.charAt(j-1)){
                    dp[i][j] = dp[i-1][j-1] + 1;
                }else{
                    dp[i][j] = Math.max(dp[i-1][j],dp[i][j-1]);
                }
            }
        }
        return dp[n][m];
    }
}
```

### 最长公共子串

```java
package Algorithm.DP;
/**
 * 最长公共子串
 */
public class LongestSubString {
    public static void main(String[] args) {
        String s1 = "asdfgh";
        String s2 = "wwesdfgddd";
        String ans = longestSubString(s1,s2);
        System.out.println(ans);
    }

    private static String longestSubString(String s1, String s2) {
        int maxLen = 0;
        int maxLastIndex = 0;
        int[][] dp = new int[s1.length()+1][s2.length()+1];
        for (int i = 0; i < s1.length(); i++) {
            for (int j = 0; j < s2.length(); j++) {
                if(s1.charAt(i) == s2.charAt(j)){
                    dp[i+1][j+1] = dp[i][j] + 1;
                    if(dp[i+1][j+1] > maxLen){
                        maxLen = dp[i+1][j+1];
                        maxLastIndex = i;
                    }
                }else{
                    //递推，两个字符不相等
                    dp[i+1][j+1] = 0;
                }
            }
        }
        //最字符串进行截取，substring(a,b)中a和b分别表示截取的开始和结束位置
        return s1.substring(maxLastIndex - maxLen + 1, maxLastIndex + 1);
    }
}

```

### 大数字符串相加

```java
package mianshi.HUAWEI;

import java.util.LinkedList;
import java.util.List;

/**
 * 题目：给定n,m，0<n<10，m代表n的个数，比如2,5表示2,22,222,2222,22222,这样一个序列，对这个序列求和并输出；
 */

public class Test06 {
    public static void main(String[] args) {
        String ans = get(2,5);
        System.out.println(ans);
    }

    private static String get(int n, int m) {
        List<String> strings = new LinkedList<>();
        StringBuffer s = new StringBuffer();
        for (int i = 1; i <= m ; i++) {
            s = s.append(n);
            strings.add(s.toString());
        }
        String ans = strings.get(0);
        for (int i = 1; i < strings.size(); i++) {
            ans = stringAdd(ans,strings.get(i));
        }
        return ans;
    }

    //字符串相加
    private static String stringAdd(String s1, String s2) {
        StringBuffer res = new StringBuffer();
        String ss1 = new StringBuffer(s1).reverse().toString();
        String ss2 = new StringBuffer(s2).reverse().toString();
        int len1 = ss1.length(),len2 = ss2.length();
        int maxlen = Math.max(len1,len2);
        int tempNum = 0;  //当前求和值
        int overFlow = 0; //进位
        for (int i = 0; i < maxlen; i++) {
            if(i < len1 && i < len2){
                tempNum = (ss1.charAt(i)- '0') + (ss2.charAt(i) - '0') + overFlow;
            }
            if(i < len1 && i >= len2){
                tempNum = (ss1.charAt(i) - '0') + overFlow;
            }
            if(i >= len1 && i < len2){
                tempNum = (ss2.charAt(i) - '0') + overFlow;
            }
            if(tempNum >= 10){
                tempNum = tempNum % 10;
                overFlow = 1;
            }else{
                overFlow = 0;
            }
            res.append(tempNum);
        }

        if(overFlow != 0){
            res.append(overFlow);
        }
        return res.reverse().toString();

    }
}
```

